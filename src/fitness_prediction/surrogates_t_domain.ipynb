{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 19:23:27.188647: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-17 19:23:27.193008: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-17 19:23:27.198699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-17 19:23:27.209847: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-17 19:23:27.209864: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 19:23:27.217034: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-17 19:23:33.661520: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from DomainPrediction.utils import helper\n",
    "from DomainPrediction.eval import metrics\n",
    "from DomainPrediction.al import top_model as topmodel\n",
    "from DomainPrediction.al.embeddings import one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = os.environ['CONDA_DEFAULT_ENV']\n",
    "if env == 'workspace':\n",
    "    sys.path.append('../../esm')\n",
    "    from DomainPrediction.esm.esmc import ESMCLM\n",
    "    from DomainPrediction.al.finetuning import ESMCLoraRegression, ESMCConFit\n",
    "elif env == 'workspace-esm':\n",
    "    from DomainPrediction.esm.esm2 import ESM2\n",
    "    from DomainPrediction.al.finetuning import ESM2LoraRegression, ESM2ConFit\n",
    "else:\n",
    "    raise Exception('I designed this for my envs. Feel free to modify accordingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/nethome/kgeorge/workspace/DomainPrediction/Data/fitness_prediction/Tdomain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(data_path, 'dataset_2_tdomain.csv')\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>seq</th>\n",
       "      <th>fitness_raw</th>\n",
       "      <th>split_id</th>\n",
       "      <th>n_mut</th>\n",
       "      <th>fitness_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WT</td>\n",
       "      <td>APGEDAFARQAYQAPQGEIEIALATIWRELLNVEQVGRHDSFFALG...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESM1</td>\n",
       "      <td>APEDSSFPRPPYAAPEGEIEQTLAGIWMELLGVERVGRHDSFFALG...</td>\n",
       "      <td>0.982485</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>-0.017670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESM2</td>\n",
       "      <td>APSEDAYPRATYEAPEGETEQLLAGIWMDLLQVDRVGRHDSFFELG...</td>\n",
       "      <td>1.730126</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.548194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESM3</td>\n",
       "      <td>APSEDSYPRPAYVAPEGPTEQLLAGIWQELLNVSKVGRDDSFFDLG...</td>\n",
       "      <td>0.073117</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>-2.615701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESM4</td>\n",
       "      <td>APEEASYPREPYVAPQGETEQLLASIWQELLGVERVGAGDNFFELG...</td>\n",
       "      <td>0.457921</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-0.781059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name                                                seq  fitness_raw  \\\n",
       "0    WT  APGEDAFARQAYQAPQGEIEIALATIWRELLNVEQVGRHDSFFALG...     1.000000   \n",
       "1  ESM1  APEDSSFPRPPYAAPEGEIEQTLAGIWMELLGVERVGRHDSFFALG...     0.982485   \n",
       "2  ESM2  APSEDAYPRATYEAPEGETEQLLAGIWMDLLQVDRVGRHDSFFELG...     1.730126   \n",
       "3  ESM3  APSEDSYPRPAYVAPEGPTEQLLAGIWQELLNVSKVGRDDSFFDLG...     0.073117   \n",
       "4  ESM4  APEEASYPREPYVAPQGETEQLLASIWQELLGVERVGAGDNFFELG...     0.457921   \n",
       "\n",
       "   split_id  n_mut  fitness_log  \n",
       "0         2      0     0.000000  \n",
       "1         2     44    -0.017670  \n",
       "2         0     45     0.548194  \n",
       "3         2     46    -2.615701  \n",
       "4         2     43    -0.781059  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = os.path.join(data_path, 'results_tdomain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(results_file):\n",
    "    df_results = pd.read_csv(results_file)\n",
    "else:\n",
    "    df_results = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pred_OHE_ridge', 'pred_OHE_RF', 'pred_OHE_MLP', 'pred_esm2_mean_ridge',\n",
       "       'pred_esm2_mean_RF', 'pred_esm2_mean_MLP', 'pred_esm2_concat_ridge',\n",
       "       'pred_esm2_concat_RF', 'pred_esmc_mean_ridge', 'pred_esmc_mean_RF',\n",
       "       'pred_esmc_mean_MLP', 'pred_esmc_concat_ridge', 'pred_esmc_concat_RF',\n",
       "       'pred_esm2_wt_marginal', 'pred_esm2_masked_marginal',\n",
       "       'pred_esm2_pseudolikelihood', 'pred_esmc_pseudolikelihood',\n",
       "       'pred_esmc_wt_marginal', 'pred_esmc_masked_marginal',\n",
       "       'pred_esm2_confit', 'pred_esmc_confit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_mask(df, omit_zero=False):\n",
    "    if omit_zero:\n",
    "        train_mask = (df['split_id'] == 2) & (df['fitness_raw'] != 0)\n",
    "    else:\n",
    "        train_mask = (df['split_id'] == 2)\n",
    "\n",
    "    test_mask = df['split_id'].isin([0, 1])\n",
    "\n",
    "    return train_mask, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spearmanr_bootstrap(a, b, n=1000, ci = 95):\n",
    "    assert type(a) == type(b) == np.ndarray\n",
    "    assert len(a) == len(b)\n",
    "    corr = []\n",
    "    p_values = []\n",
    "    np.random.seed(0)\n",
    "    for _ in range(n):\n",
    "        indices = np.random.choice(len(a), size=len(a), replace=True)\n",
    "        res = stats.spearmanr(a[indices], b[indices])\n",
    "        \n",
    "        if not np.isnan(res.statistic):\n",
    "            corr.append(res.statistic)\n",
    "            p_values.append(res.pvalue)\n",
    "\n",
    "    ci_lower, ci_upper = np.percentile(corr, [100-ci, ci]) \n",
    "    # stats.t.interval(confidence=ci, df=len(corr)-1, loc=np.mean(corr), scale=np.std(corr))\n",
    "    mean_corr = np.mean(corr)\n",
    "    p_value = np.mean(np.array(corr) < 0)\n",
    "\n",
    "    return round(mean_corr, 2), round(ci_lower, 2), round(ci_upper, 2), p_value, corr, p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OHE based models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get embeddings and splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = one_hot_encode(df['seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, test_mask = get_split_mask(df, omit_zero=False)\n",
    "\n",
    "X_train = embeddings[train_mask]\n",
    "X_test = embeddings[test_mask]\n",
    "\n",
    "y_train = df.loc[train_mask, 'fitness_log'].to_numpy().astype(np.float32)\n",
    "y_test = df.loc[test_mask, 'fitness_log'].to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train {train_mask.sum()} test {test_mask.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = topmodel.RidgeSurrogate(alpha=1.0)\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0],\n",
    "            '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[1].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0])\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0])\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = surrogate.predict(embeddings)\n",
    "# assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "\n",
    "# df_results['pred_OHE_ridge'] = y_pred\n",
    "# df_results.to_csv(results_file, index=False)\n",
    "\n",
    "# df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = topmodel.RFSurrogate()\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0],\n",
    "            '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[1].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0])\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0])\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surrogate.predict(embeddings)\n",
    "assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "\n",
    "df_results['pred_OHE_RF'] = y_pred\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'input layer shape: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'layers': [2300, 512, 1], \n",
    "        'epoch': 100, \n",
    "        'batch_size': 16,\n",
    "        'patience': 100,\n",
    "        'early_stopping': False,\n",
    "        'lr': 1e-3,\n",
    "        'print_every_n_epoch': 10,\n",
    "        'debug': True}\n",
    "surrogate = topmodel.MLPSurrogate(config=config)\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0],\n",
    "            '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[1].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0])\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0])\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surrogate.predict(embeddings)\n",
    "assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "\n",
    "df_results['pred_OHE_MLP'] = y_pred\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding-based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Embedding and splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choices = 'esmc'  # 'esm2', 'esmc'\n",
    "\n",
    "if model_choices == 'esm2':\n",
    "    base_model = ESM2(model_path='/data/users/kgeorge/workspace/esm2/checkpoints/esm2_t33_650M_UR50D.pt', device='gpu')\n",
    "elif model_choices == 'esmc':\n",
    "    base_model = ESMCLM(name='esmc_600m', device='gpu')\n",
    "else:\n",
    "    raise ValueError('model not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_choice = 'concat' # 'mean', 'concat'\n",
    "\n",
    "if embedding_choice == 'mean':\n",
    "    embeddings = base_model.get_embeddings_mean(df['seq'])\n",
    "elif embedding_choice == 'concat':\n",
    "    embeddings = base_model.get_embeddings_flatten(df['seq'])\n",
    "else:\n",
    "    raise ValueError('model not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, test_mask = get_split_mask(df, omit_zero=False)\n",
    "\n",
    "X_train = embeddings[train_mask]\n",
    "X_test = embeddings[test_mask]\n",
    "\n",
    "y_train = df.loc[train_mask, 'fitness_log'].to_numpy().astype(np.float32)\n",
    "y_test = df.loc[test_mask, 'fitness_log'].to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train {train_mask.sum()} test {test_mask.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = topmodel.RidgeSurrogate(alpha=1.0)\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0],\n",
    "            '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[1].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0])\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0])\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surrogate.predict(embeddings)\n",
    "assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "\n",
    "df_results[f'pred_{model_choices}_{embedding_choice}_ridge'] = y_pred\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = topmodel.RFSurrogate()\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0],\n",
    "            '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[1].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0])\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0])\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surrogate.predict(embeddings)\n",
    "assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "\n",
    "df_results[f'pred_{model_choices}_{embedding_choice}_RF'] = y_pred\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'input layer shape: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'layers': [1152, 512, 1], \n",
    "        'epoch': 300, \n",
    "        'batch_size': 16,\n",
    "        'patience': 200,\n",
    "        'early_stopping': True,\n",
    "        'lr': 1e-3,\n",
    "        'print_every_n_epoch': 10,\n",
    "        'debug': True}\n",
    "surrogate = topmodel.MLPSurrogate(config=config)\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0],\n",
    "            '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[1].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0])\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0])\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surrogate.predict(embeddings)\n",
    "assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "\n",
    "df_results[f'pred_{model_choices}_{embedding_choice}_MLP'] = y_pred\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Shot PLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choices = 'esmc'\n",
    "\n",
    "if model_choices == 'esm2':\n",
    "    base_model = ESM2(model_path='/data/users/kgeorge/workspace/esm2/checkpoints/esm2_t33_650M_UR50D.pt', device='gpu')\n",
    "elif model_choices == 'esmc':\n",
    "    base_model = ESMCLM(name='esmc_600m', device='gpu')\n",
    "else:\n",
    "    raise ValueError('model not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_sequence = df.loc[df['name'] == 'WT', 'seq'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_method = 'masked_marginal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    mt_sequence = row['seq']\n",
    "\n",
    "    if zero_shot_method == 'wt_marginal':\n",
    "        score, n_muts = base_model.get_wildtype_marginal(mt_sequence, wt_sequence)\n",
    "        assert n_muts == row['n_mut']\n",
    "    elif zero_shot_method == 'masked_marginal':\n",
    "        score, n_muts = base_model.get_masked_marginal(mt_sequence, wt_sequence)\n",
    "        assert n_muts == row['n_mut']\n",
    "    elif zero_shot_method == 'pseudolikelihood':\n",
    "        score = base_model.pseudolikelihood(mt_sequence)\n",
    "    else:\n",
    "        raise ValueError('method not found')\n",
    "\n",
    "    y_pred.append(score)\n",
    "\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, test_mask = get_split_mask(df, omit_zero=False)\n",
    "\n",
    "y = df['fitness_log'].to_numpy().astype(np.float32)\n",
    "\n",
    "y_train = y[train_mask]\n",
    "y_test = y[test_mask]\n",
    "\n",
    "y_train_pred = y_pred[train_mask]\n",
    "y_test_pred = y_pred[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0],\n",
    "            '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[1].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0])\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test[df.loc[test_mask, 'fitness_raw'] > 0], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0])\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_pred.shape[0] == df_results.shape[0]\n",
    "\n",
    "df_results[f'pred_{model_choices}_{zero_shot_method}'] = y_pred\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1821475 || all params: 1303439469 || trainable%: 0.14\n"
     ]
    }
   ],
   "source": [
    "model_choices = 'esm2'\n",
    "\n",
    "config={'epoch': 100, \n",
    "        'batch_size': 8,\n",
    "        'lambda': 0.1,\n",
    "        'accumulate_batch_size': 32,\n",
    "        'patience': 20,\n",
    "        'early_stopping': False,\n",
    "        'lr': 1e-3,\n",
    "        'print_every_n_epoch': 1,\n",
    "        'device': 'gpu'}\n",
    "\n",
    "if model_choices == 'esmc':\n",
    "    surrogate = ESMCLoraRegression(name='esmc_600m', config=config)\n",
    "elif model_choices == 'esm2':\n",
    "    surrogate = ESM2LoraRegression(model_path='/data/users/kgeorge/workspace/esm2/checkpoints/esm2_t33_650M_UR50D.pt', config=config)\n",
    "\n",
    "surrogate.print_trainable_parameters(surrogate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESM2LoraRegression(\n",
       "  (basemodel): ESM2(\n",
       "    (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "    (layers): ModuleList(\n",
       "      (0-32): 33 x TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): lora.Linear(\n",
       "            (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (q_proj): lora.Linear(\n",
       "            (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (rot_emb): RotaryEmbedding()\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (contact_head): ContactPredictionHead(\n",
       "      (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "    (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    (lm_head): RobertaLMHead(\n",
       "      (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (model_reg): ESM2(\n",
       "    (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "    (layers): ModuleList(\n",
       "      (0-32): 33 x TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (rot_emb): RotaryEmbedding()\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (contact_head): ContactPredictionHead(\n",
       "      (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "    (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    (lm_head): RobertaLMHead(\n",
       "      (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (model): PeftModel(\n",
       "    (base_model): LoraModel(\n",
       "      (model): ESM2(\n",
       "        (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "        (layers): ModuleList(\n",
       "          (0-32): 33 x TransformerLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (rot_emb): RotaryEmbedding()\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (contact_head): ContactPredictionHead(\n",
       "          (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "          (activation): Sigmoid()\n",
       "        )\n",
       "        (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (lm_head): RobertaLMHead(\n",
       "          (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp): Linear(in_features=1280, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, test_mask = get_split_mask(df, omit_zero=False)\n",
    "\n",
    "df_train = df[train_mask]\n",
    "df_test = df[test_mask]\n",
    "\n",
    "y_train = df_train['fitness_log'].to_numpy().astype(np.float32)\n",
    "y_test = df_test['fitness_log'].to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A2000 12GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /nethome/kgeorge/workspace/DomainPrediction/src/fitness_prediction/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type      | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | basemodel | ESM2      | 652 M  | train\n",
      "1 | model_reg | ESM2      | 651 M  | eval \n",
      "2 | model     | PeftModel | 652 M  | train\n",
      "3 | mlp       | Linear    | 1.3 K  | train\n",
      "------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "1.3 B     Non-trainable params\n",
      "1.3 B     Total params\n",
      "5,213.758 Total estimated model params size (MB)\n",
      "/nethome/kgeorge/miniconda3/envs/workspace-esm/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/nethome/kgeorge/miniconda3/envs/workspace-esm/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/nethome/kgeorge/miniconda3/envs/workspace-esm/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0: train loss: 38.60412086759295 mse loss: 38.60412086759295 kl div 0.0 val loss: 19.933925449848175 mse loss: 19.91361966729164 kl div 0.20305811241269112\n",
      "Epoch: 1: train loss: 37.355418750217986 mse loss: 37.305528095790315 kl div 0.4989001750946045 val loss: 19.424771547317505 mse loss: 19.39489358663559 kl div 0.29877183586359024\n",
      "Epoch: 2: train loss: 37.13044221060617 mse loss: 37.000881740025115 kl div 1.2956079244613647 val loss: 18.917054548859596 mse loss: 18.86837165057659 kl div 0.4868326261639595\n",
      "Epoch: 3: train loss: 35.45123423848833 mse loss: 35.31932732037136 kl div 1.319065979548863 val loss: 18.400584876537323 mse loss: 18.333707958459854 kl div 0.6687624007463455\n",
      "Epoch: 4: train loss: 35.68491983413696 mse loss: 35.562799317496165 kl div 1.2212047236306327 val loss: 17.90158075094223 mse loss: 17.79703262448311 kl div 1.045479103922844\n",
      "Epoch: 5: train loss: 34.46531610829489 mse loss: 34.33633404118674 kl div 1.28981990473611 val loss: 17.402997888624668 mse loss: 17.25207857787609 kl div 1.5091971158981323\n",
      "Epoch: 6: train loss: 34.1514071055821 mse loss: 34.00374892779759 kl div 1.4765857287815638 val loss: 16.899034410715103 mse loss: 16.699278384447098 kl div 1.9975633323192596\n",
      "Epoch: 7: train loss: 32.840932164873394 mse loss: 32.66733237675258 kl div 1.7359999418258667 val loss: 16.378553107380867 mse loss: 16.126948174089193 kl div 2.5160478353500366\n",
      "Epoch: 8: train loss: 32.49245161669595 mse loss: 32.29319650786264 kl div 1.992550185748509 val loss: 15.839262589812279 mse loss: 15.527712686918676 kl div 3.115500509738922\n",
      "Epoch: 9: train loss: 31.08111354282924 mse loss: 30.857594762529647 kl div 2.235190851347787 val loss: 15.24253748357296 mse loss: 14.866923775523901 kl div 3.756140947341919\n",
      "Epoch: 10: train loss: 30.861878190721786 mse loss: 30.597386802945817 kl div 2.6449079513549805 val loss: 14.61031959950924 mse loss: 14.155766066163778 kl div 4.545535445213318\n",
      "Epoch: 11: train loss: 29.604876382010325 mse loss: 29.275998864855087 kl div 3.288770777838571 val loss: 14.317974746227264 mse loss: 13.482335537672043 kl div 8.356389045715332\n",
      "Epoch: 12: train loss: 28.47546931675502 mse loss: 27.518953323364258 kl div 9.565165655953544 val loss: 13.582566797733307 mse loss: 13.065675526857376 kl div 5.168910980224609\n",
      "Epoch: 13: train loss: 26.8936105966568 mse loss: 26.47691900389535 kl div 4.166913986206055 val loss: 13.289690345525742 mse loss: 12.762843817472458 kl div 5.26846706867218\n",
      "Epoch: 14: train loss: 25.480311189379012 mse loss: 25.048032964978898 kl div 4.32278094972883 val loss: 13.107379078865051 mse loss: 12.560632348060608 kl div 5.467464447021484\n",
      "Epoch: 15: train loss: 25.095206260681152 mse loss: 24.63861554009574 kl div 4.56590257372175 val loss: 13.022680759429932 mse loss: 12.455235302448273 kl div 5.674457550048828\n",
      "Epoch: 16: train loss: 24.13061032976423 mse loss: 23.651889664786204 kl div 4.787201881408691 val loss: 13.089893817901611 mse loss: 12.525565087795258 kl div 5.643289923667908\n",
      "Epoch: 17: train loss: 23.52870069231306 mse loss: 23.04260676247733 kl div 4.86093943459647 val loss: 13.301280736923218 mse loss: 12.748053908348083 kl div 5.532266020774841\n",
      "Epoch: 18: train loss: 23.178698812212264 mse loss: 22.696107183183944 kl div 4.825910806655884 val loss: 13.51285207271576 mse loss: 12.982495307922363 kl div 5.303562045097351\n",
      "Epoch: 19: train loss: 23.438308102743967 mse loss: 22.974971498761857 kl div 4.633365256445749 val loss: 13.673288941383362 mse loss: 13.152832508087158 kl div 5.20456326007843\n",
      "Epoch: 20: train loss: 23.042472090039933 mse loss: 22.59270770209176 kl div 4.497646161488125 val loss: 13.623457908630371 mse loss: 13.099678635597229 kl div 5.237795352935791\n",
      "Epoch: 21: train loss: 23.22256898880005 mse loss: 22.776772362845286 kl div 4.4579676900591165 val loss: 13.514894366264343 mse loss: 12.99738883972168 kl div 5.17505419254303\n",
      "Epoch: 22: train loss: 21.913660526275635 mse loss: 21.48344326019287 kl div 4.302171264375959 val loss: 13.414758920669556 mse loss: 12.915579676628113 kl div 4.99179083108902\n",
      "Epoch: 23: train loss: 21.828394412994385 mse loss: 21.422668933868408 kl div 4.057254212243216 val loss: 13.407509088516235 mse loss: 12.935961127281189 kl div 4.715478241443634\n",
      "Epoch: 24: train loss: 21.47940022604806 mse loss: 21.102304799216135 kl div 3.770951271057129 val loss: 13.51983368396759 mse loss: 13.073373794555664 kl div 4.464594066143036\n",
      "Epoch: 25: train loss: 20.664410182407924 mse loss: 20.304314919880458 kl div 3.600949662072318 val loss: 13.721301198005676 mse loss: 13.290810942649841 kl div 4.304901301860809\n",
      "Epoch: 26: train loss: 20.11399439402989 mse loss: 19.76042263848441 kl div 3.5357154437473843 val loss: 13.746017694473267 mse loss: 13.329681038856506 kl div 4.163364946842194\n",
      "Epoch: 27: train loss: 20.020331110273087 mse loss: 19.67394651685442 kl div 3.463846036366054 val loss: 13.411334037780762 mse loss: 13.010292530059814 kl div 4.0104159116744995\n",
      "Epoch: 28: train loss: 19.472146238599503 mse loss: 19.13665751048497 kl div 3.354888779776437 val loss: 12.96617066860199 mse loss: 12.577465951442719 kl div 3.887048661708832\n",
      "Epoch: 29: train loss: 18.558425154004777 mse loss: 18.233229569026403 kl div 3.2519537721361433 val loss: 12.700380444526672 mse loss: 12.318914532661438 kl div 3.8146625757217407\n",
      "Epoch: 30: train loss: 18.37343692779541 mse loss: 18.053669793265207 kl div 3.197672060557774 val loss: 12.677153587341309 mse loss: 12.303836405277252 kl div 3.7331730723381042\n",
      "Epoch: 31: train loss: 17.574179444994247 mse loss: 17.25416442326137 kl div 3.2001475266047885 val loss: 12.852810978889465 mse loss: 12.484149813652039 kl div 3.686612367630005\n",
      "Epoch: 32: train loss: 16.94946472985404 mse loss: 16.62806122643607 kl div 3.214035749435425 val loss: 12.929013848304749 mse loss: 12.565376877784729 kl div 3.636366605758667\n",
      "Epoch: 33: train loss: 16.1970089163099 mse loss: 15.880990028381348 kl div 3.1601861885615756 val loss: 12.208643317222595 mse loss: 11.851900100708008 kl div 3.567429482936859\n",
      "Epoch: 34: train loss: 14.959472826548986 mse loss: 14.656995194298881 kl div 3.0247757775442943 val loss: 11.223142385482788 mse loss: 10.869932651519775 kl div 3.5320966243743896\n",
      "Epoch: 35: train loss: 14.178747177124023 mse loss: 13.878787977354866 kl div 2.9995927129473006 val loss: 10.51371830701828 mse loss: 10.156918287277222 kl div 3.5680012106895447\n",
      "Epoch: 36: train loss: 13.319786412375313 mse loss: 13.009118284497942 kl div 3.1066813468933105 val loss: 10.291499614715576 mse loss: 9.92393273115158 kl div 3.6756693720817566\n",
      "Epoch: 37: train loss: 12.44557751928057 mse loss: 12.12381134714399 kl div 3.2176624706813266 val loss: 10.241727769374847 mse loss: 9.871113896369934 kl div 3.7061386704444885\n",
      "Epoch: 38: train loss: 12.14299760546003 mse loss: 11.81955429485866 kl div 3.2344323226383755 val loss: 10.990375995635986 mse loss: 10.615180969238281 kl div 3.7519545555114746\n",
      "Epoch: 39: train loss: 11.379607796669006 mse loss: 11.057963388306755 kl div 3.2164426190512523 val loss: 10.61614316701889 mse loss: 10.24796575307846 kl div 3.6817760467529297\n",
      "Epoch: 40: train loss: 11.21635273524693 mse loss: 10.83716538974217 kl div 3.7918755326952254 val loss: 11.162577867507935 mse loss: 10.79736340045929 kl div 3.652145802974701\n",
      "Epoch: 41: train loss: 10.207759686878749 mse loss: 9.888378705297198 kl div 3.193810905729021 val loss: 10.965840220451355 mse loss: 10.606029093265533 kl div 3.5981128811836243\n",
      "Epoch: 42: train loss: 9.82488123008183 mse loss: 9.514739343098231 kl div 3.1014182567596436 val loss: 10.665308952331543 mse loss: 10.308827877044678 kl div 3.5648111701011658\n",
      "Epoch: 43: train loss: 9.428018638065883 mse loss: 9.121691175869532 kl div 3.063275098800659 val loss: 10.809811472892761 mse loss: 10.45464015007019 kl div 3.5517160892486572\n",
      "Epoch: 44: train loss: 9.129244191305977 mse loss: 8.826208080564227 kl div 3.0303612777165005 val loss: 10.98407793045044 mse loss: 10.629065573215485 kl div 3.5501222014427185\n",
      "Epoch: 45: train loss: 8.662404469081334 mse loss: 8.363391092845372 kl div 2.9901321615491594 val loss: 10.982133328914642 mse loss: 10.6279858648777 kl div 3.5414721965789795\n",
      "Epoch: 46: train loss: 8.214996474129814 mse loss: 7.920441661562238 kl div 2.9455499989645824 val loss: 10.908419638872147 mse loss: 10.556222289800644 kl div 3.5219775438308716\n",
      "Epoch: 47: train loss: 7.840553079332624 mse loss: 7.551886439323425 kl div 2.886665548597063 val loss: 10.898559808731079 mse loss: 10.548038274049759 kl div 3.5052137970924377\n",
      "Epoch: 48: train loss: 7.5290253502982 mse loss: 7.246739319392613 kl div 2.822859900338309 val loss: 11.210790395736694 mse loss: 10.861166954040527 kl div 3.496236562728882\n",
      "Epoch: 49: train loss: 7.432525413376944 mse loss: 7.156337874276297 kl div 2.761875186647688 val loss: 11.375594526529312 mse loss: 11.029837191104889 kl div 3.4575729370117188\n",
      "Epoch: 50: train loss: 6.89864570753915 mse loss: 6.629425287246704 kl div 2.6922031811305454 val loss: 11.437581211328506 mse loss: 11.097761005163193 kl div 3.398197889328003\n",
      "Epoch: 51: train loss: 6.503673400197711 mse loss: 6.240437286240714 kl div 2.6323623657226562 val loss: 11.540298789739609 mse loss: 11.204197078943253 kl div 3.3610183000564575\n",
      "Epoch: 52: train loss: 6.268154893602643 mse loss: 6.008346012660435 kl div 2.598088264465332 val loss: 11.785359263420105 mse loss: 11.451494574546814 kl div 3.3386459946632385\n",
      "Epoch: 53: train loss: 6.152682866368975 mse loss: 5.894282613481794 kl div 2.584003448486328 val loss: 10.90516746044159 mse loss: 10.57816457748413 kl div 3.2700321674346924\n",
      "Epoch: 54: train loss: 6.363043427467346 mse loss: 6.101704120635986 kl div 2.613393885748727 val loss: 11.985991358757019 mse loss: 11.660410687327385 kl div 3.255810558795929\n",
      "Epoch: 55: train loss: 5.387742825916836 mse loss: 5.1233269316809515 kl div 2.6441591126578197 val loss: 12.387500613927841 mse loss: 12.065290734171867 kl div 3.2221017479896545\n",
      "Epoch: 56: train loss: 6.423830100468227 mse loss: 6.161134924207415 kl div 2.626951592309134 val loss: 9.766921162605286 mse loss: 9.455256283283234 kl div 3.1166497468948364\n",
      "Epoch: 57: train loss: 6.433784144265311 mse loss: 6.032999004636492 kl div 4.007852349962507 val loss: 7.5574010014534 mse loss: 7.251455307006836 kl div 3.059458017349243\n",
      "Epoch: 58: train loss: 6.900573253631592 mse loss: 6.586624894823347 kl div 3.139483860560826 val loss: 9.755274146795273 mse loss: 9.454077333211899 kl div 3.011972188949585\n",
      "Epoch: 59: train loss: 5.9486421176365445 mse loss: 5.691612311771938 kl div 2.5702973093305315 val loss: 11.333892673254013 mse loss: 11.035297140479088 kl div 2.9859527945518494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60: train loss: 5.9486421176365445 val loss: 11.333892673254013\n"
     ]
    }
   ],
   "source": [
    "surrogate.trainmodel(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:03<00:00, 15.08it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 15.10it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_pred = surrogate.predict(df_train['seq'])\n",
    "y_test_pred = surrogate.predict(df_test['seq'])\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test[df.loc[test_mask, 'fitness_raw'] > 0.1], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0.1],\n",
    "            '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[1].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test[df.loc[test_mask, 'fitness_raw'] > 0.1], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0.1])\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test[df.loc[test_mask, 'fitness_raw'] > 0.1], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0.1])\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, ci_lower, ci_upper, p_value, *_ =  get_spearmanr_bootstrap(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.56, 0.27, 0.8, 0.001)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr, ci_lower, ci_upper, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surrogate.predict(df['seq'])\n",
    "assert y_pred.shape[0] == df_results.shape[0]\n",
    "\n",
    "df_results[f'pred_{model_choices}_regfit'] = y_pred\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrastive Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choices = 'esmc'\n",
    "\n",
    "config={'epoch': 60, \n",
    "        'batch_size': 8,\n",
    "        'lambda': 0.1,\n",
    "        'accumulate_batch_size': 32,\n",
    "        'patience': 20,\n",
    "        'early_stopping': False,\n",
    "        'model_checkpoint': True,\n",
    "        'lr': 5e-4,\n",
    "        'print_every_n_epoch': 1,\n",
    "        'use_seq_head': True,\n",
    "        'device': 'gpu'}\n",
    "\n",
    "if model_choices == 'esmc':\n",
    "    surrogate = ESMCConFit(name='esmc_600m', config=config)\n",
    "elif model_choices == 'esm2':\n",
    "    surrogate = ESM2ConFit(model_path='/data/users/kgeorge/workspace/esm2/checkpoints/esm2_t33_650M_UR50D.pt', config=config)\n",
    "\n",
    "surrogate.print_trainable_parameters(surrogate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, pm in surrogate.model.named_parameters():\n",
    "    if pm.requires_grad:\n",
    "        print(name, pm.requires_grad)\n",
    "    # print(name, pm.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_sequence = df.loc[df['name'] == 'WT', 'seq'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, test_mask = get_split_mask(df, omit_zero=False)\n",
    "\n",
    "df_train = df[train_mask]\n",
    "df_test = df[test_mask]\n",
    "\n",
    "y_train = df_train['fitness_log'].to_numpy().astype(np.float32)\n",
    "y_test = df_test['fitness_log'].to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.config['lr'] = 1e-4\n",
    "surrogate.config['epoch'] = 300\n",
    "surrogate.trainmodel(df_train, wt_sequence, val=df_test[df_test['fitness_raw'] > 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.load_state_dict(torch.load(surrogate.trainer.checkpoint_callback.best_model_path)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(df_train['seq'], wt_sequence)\n",
    "y_test_pred = surrogate.predict(df_test['seq'], wt_sequence)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test[df.loc[test_mask, 'fitness_raw'] > 0.1], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0.1],\n",
    "            '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[1].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test[df.loc[test_mask, 'fitness_raw'] > 0.1], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0.1])\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test[df.loc[test_mask, 'fitness_raw'] > 0.1], y_test_pred[df.loc[test_mask, 'fitness_raw'] > 0.1])\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = surrogate.predict(df['seq'], wt_sequence)\n",
    "# assert y_pred.shape[0] == df_results.shape[0]\n",
    "\n",
    "# df_results[f'pred_{model_choices}_confit'] = y_pred\n",
    "# df_results.to_csv(results_file, index=False)\n",
    "\n",
    "# df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace-esm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
