{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DomainPrediction.utils import helper\n",
    "from DomainPrediction.eval import metrics\n",
    "from DomainPrediction.al import top_model as topmodel\n",
    "from DomainPrediction.al.embeddings import one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = os.environ['CONDA_DEFAULT_ENV']\n",
    "if env == 'workspace':\n",
    "    sys.path.append('../../esm')\n",
    "    from DomainPrediction.esm.esmc import ESMCLM\n",
    "    from DomainPrediction.al.finetuning import ESMCLoraRegression, ESMCConFit\n",
    "elif env == 'workspace-esm':\n",
    "    from DomainPrediction.esm.esm2 import ESM2\n",
    "    from DomainPrediction.al.finetuning import ESM2LoraRegression, ESM2ConFit\n",
    "else:\n",
    "    raise Exception('I designed this for my envs. Feel free to modify accordingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/nethome/kgeorge/workspace/DomainPrediction/Data/fitness_prediction/GB1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(data_path, 'dataset_gb1.csv')\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = os.path.join(data_path, 'results_gb1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(results_file):\n",
    "    df_results = pd.read_csv(results_file)\n",
    "else:\n",
    "    df_results = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_results.columns[df_results.columns.str.contains('pred')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_mask(df, omit_zero=False):\n",
    "    if omit_zero:\n",
    "        train_mask = (df['split_id'] == 2) & (df['fitness_raw'] != 0)\n",
    "    else:\n",
    "        train_mask = (df['split_id'] == 2)\n",
    "\n",
    "    val_mask = df['split_id'] == 1\n",
    "    test_mask = df['split_id'] == 0\n",
    "\n",
    "    return train_mask, val_mask, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spearmanr_bootstrap(a, b, n=1000, ci = 95):\n",
    "    assert type(a) == type(b) == np.ndarray\n",
    "    assert len(a) == len(b)\n",
    "    corr = []\n",
    "    p_values = []\n",
    "    np.random.seed(0)\n",
    "    for _ in range(n):\n",
    "        indices = np.random.choice(len(a), size=len(a), replace=True)\n",
    "        res = stats.spearmanr(a[indices], b[indices])\n",
    "        \n",
    "        if not np.isnan(res.statistic):\n",
    "            corr.append(res.statistic)\n",
    "            p_values.append(res.pvalue)\n",
    "\n",
    "    ci_lower, ci_upper = np.percentile(corr, [100-ci, ci]) \n",
    "    # stats.t.interval(confidence=ci, df=len(corr)-1, loc=np.mean(corr), scale=np.std(corr))\n",
    "    mean_corr = np.mean(corr)\n",
    "    p_value = np.mean(np.array(corr) < 0)\n",
    "\n",
    "    return round(mean_corr, 2), round(ci_lower, 2), round(ci_upper, 2), p_value, corr, p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### OHE based models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get embeddings and splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = one_hot_encode(df['seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, val_mask, test_mask = get_split_mask(df, omit_zero=False)\n",
    "\n",
    "X_train = embeddings[train_mask]\n",
    "X_val = embeddings[val_mask]\n",
    "X_test = embeddings[test_mask]\n",
    "\n",
    "y_train = df.loc[train_mask, 'fitness_log'].to_numpy().astype(np.float32)\n",
    "y_val = df.loc[val_mask, 'fitness_log'].to_numpy().astype(np.float32)\n",
    "y_test = df.loc[test_mask, 'fitness_log'].to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train {train_mask.sum()} val {val_mask.sum()} test {test_mask.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = topmodel.RidgeSurrogate(alpha=1.0)\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_val_pred = surrogate.predict(X_val)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "ax[1].set_title(f'Val \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surrogate.predict(embeddings)\n",
    "assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "\n",
    "df_results['pred_OHE_ridge'] = y_pred\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = topmodel.RFSurrogate()\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_val_pred = surrogate.predict(X_val)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "ax[1].set_title(f'Val \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surrogate.predict(embeddings)\n",
    "assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "\n",
    "df_results['pred_OHE_RF'] = y_pred\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'input layer shape: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'layers': [5300, 512, 1], \n",
    "        'epoch': 100, \n",
    "        'batch_size': 16,\n",
    "        'patience': 100,\n",
    "        'early_stopping': False,\n",
    "        'lr': 1e-3,\n",
    "        'print_every_n_epoch': 10,\n",
    "        'debug': True}\n",
    "surrogate = topmodel.MLPSurrogate(config=config)\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_val_pred = surrogate.predict(X_val)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "ax[1].set_title(f'Val \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surrogate.predict(embeddings)\n",
    "assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "\n",
    "df_results['pred_OHE_MLP'] = y_pred\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Embedding-based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Embedding and splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choices = 'esmc'  # 'esm2', 'esmc'\n",
    "\n",
    "if model_choices == 'esm2':\n",
    "    base_model = ESM2(model_path='/data/users/kgeorge/workspace/esm2/checkpoints/esm2_t33_650M_UR50D.pt', device='gpu')\n",
    "elif model_choices == 'esmc':\n",
    "    base_model = ESMCLM(name='esmc_600m', device='gpu')\n",
    "else:\n",
    "    raise ValueError('model not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_choice = 'concat' # or concat\n",
    "\n",
    "if embedding_choice == 'mean':\n",
    "    embeddings = base_model.get_embeddings_mean(df['seq'])\n",
    "elif embedding_choice == 'concat':\n",
    "    embeddings = base_model.get_embeddings_flatten(df['seq'])\n",
    "else:\n",
    "    raise ValueError('model not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, val_mask, test_mask = get_split_mask(df, omit_zero=False)\n",
    "\n",
    "X_train = embeddings[train_mask]\n",
    "X_val = embeddings[val_mask]\n",
    "X_test = embeddings[test_mask]\n",
    "\n",
    "y_train = df.loc[train_mask, 'fitness_log'].to_numpy().astype(np.float32)\n",
    "y_val = df.loc[val_mask, 'fitness_log'].to_numpy().astype(np.float32)\n",
    "y_test = df.loc[test_mask, 'fitness_log'].to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train {train_mask.sum()} val {val_mask.sum()} test {test_mask.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = topmodel.RidgeSurrogate(alpha=1.0)\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_val_pred = surrogate.predict(X_val)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "ax[1].set_title(f'Val \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surrogate.predict(embeddings)\n",
    "assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "\n",
    "df_results[f'pred_{model_choices}_{embedding_choice}_ridge'] = y_pred\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = topmodel.RFSurrogate()\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_val_pred = surrogate.predict(X_val)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "ax[1].set_title(f'Val \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surrogate.predict(embeddings)\n",
    "assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "\n",
    "df_results[f'pred_{model_choices}_{embedding_choice}_RF'] = y_pred\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'input layer shape: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'layers': [1152, 512, 1], \n",
    "        'epoch': 300, \n",
    "        'batch_size': 16,\n",
    "        'patience': 200,\n",
    "        'early_stopping': True,\n",
    "        'lr': 1e-4,\n",
    "        'print_every_n_epoch': 10,\n",
    "        'debug': True}\n",
    "surrogate = topmodel.MLPSurrogate(config=config)\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_val_pred = surrogate.predict(X_val)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "ax[1].set_title(f'Val \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surrogate.predict(embeddings)\n",
    "assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "\n",
    "df_results[f'pred_{model_choices}_{embedding_choice}_MLP'] = y_pred\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Zero-Shot PLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choices = 'esmc'\n",
    "\n",
    "if model_choices == 'esm2':\n",
    "    base_model = ESM2(model_path='/data/users/kgeorge/workspace/esm2/checkpoints/esm2_t33_650M_UR50D.pt', device='gpu')\n",
    "elif model_choices == 'esmc':\n",
    "    base_model = ESMCLM(name='esmc_600m', device='gpu')\n",
    "else:\n",
    "    raise ValueError('model not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_sequence = helper.read_fasta(os.path.join(data_path, 'GB1_WT.fasta'), mode='str')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_method = 'masked_marginal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    mt_sequence = row['seq']\n",
    "\n",
    "    if zero_shot_method == 'wt_marginal':\n",
    "        score, n_muts = base_model.get_wildtype_marginal(mt_sequence, wt_sequence)\n",
    "        assert n_muts == row['n_mut']\n",
    "    elif zero_shot_method == 'masked_marginal':\n",
    "        score, n_muts = base_model.get_masked_marginal(mt_sequence, wt_sequence)\n",
    "        assert n_muts == row['n_mut']\n",
    "    elif zero_shot_method == 'pseudolikelihood':\n",
    "        score = base_model.pseudolikelihood(mt_sequence)\n",
    "    else:\n",
    "        raise ValueError('method not found')\n",
    "\n",
    "    y_pred.append(score)\n",
    "\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, val_mask, test_mask = get_split_mask(df, omit_zero=False)\n",
    "\n",
    "y = df['fitness_log'].to_numpy().astype(np.float32)\n",
    "\n",
    "y_train = y[train_mask]\n",
    "y_val = y[val_mask]\n",
    "y_test = y[test_mask]\n",
    "\n",
    "y_train_pred = y_pred[train_mask]\n",
    "y_val_pred = y_pred[val_mask]\n",
    "y_test_pred = y_pred[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(7,3), layout='constrained')\n",
    "\n",
    "ax[0].plot(y, y_pred, '.', alpha=0.5)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y, y_pred)\n",
    "ax[0].set_title(f'Full Dataset \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mask = ~(df['fitness_raw'] == 0)\n",
    "ax[1].plot(y[mask], y_pred[mask], '.', alpha=0.5)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y[mask], y_pred[mask])\n",
    "ax[1].set_title(f'Omit fitness = 0 \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "ax[1].set_title(f'Val \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_pred.shape[0] == df_results.shape[0]\n",
    "\n",
    "df_results[f'pred_{model_choices}_{zero_shot_method}'] = y_pred\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Regression Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choices = 'esmc'  # 'esm2', 'esmc'\n",
    "\n",
    "config={'epoch': 50, \n",
    "        'batch_size': 8,\n",
    "        'lambda': 0.1,\n",
    "        'accumulate_batch_size': 32,\n",
    "        'patience': 20,\n",
    "        'early_stopping': False,\n",
    "        'lr': 1e-3,\n",
    "        'print_every_n_epoch': 1,\n",
    "        'device': 'gpu'}\n",
    "\n",
    "if model_choices == 'esmc':\n",
    "    surrogate = ESMCLoraRegression(name='esmc_600m', config=config)\n",
    "elif model_choices == 'esm2':\n",
    "    surrogate = ESM2LoraRegression(model_path='/data/users/kgeorge/workspace/esm2/checkpoints/esm2_t33_650M_UR50D.pt', config=config)\n",
    "\n",
    "surrogate.print_trainable_parameters(surrogate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, val_mask, test_mask = get_split_mask(df, omit_zero=False)\n",
    "\n",
    "df_train = df[train_mask]\n",
    "df_val = df[val_mask]\n",
    "df_test = df[test_mask]\n",
    "\n",
    "y_train = df_train['fitness_log'].to_numpy().astype(np.float32)\n",
    "y_val = df_val['fitness_log'].to_numpy().astype(np.float32)\n",
    "y_test = df_test['fitness_log'].to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.trainmodel(df_train, df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.load_state_dict(torch.load(surrogate.trainer.checkpoint_callback.best_model_path)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(df_train['seq'])\n",
    "y_val_pred = surrogate.predict(df_val['seq'])\n",
    "y_test_pred = surrogate.predict(df_test['seq'])\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "ax[1].set_title(f'Val \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surrogate.predict(df['seq'])\n",
    "assert y_pred.shape[0] == df_results.shape[0]\n",
    "\n",
    "df_results[f'pred_{model_choices}_regfit'] = y_pred\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrastive Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choices = 'esm2'  # 'esm2', 'esmc'\n",
    "\n",
    "config={'epoch': 60, \n",
    "        'batch_size': 32,\n",
    "        'lambda': 0.1,\n",
    "        'accumulate_batch_size': 32,\n",
    "        'patience': 20,\n",
    "        'early_stopping': False,\n",
    "        'model_checkpoint': True,\n",
    "        'lr': 5e-4,\n",
    "        'print_every_n_epoch': 1,\n",
    "        'use_seq_head': True,\n",
    "        'device': 'gpu'}\n",
    "\n",
    "if model_choices == 'esmc':\n",
    "    surrogate = ESMCConFit(name='esmc_600m', config=config)\n",
    "elif model_choices == 'esm2':\n",
    "    surrogate = ESM2ConFit(model_path='/data/users/kgeorge/workspace/esm2/checkpoints/esm2_t33_650M_UR50D.pt', config=config)\n",
    "\n",
    "surrogate.print_trainable_parameters(surrogate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_sequence = helper.read_fasta(os.path.join(data_path, 'GB1_WT.fasta'), mode='str')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, val_mask, test_mask = get_split_mask(df, omit_zero=False)\n",
    "\n",
    "df_train = df[train_mask]\n",
    "df_val = df[val_mask]\n",
    "df_test = df[test_mask]\n",
    "\n",
    "y_train = df_train['fitness_log'].to_numpy().astype(np.float32)\n",
    "y_val = df_val['fitness_log'].to_numpy().astype(np.float32)\n",
    "y_test = df_test['fitness_log'].to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.trainmodel(df_train, wt_sequence, val=df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surrogate.load_state_dict(torch.load(surrogate.trainer.checkpoint_callback.best_model_path)['state_dict'])\n",
    "# surrogate.load_state_dict(torch.load('/nethome/kgeorge/workspace/DomainPrediction/src/fitness_prediction/lightning_logs/version_2/checkpoints/best-checkpoint-epoch=37.ckpt')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(df_train['seq'], wt_sequence)\n",
    "y_val_pred = surrogate.predict(df_val['seq'], wt_sequence)\n",
    "y_test_pred = surrogate.predict(df_test['seq'], wt_sequence)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "ax[1].set_title(f'Val \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surrogate.predict(df['seq'], wt_sequence)\n",
    "assert y_pred.shape[0] == df_results.shape[0]\n",
    "\n",
    "df_results[f'pred_{model_choices}_confit'] = y_pred\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "df_results.columns[df_results.columns.str.contains('pred')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
