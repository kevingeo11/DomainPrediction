{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DomainPrediction.utils import helper\n",
    "from DomainPrediction.eval import metrics\n",
    "from DomainPrediction.al import top_model as topmodel\n",
    "from DomainPrediction.al.embeddings import one_hot_encode\n",
    "from DomainPrediction.protein.base import BaseProtein\n",
    "from DomainPrediction.utils.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../esm')\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import torch\n",
    "from esm.models.esm3 import ESM3\n",
    "from esm.sdk.api import ESMProtein, LogitsConfig, GenerationConfig, ESMProteinTensor\n",
    "from esm.utils.structure.protein_chain import ProteinChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esm.utils.generation import (\n",
    "    _stack_protein_tensors,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPO Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPOTrainer:\n",
    "    def __init__(self, model, model_ref, device='cpu') -> None:\n",
    "        self.device = device\n",
    "\n",
    "        # if self.device == 'gpu':\n",
    "        #     self.model = model.to(\"cuda:0\")\n",
    "        #     self.model_ref = model_ref.to(\"cuda:1\")\n",
    "        # else:\n",
    "        #     self.model = model.to(\"cpu\")\n",
    "        #     self.model_ref = model_ref.to(\"cpu\")\n",
    "\n",
    "        self.model = model\n",
    "        self.model_ref =  model_ref\n",
    "\n",
    "        self.model_ref.eval()\n",
    "        for pm in self.model_ref.parameters():\n",
    "            pm.requires_grad = False\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name in [\n",
    "                \"encoder.sequence_embed.weight\", \n",
    "                \"output_heads.sequence_head.0.weight\", \n",
    "                \"output_heads.sequence_head.0.bias\",\n",
    "                \"output_heads.sequence_head.2.weight\",\n",
    "                \"output_heads.sequence_head.2.bias\",\n",
    "                \"output_heads.sequence_head.3.weight\",\n",
    "                \"output_heads.sequence_head.3.bias\"\n",
    "            ]:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        ## need to add peft here ? Do we ?\n",
    "    \n",
    "    def print_trainable_parameters(self, model):\n",
    "        trainable_params = 0\n",
    "        all_param = 0\n",
    "        for _, param in model.named_parameters():\n",
    "            all_param += param.numel()\n",
    "            if param.requires_grad:\n",
    "                trainable_params += param.numel()\n",
    "        print(\n",
    "            f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
    "        )\n",
    "\n",
    "    def generate_sequences(self, sequence_prompt, structure_prompt, size, ref=False):\n",
    "        sequence_prediction_config = GenerationConfig(\n",
    "            track=\"sequence\", \n",
    "            num_steps=sequence_prompt.count(\"_\") // 2, \n",
    "            temperature=0.5\n",
    "        )\n",
    "        esm_protein = ESMProtein(sequence=sequence_prompt, coordinates=structure_prompt)\n",
    "        \n",
    "        generated_proteins = []\n",
    "        for _ in tqdm(range(size)):\n",
    "            generated_protein = self.model.generate(esm_protein, sequence_prediction_config)\n",
    "            generated_proteins.append(generated_protein.sequence)\n",
    "\n",
    "        return generated_proteins\n",
    "    \n",
    "    def create_dataset(self, sequence_prompt, structure_prompt, mask_positions, size):\n",
    "\n",
    "        generated_sequences = self.generate_sequences(sequence_prompt, structure_prompt, size)\n",
    "\n",
    "        dataset = []\n",
    "        for _seq in generated_sequences:\n",
    "            dataset.append({\n",
    "                'generated_sequence': _seq,\n",
    "                'masked_sequence': ''.join([s for _i, s in enumerate(_seq) if _i in mask_positions]),\n",
    "                'masked_positions': mask_positions, ## These are the same\n",
    "                'sequence_prompt': sequence_prompt, ## These are the same\n",
    "                'structure_prompt': structure_prompt, ## These are the same   \n",
    "            })\n",
    "\n",
    "        for item in dataset:\n",
    "            item['property'] = self.__get_n_mutations(item['masked_sequence'])\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    def get_mask_positions(self, sequence_prompt, mask_var='_'):\n",
    "        positions = []\n",
    "        for i in range(len(sequence_prompt)):\n",
    "            if sequence_prompt[i] == mask_var:\n",
    "                positions.append(i)\n",
    "\n",
    "        return np.array(positions)\n",
    "    \n",
    "    def __get_n_mutations(self, sequence):\n",
    "        base = 'APSEDAYPRATYEAPEGETEQLLAGIWMDLLQVDRVGRHDSFFELGGHSLLAVRLLGRLRQHGLGLQMRDLFEAPVLAELATRLRPYQPLEVPANGITPDTTVLTPEMLPLVTLS'\n",
    "        assert len(base) == len(sequence)\n",
    "\n",
    "        count = 0\n",
    "        for aa1, aa2 in zip(base, sequence):\n",
    "            if aa1 != aa2:\n",
    "                count += 1\n",
    "\n",
    "        return -1*count\n",
    "    \n",
    "    # def get_property_batch(self, batch):\n",
    "    #     for item in batch:\n",
    "    #         item['property'] = self.__get_n_mutations(item['masked_sequence'])\n",
    "\n",
    "    #     return batch\n",
    "    \n",
    "    def get_PLL(self, item, ref=False):\n",
    "        '''\n",
    "            We always feed in the sequence prompt\n",
    "            We get Log Prob(A_C) -  entire T region is masked\n",
    "        '''\n",
    "        proteins = [ESMProtein(sequence=item['sequence_prompt'], \n",
    "                        coordinates=item['structure_prompt'])]\n",
    "        \n",
    "        if ref:\n",
    "            input_tokens = [self.model_ref.encode(protein) for protein in proteins]\n",
    "            generated_tokens = self.model_ref.encode(ESMProtein(sequence=item['generated_sequence'], \n",
    "                                                        coordinates=item['structure_prompt']))\n",
    "        else:\n",
    "            input_tokens = [self.model.encode(protein) for protein in proteins]\n",
    "            generated_tokens = self.model.encode(ESMProtein(sequence=item['generated_sequence'], \n",
    "                                                        coordinates=item['structure_prompt']))\n",
    "        \n",
    "        \n",
    "        devices = set([t.device for t in input_tokens])\n",
    "        if len(devices) > 1:\n",
    "                raise AttributeError(f\"Input tokens on multiple devices {devices}\")\n",
    "        sequence_lengths = [len(tokens) for tokens in input_tokens]\n",
    "        assert len(set(sequence_lengths)) == 1\n",
    "        \n",
    "        if ref:\n",
    "            batched_tokens = _stack_protein_tensors(\n",
    "                    input_tokens, sequence_lengths, self.model_ref.tokenizers, self.model_ref.device\n",
    "                )\n",
    "        else:\n",
    "            batched_tokens = _stack_protein_tensors(\n",
    "                    input_tokens, sequence_lengths, self.model.tokenizers, self.model.device\n",
    "                )\n",
    "        \n",
    "        if batched_tokens.coordinates is None:\n",
    "            per_res_plddt = None\n",
    "        else:\n",
    "            # 1.0 if all coordinates at specific indices have valid non-nan values.\n",
    "            per_res_plddt = batched_tokens.coordinates.isfinite().all(dim=-1).any(dim=-1).float()\n",
    "\n",
    "        if ref:\n",
    "            assert model_ref.device == batched_tokens.device\n",
    "            with (torch.no_grad(),\n",
    "                torch.autocast(enabled=True, device_type=torch.device(batched_tokens.device).type, dtype=torch.bfloat16)):\n",
    "                output = self.model_ref.forward(\n",
    "                        sequence_tokens=batched_tokens.sequence,\n",
    "                        structure_tokens=batched_tokens.structure,\n",
    "                        ss8_tokens=batched_tokens.secondary_structure,\n",
    "                        sasa_tokens=batched_tokens.sasa,\n",
    "                        function_tokens=batched_tokens.function,\n",
    "                        residue_annotation_tokens=batched_tokens.residue_annotations,\n",
    "                        average_plddt=torch.tensor(1.0, device=batched_tokens.device),\n",
    "                        per_res_plddt=per_res_plddt,\n",
    "                        structure_coords=batched_tokens.coordinates,\n",
    "                        chain_id=None,\n",
    "                        sequence_id=None,\n",
    "                )\n",
    "        else:\n",
    "            assert model.device == batched_tokens.device\n",
    "            with (torch.autocast(enabled=True, device_type=torch.device(batched_tokens.device).type, dtype=torch.bfloat16)):\n",
    "                output = self.model.forward(\n",
    "                        sequence_tokens=batched_tokens.sequence,\n",
    "                        structure_tokens=batched_tokens.structure,\n",
    "                        ss8_tokens=batched_tokens.secondary_structure,\n",
    "                        sasa_tokens=batched_tokens.sasa,\n",
    "                        function_tokens=batched_tokens.function,\n",
    "                        residue_annotation_tokens=batched_tokens.residue_annotations,\n",
    "                        average_plddt=torch.tensor(1.0, device=batched_tokens.device),\n",
    "                        per_res_plddt=per_res_plddt,\n",
    "                        structure_coords=batched_tokens.coordinates,\n",
    "                        chain_id=None,\n",
    "                        sequence_id=None,\n",
    "                )\n",
    "        \n",
    "        log_prob = torch.log_softmax(output.sequence_logits, dim=-1)\n",
    "\n",
    "        masked_log_prob = log_prob[:, item['masked_positions'] + 1, generated_tokens.sequence[item['masked_positions'] + 1]]\n",
    "        pll = torch.sum(masked_log_prob)\n",
    "\n",
    "        # print(item['masked_sequence'])\n",
    "        print(generated_tokens.sequence[item['masked_positions'] + 1])\n",
    "        print(masked_log_prob)\n",
    "        # print(pll)\n",
    "\n",
    "        return pll\n",
    "         \n",
    "    def dpo_paired_loss(self, batch):\n",
    "\n",
    "        pll_policy = []\n",
    "        pll_ref = []\n",
    "        for item in batch:\n",
    "            pll_policy.append(self.get_PLL(item))\n",
    "            pll_ref.append(self.get_PLL(item, ref=True))\n",
    "            print(item['property'])\n",
    "\n",
    "        print([x['property'] for x in batch])\n",
    "        print(pll_policy)\n",
    "        print(pll_ref)\n",
    "\n",
    "        pll_ref = [x.to(self.model.device) for x in pll_ref]\n",
    "\n",
    "        print(pll_ref)\n",
    "\n",
    "        batch_size = len(batch)\n",
    "        assert batch_size > 1\n",
    "        beta = 0.01\n",
    "\n",
    "        loss = []\n",
    "\n",
    "        pairs_debug = []\n",
    "        for i in range(batch_size-1):\n",
    "            for j in range(1, batch_size):\n",
    "                if batch[i]['property'] > batch[j]['property'] + 0:\n",
    "                    loss_item = -torch.nn.functional.logsigmoid( beta * ((pll_policy[i] - pll_ref[i]) - (pll_policy[j] - pll_ref[j])) )\n",
    "                    # loss_item = -torch.nn.functional.logsigmoid( beta * ((pll_policy[i]) - (pll_policy[j])) )\n",
    "                    loss.append(loss_item)\n",
    "\n",
    "                    pairs_debug.append((batch[i]['property'], batch[j]['property'],\n",
    "                                        (pll_policy[i] - pll_ref[i]).item(), (pll_policy[j] - pll_ref[j]).item(),\n",
    "                                        loss_item.item()))\n",
    "                    \n",
    "                elif batch[j]['property'] > batch[i]['property'] + 0:\n",
    "                    loss_item = -torch.nn.functional.logsigmoid( beta * ((pll_policy[j] - pll_ref[j]) - (pll_policy[i] - pll_ref[i])) )\n",
    "                    # loss_item = -torch.nn.functional.logsigmoid( beta * ((pll_policy[j]) - (pll_policy[i])) )\n",
    "                    loss.append(loss_item)\n",
    "\n",
    "                    pairs_debug.append((batch[j]['property'], batch[i]['property'],\n",
    "                                        (pll_policy[j] - pll_ref[j]).item(), (pll_policy[i] - pll_ref[i]).item(),\n",
    "                                        loss_item.item()))\n",
    "                    \n",
    "        for _pair in pairs_debug:\n",
    "            print(f'pair :{_pair}')\n",
    "\n",
    "        if len(loss) > 0:\n",
    "            loss = torch.mean(torch.stack(loss))\n",
    "        else:\n",
    "            loss = torch.tensor(0.).to(self.model.device)\n",
    "                    \n",
    "        return loss\n",
    " \n",
    "    def train(self, sequence_prompt, structure_prompt):\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        self.print_trainable_parameters(self.model)\n",
    "        self.print_trainable_parameters(self.model_ref)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=1e-3,\n",
    "            betas=(0.9, 0.98),\n",
    "            eps=1e-8,\n",
    "            weight_decay=0.1,\n",
    "        )\n",
    "\n",
    "        mask_positions = self.get_mask_positions(sequence_prompt=sequence_prompt)\n",
    "\n",
    "        dataset = self.create_dataset(sequence_prompt, structure_prompt,\n",
    "                                      mask_positions, 10)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return dataset\n",
    "\n",
    "        # epochs = 100\n",
    "        # batch_size = 1\n",
    "        # for epoch in range(epochs):\n",
    "        #     optimizer.zero_grad()\n",
    "\n",
    "        #     # A, C = sequence_prompt.split('_'*115)\n",
    "        #     # base = 'APSEDAYPRATYEAPEGETEQLLAGIWMDLLQVDRVGRHDSFFELGGHSLLAVRLLGRLRQHGLGLQMRDLFEAPVLAELATRLRPYQPLEVPANGITPDTTVLTPEMLPLVTLS'\n",
    "        #     # batch_dataset.append({\n",
    "        #     #     'generated_sequence': A+base+C,\n",
    "        #     #     'masked_sequence': base,\n",
    "        #     #     'masked_positions': mask_positions, ## These are the same\n",
    "        #     #     'sequence_prompt': sequence_prompt, ## These are the same\n",
    "        #     #     'structure_prompt': structure_prompt ## These are the same  \n",
    "        #     # })\n",
    "\n",
    "        #     batch_dataset = self.get_property_batch(batch_dataset)\n",
    "            \n",
    "        #     print(f'epoch {epoch}: calculating loss')\n",
    "        #     loss = self.dpo_paired_loss(batch_dataset)\n",
    "        #     print(f'loss {loss.item()}')\n",
    "\n",
    "        #     if loss != 0:\n",
    "        #         print(f'epoch {epoch}: optimizer step')\n",
    "        #         loss.backward()\n",
    "        #         optimizer.step()\n",
    "\n",
    "        #     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein = ProteinChain.from_pdb('../../Data/gxps/gxps_ATC_AF.pdb')\n",
    "\n",
    "sequence_prompt = ''.join([protein[i].sequence if i in A_gxps_atc + C_gxps_atc else '_' for i in range(len(protein))])\n",
    "structure_prompt = torch.tensor(protein.atom37_positions)\n",
    "\n",
    "# structure_prompt = torch.tensor(protein.atom37_positions)[T_gxps_atc[0]-50:T_gxps_atc[-1]+50]\n",
    "# sequence_prompt = ''.join([s for i, s in enumerate(sequence_prompt) if i in list(range(T_gxps_atc[0]-50,T_gxps_atc[-1]+50))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sequence_prompt), sequence_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sequence_prompt) == structure_prompt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write script to check the availability of the GPUs and no of GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ESM3.from_pretrained(\"esm3_sm_open_v1\", device=torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ref = ESM3.from_pretrained(\"esm3_sm_open_v1\", torch.device('cuda:1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_trainer = DPOTrainer(model, model_ref, device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DISABLE_ITERATIVE_SAMPLING_TQDM\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dpo_trainer.train(sequence_prompt=sequence_prompt, structure_prompt=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(dataset):\n",
    "    \n",
    "    pair_dataset = []\n",
    "    for item_1 in batch[:-1]:\n",
    "        for item_2 in batch[1:]:\n",
    "            if item_1['property'] < item_2['property'] and item_1['log_likelihood'] < item_2['log_likelihood']:\n",
    "                pair_dataset.append((item_1, item_2))\n",
    "            elif item_1['property'] > item_2['property'] and item_1['log_likelihood'] > item_2['log_likelihood']:\n",
    "                pair_dataset.append((item_2, item_1))\n",
    "\n",
    "    # _, ax = plt.subplots(1, 2, figsize=(7, 3), layout='constrained')\n",
    "    # ax[0].hist([[item[0]['property'] for item in pair_dataset], \n",
    "    #             [item[1]['property'] for item in pair_dataset]], label=['pos', 'neg'])\n",
    "    # ax[1].hist([[item[0]['log_likelihood'] for item in pair_dataset],\n",
    "    #             [item[1]['log_likelihood'] for item in pair_dataset]], label=['pos', 'neg'])\n",
    "    # ax[0].legend()\n",
    "    # ax[1].legend()\n",
    "    # plt.show()\n",
    "\n",
    "    return pair_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
