{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DomainPrediction.utils import helper\n",
    "from DomainPrediction.eval import metrics\n",
    "from DomainPrediction.al import top_model as topmodel\n",
    "from DomainPrediction.al.embeddings import one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DomainPrediction.esm.esm2 import ESM2\n",
    "from DomainPrediction.al.confit import ESM2ConFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../esm')\n",
    "from DomainPrediction.esm.esm3 import ESM3LM\n",
    "from DomainPrediction.esm.esmc import ESMCLM\n",
    "from DomainPrediction.al.confit import ESMCConFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/nethome/kgeorge/workspace/DomainPrediction/Data/al_test_experiments/Tdomain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(data_path, 'dataset_2_tdomain.csv')\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>seq</th>\n",
       "      <th>fitness_raw</th>\n",
       "      <th>split_id</th>\n",
       "      <th>n_mut</th>\n",
       "      <th>fitness_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WT</td>\n",
       "      <td>APGEDAFARQAYQAPQGEIEIALATIWRELLNVEQVGRHDSFFALG...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESM1</td>\n",
       "      <td>APEDSSFPRPPYAAPEGEIEQTLAGIWMELLGVERVGRHDSFFALG...</td>\n",
       "      <td>0.982485</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>-0.017670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESM2</td>\n",
       "      <td>APSEDAYPRATYEAPEGETEQLLAGIWMDLLQVDRVGRHDSFFELG...</td>\n",
       "      <td>0.958725</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>-0.042151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESM3</td>\n",
       "      <td>APSEDSYPRPAYVAPEGPTEQLLAGIWQELLNVSKVGRDDSFFDLG...</td>\n",
       "      <td>0.035325</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>-3.343159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESM4</td>\n",
       "      <td>APEEASYPREPYVAPQGETEQLLASIWQELLGVERVGAGDNFFELG...</td>\n",
       "      <td>0.457921</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-0.781059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name                                                seq  fitness_raw  \\\n",
       "0    WT  APGEDAFARQAYQAPQGEIEIALATIWRELLNVEQVGRHDSFFALG...     1.000000   \n",
       "1  ESM1  APEDSSFPRPPYAAPEGEIEQTLAGIWMELLGVERVGRHDSFFALG...     0.982485   \n",
       "2  ESM2  APSEDAYPRATYEAPEGETEQLLAGIWMDLLQVDRVGRHDSFFELG...     0.958725   \n",
       "3  ESM3  APSEDSYPRPAYVAPEGPTEQLLAGIWQELLNVSKVGRDDSFFDLG...     0.035325   \n",
       "4  ESM4  APEEASYPREPYVAPQGETEQLLASIWQELLGVERVGAGDNFFELG...     0.457921   \n",
       "\n",
       "   split_id  n_mut  fitness_log  \n",
       "0         2      0     0.000000  \n",
       "1         2     44    -0.017670  \n",
       "2         0     45    -0.042151  \n",
       "3         2     46    -3.343159  \n",
       "4         2     43    -0.781059  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = os.path.join(data_path, 'results_2_tdomain_confit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(results_file):\n",
    "    df_results = pd.read_csv(results_file)\n",
    "else:\n",
    "    df_results = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>seq</th>\n",
       "      <th>fitness_raw</th>\n",
       "      <th>split_id</th>\n",
       "      <th>n_mut</th>\n",
       "      <th>fitness_log</th>\n",
       "      <th>pred_ESM650M_confit</th>\n",
       "      <th>pred_ESMC300M_confit</th>\n",
       "      <th>pred_ESMC600M_confit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WT</td>\n",
       "      <td>APGEDAFARQAYQAPQGEIEIALATIWRELLNVEQVGRHDSFFALG...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESM1</td>\n",
       "      <td>APEDSSFPRPPYAAPEGEIEQTLAGIWMELLGVERVGRHDSFFALG...</td>\n",
       "      <td>0.982485</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>-0.017670</td>\n",
       "      <td>3.345487</td>\n",
       "      <td>1.748047</td>\n",
       "      <td>-1.813965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESM2</td>\n",
       "      <td>APSEDAYPRATYEAPEGETEQLLAGIWMDLLQVDRVGRHDSFFELG...</td>\n",
       "      <td>0.958725</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>-0.042151</td>\n",
       "      <td>-3.205000</td>\n",
       "      <td>2.612305</td>\n",
       "      <td>5.303711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESM3</td>\n",
       "      <td>APSEDSYPRPAYVAPEGPTEQLLAGIWQELLNVSKVGRDDSFFDLG...</td>\n",
       "      <td>0.035325</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>-3.343159</td>\n",
       "      <td>-8.855375</td>\n",
       "      <td>-14.083740</td>\n",
       "      <td>-19.246704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESM4</td>\n",
       "      <td>APEEASYPREPYVAPQGETEQLLASIWQELLGVERVGAGDNFFELG...</td>\n",
       "      <td>0.457921</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-0.781059</td>\n",
       "      <td>-0.798962</td>\n",
       "      <td>-2.969727</td>\n",
       "      <td>-12.833252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name                                                seq  fitness_raw  \\\n",
       "0    WT  APGEDAFARQAYQAPQGEIEIALATIWRELLNVEQVGRHDSFFALG...     1.000000   \n",
       "1  ESM1  APEDSSFPRPPYAAPEGEIEQTLAGIWMELLGVERVGRHDSFFALG...     0.982485   \n",
       "2  ESM2  APSEDAYPRATYEAPEGETEQLLAGIWMDLLQVDRVGRHDSFFELG...     0.958725   \n",
       "3  ESM3  APSEDSYPRPAYVAPEGPTEQLLAGIWQELLNVSKVGRDDSFFDLG...     0.035325   \n",
       "4  ESM4  APEEASYPREPYVAPQGETEQLLASIWQELLGVERVGAGDNFFELG...     0.457921   \n",
       "\n",
       "   split_id  n_mut  fitness_log  pred_ESM650M_confit  pred_ESMC300M_confit  \\\n",
       "0         2      0     0.000000             0.000000              0.000000   \n",
       "1         2     44    -0.017670             3.345487              1.748047   \n",
       "2         0     45    -0.042151            -3.205000              2.612305   \n",
       "3         2     46    -3.343159            -8.855375            -14.083740   \n",
       "4         2     43    -0.781059            -0.798962             -2.969727   \n",
       "\n",
       "   pred_ESMC600M_confit  \n",
       "0              0.000000  \n",
       "1             -1.813965  \n",
       "2              5.303711  \n",
       "3            -19.246704  \n",
       "4            -12.833252  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pred_ESM650M_confit', 'pred_ESMC300M_confit', 'pred_ESMC600M_confit'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_results.columns[df_results.columns.str.contains('pred')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_mask(df, omit_zero=False):\n",
    "    if omit_zero:\n",
    "        train_mask = (df['split_id'] == 2) & (df['fitness_raw'] != 0)\n",
    "    else:\n",
    "        train_mask = (df['split_id'] == 2)\n",
    "\n",
    "    val_mask = df['split_id'] == 1\n",
    "    test_mask = df['split_id'].isin([0, 1])\n",
    "    # test_mask = df['split_id'] == 0\n",
    "\n",
    "    return train_mask, val_mask, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spearmanr_bootstrap(a, b, n=1000):\n",
    "    assert type(a) == type(b) == np.ndarray\n",
    "    assert len(a) == len(b)\n",
    "    corr = []\n",
    "    p_value = []\n",
    "    np.random.seed(0)\n",
    "    for _ in range(n):\n",
    "        indices = np.random.choice(len(a), size=len(a), replace=True)\n",
    "        res = stats.spearmanr(a[indices], b[indices])\n",
    "        \n",
    "        if not np.isnan(res.statistic):\n",
    "            corr.append(res.statistic)\n",
    "            p_value.append(res.pvalue)\n",
    "\n",
    "    ci_lower, ci_upper = np.percentile(corr, [5, 95]) \n",
    "    # stats.t.interval(confidence=0.95, df=len(corr)-1, loc=np.mean(corr), scale=np.std(corr))\n",
    "    mean_corr = np.mean(corr)\n",
    "\n",
    "    return round(mean_corr, 2), round(ci_lower, 2), round(ci_upper, 2), corr, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = one_hot_encode(df['seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, val_mask, test_mask = get_split_mask(df, omit_zero=False)\n",
    "\n",
    "X_train = embeddings[train_mask]\n",
    "X_val = embeddings[val_mask]\n",
    "X_test = embeddings[test_mask]\n",
    "\n",
    "# y_train = df.loc[train_mask, 'fitness_raw'].to_numpy().astype(np.float32)\n",
    "# y_val = df.loc[val_mask, 'fitness_raw'].to_numpy().astype(np.float32)\n",
    "# y_test = df.loc[test_mask, 'fitness_raw'].to_numpy().astype(np.float32)\n",
    "\n",
    "y_train = df.loc[train_mask, 'fitness_log'].to_numpy().astype(np.float32)\n",
    "y_val = df.loc[val_mask, 'fitness_log'].to_numpy().astype(np.float32)\n",
    "y_test = df.loc[test_mask, 'fitness_log'].to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = topmodel.RidgeSurrogate(alpha=1.0)\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_val_pred = surrogate.predict(X_val)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "ax[1].set_title(f'Val \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surrogate.predict(embeddings)\n",
    "assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "df_results['pred_OHE_ridge'] = y_pred\n",
    "\n",
    "mse = mean_squared_error(df_results['fitness_log'], df_results['pred_OHE_ridge'])\n",
    "corr = stats.spearmanr(df_results['fitness_log'], df_results['pred_OHE_ridge'])\n",
    "s_corr = round(corr.statistic, 2)\n",
    "print(f'mse : {str(round(mse, 2))} || spearman correlation = {s_corr}')\n",
    "\n",
    "df_results.to_csv(results_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = topmodel.RFSurrogate()\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_val_pred = surrogate.predict(X_val)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "ax[1].set_title(f'Val \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surrogate.predict(embeddings)\n",
    "assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "df_results['pred_OHE_RF'] = y_pred\n",
    "\n",
    "mse = mean_squared_error(df_results['fitness_log'], df_results['pred_OHE_RF'])\n",
    "corr = stats.spearmanr(df_results['fitness_log'], df_results['pred_OHE_RF'])\n",
    "s_corr = round(corr.statistic, 2)\n",
    "print(f'mse : {str(round(mse, 2))} || spearman correlation = {s_corr}')\n",
    "\n",
    "df_results.to_csv(results_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'input layer shape: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'layers': [2300, 512, 1], \n",
    "        'epoch': 100, \n",
    "        'batch_size': 16,\n",
    "        'patience': 100,\n",
    "        'early_stopping': False,\n",
    "        'lr': 1e-3,\n",
    "        'print_every_n_epoch': 10,\n",
    "        'debug': True}\n",
    "surrogate = topmodel.MLPSurrogate(config=config)\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_val_pred = surrogate.predict(X_val)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "ax[1].set_title(f'Val \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surrogate.predict(embeddings)\n",
    "assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "df_results['pred_OHE_MLP'] = y_pred\n",
    "\n",
    "mse = mean_squared_error(df_results['fitness_log'], df_results['pred_OHE_MLP'])\n",
    "corr = stats.spearmanr(df_results['fitness_log'], df_results['pred_OHE_MLP'])\n",
    "s_corr = round(corr.statistic, 2)\n",
    "print(f'mse : {str(round(mse, 2))} || spearman correlation = {s_corr}')\n",
    "\n",
    "df_results.to_csv(results_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESM2, ESM3 and ESMC Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esm2 = ESM2(model_path='/data/users/kgeorge/workspace/esm2/checkpoints/esm2_t33_650M_UR50D.pt', device='gpu')\n",
    "# esm3 = ESM3LM(device='gpu')\n",
    "esmc = ESMCLM(name='esmc_300m', device='gpu')\n",
    "# esmc = ESMCLM(name='esmc_600m', device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:01<00:00, 82.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# embeddings = esm2.get_embeddings_flatten(df['seq'])\n",
    "# embeddings = esm3.get_embeddings_flatten(df['seq'])\n",
    "embeddings = esmc.get_embeddings_mean(df['seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 960)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, val_mask, test_mask = get_split_mask(df, omit_zero=False)\n",
    "\n",
    "X_train = embeddings[train_mask]\n",
    "X_val = embeddings[val_mask]\n",
    "X_test = embeddings[test_mask]\n",
    "\n",
    "# y_train = df.loc[train_mask, 'fitness_raw'].to_numpy().astype(np.float32)\n",
    "# y_val = df.loc[val_mask, 'fitness_raw'].to_numpy().astype(np.float32)\n",
    "# y_test = df.loc[test_mask, 'fitness_raw'].to_numpy().astype(np.float32)\n",
    "\n",
    "y_train = df.loc[train_mask, 'fitness_log'].to_numpy().astype(np.float32)\n",
    "y_val = df.loc[val_mask, 'fitness_log'].to_numpy().astype(np.float32)\n",
    "y_test = df.loc[test_mask, 'fitness_log'].to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 53 val 5 test 32\n"
     ]
    }
   ],
   "source": [
    "print(f'train {train_mask.sum()} val {val_mask.sum()} test {test_mask.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = topmodel.RidgeSurrogate(alpha=1.0)\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_val_pred = surrogate.predict(X_val)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "ax[1].set_title(f'Val \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = surrogate.predict(embeddings)\n",
    "# assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "# df_results['pred_ESMC600M_concat_ridge'] = y_pred\n",
    "\n",
    "# df_results.to_csv(results_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = topmodel.RFSurrogate()\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_val_pred = surrogate.predict(X_val)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "ax[1].set_title(f'Val \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = surrogate.predict(embeddings)\n",
    "# assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "# df_results['pred_ESMC600M_concat_RF'] = y_pred\n",
    "\n",
    "# df_results.to_csv(results_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input layer shape: 960\n"
     ]
    }
   ],
   "source": [
    "print(f'input layer shape: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | mlp  | Sequential | 492 K  | train\n",
      "--------------------------------------------\n",
      "492 K     Trainable params\n",
      "0         Non-trainable params\n",
      "492 K     Total params\n",
      "1.970     Total estimated model params size (MB)\n",
      "4         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0: train mse: 32.40323066711426 val mse: 19.100771844387054\n",
      "Epoch: 1: train mse: 37.75701832771301 val mse: 18.983877420425415\n",
      "Epoch: 2: train mse: 37.29800844192505 val mse: 18.86839407682419\n",
      "Epoch: 3: train mse: 30.74359256029129 val mse: 18.758005023002625\n",
      "Epoch: 4: train mse: 30.94946253299713 val mse: 18.652496695518494\n",
      "Epoch: 5: train mse: 37.107656478881836 val mse: 18.551469147205353\n",
      "Epoch: 6: train mse: 36.71254634857178 val mse: 18.44713181257248\n",
      "Epoch: 7: train mse: 36.84172344207764 val mse: 18.34192168712616\n",
      "Epoch: 8: train mse: 30.33757185935974 val mse: 18.236852824687958\n",
      "Epoch: 9: train mse: 36.36821889877319 val mse: 18.134923189878464\n",
      "Epoch: 10: train mse: 36.36141490936279 val mse: 18.029992401599884\n",
      "Epoch: 11: train mse: 30.50935971736908 val mse: 17.922178745269775\n",
      "Epoch: 12: train mse: 38.577144622802734 val mse: 17.816328823566437\n",
      "Epoch: 13: train mse: 31.026883363723755 val mse: 17.70317244529724\n",
      "Epoch: 14: train mse: 30.632580280303955 val mse: 17.59229224920273\n",
      "Epoch: 15: train mse: 29.28669235110283 val mse: 17.48260933160782\n",
      "Epoch: 16: train mse: 35.08672881126404 val mse: 17.370736360549927\n",
      "Epoch: 17: train mse: 47.35840129852295 val mse: 17.26075142621994\n",
      "Epoch: 18: train mse: 28.837915033102036 val mse: 17.141534686088562\n",
      "Epoch: 19: train mse: 41.19812297821045 val mse: 17.02458882331848\n",
      "Epoch: 20: train mse: 46.80286526679993 val mse: 16.898983359336853\n",
      "Epoch: 21: train mse: 34.49315404891968 val mse: 16.769396632909775\n",
      "Epoch: 22: train mse: 34.173309326171875 val mse: 16.64322355389595\n",
      "Epoch: 23: train mse: 34.080984592437744 val mse: 16.518546015024185\n",
      "Epoch: 24: train mse: 27.61687644943595 val mse: 16.393096953630447\n",
      "Epoch: 25: train mse: 34.082632064819336 val mse: 16.278086215257645\n",
      "Epoch: 26: train mse: 33.19972324371338 val mse: 16.158255845308304\n",
      "Epoch: 27: train mse: 27.268454626202583 val mse: 16.039322316646576\n",
      "Epoch: 28: train mse: 27.356875240802765 val mse: 15.925230860710144\n",
      "Epoch: 29: train mse: 32.98495531082153 val mse: 15.81341603398323\n",
      "Epoch: 30: train mse: 28.31413447856903 val mse: 15.7011878490448\n",
      "Epoch: 31: train mse: 27.63385808467865 val mse: 15.587631493806839\n",
      "Epoch: 32: train mse: 38.11480236053467 val mse: 15.47542953491211\n",
      "Epoch: 33: train mse: 26.282311752438545 val mse: 15.355650901794434\n",
      "Epoch: 34: train mse: 38.156508445739746 val mse: 15.244760632514954\n",
      "Epoch: 35: train mse: 32.76036810874939 val mse: 15.123137265443802\n",
      "Epoch: 36: train mse: 38.02107095718384 val mse: 14.998483508825302\n",
      "Epoch: 37: train mse: 36.87739014625549 val mse: 14.872735679149628\n",
      "Epoch: 38: train mse: 36.54718327522278 val mse: 14.748523712158203\n",
      "Epoch: 39: train mse: 32.85481095314026 val mse: 14.62412878870964\n",
      "Epoch: 40: train mse: 26.206785559654236 val mse: 14.503057658672333\n",
      "Epoch: 41: train mse: 25.18560880422592 val mse: 14.399359345436096\n",
      "Epoch: 42: train mse: 24.809980913996696 val mse: 14.305416494607925\n",
      "Epoch: 43: train mse: 35.30655097961426 val mse: 14.216901123523712\n",
      "Epoch: 44: train mse: 25.23112690448761 val mse: 14.122714161872864\n",
      "Epoch: 45: train mse: 25.181978583335876 val mse: 14.030011713504791\n",
      "Epoch: 46: train mse: 30.417015314102173 val mse: 13.949906945228577\n",
      "Epoch: 47: train mse: 29.380669355392456 val mse: 13.864830553531647\n",
      "Epoch: 48: train mse: 29.850101947784424 val mse: 13.779922902584076\n",
      "Epoch: 49: train mse: 30.57219409942627 val mse: 13.694869577884674\n",
      "Epoch: 50: train mse: 24.716611862182617 val mse: 13.607428967952728\n",
      "Epoch: 51: train mse: 23.806550562381744 val mse: 13.531149208545685\n",
      "Epoch: 52: train mse: 23.595330476760864 val mse: 13.469184875488281\n",
      "Epoch: 53: train mse: 23.6010759472847 val mse: 13.408604800701141\n",
      "Epoch: 54: train mse: 28.346243858337402 val mse: 13.353129982948303\n",
      "Epoch: 55: train mse: 28.16921854019165 val mse: 13.296854197978973\n",
      "Epoch: 56: train mse: 27.799132108688354 val mse: 13.238651871681213\n",
      "Epoch: 57: train mse: 28.06410789489746 val mse: 13.183159947395325\n",
      "Epoch: 58: train mse: 27.591915607452393 val mse: 13.129960179328918\n",
      "Epoch: 59: train mse: 27.81771993637085 val mse: 13.078184247016907\n",
      "Epoch: 60: train mse: 27.687610626220703 val mse: 13.029196381568909\n",
      "Epoch: 61: train mse: 27.32737922668457 val mse: 12.983748197555542\n",
      "Epoch: 62: train mse: 23.52406108379364 val mse: 12.93825089931488\n",
      "Epoch: 63: train mse: 22.641934990882874 val mse: 12.897422909736633\n",
      "Epoch: 64: train mse: 23.028056144714355 val mse: 12.863728761672974\n",
      "Epoch: 65: train mse: 22.275215089321136 val mse: 12.831294775009155\n",
      "Epoch: 66: train mse: 31.5804545879364 val mse: 12.801335453987122\n",
      "Epoch: 67: train mse: 22.114635348320007 val mse: 12.768627882003784\n",
      "Epoch: 68: train mse: 26.76968002319336 val mse: 12.740115761756897\n",
      "Epoch: 69: train mse: 31.18088960647583 val mse: 12.711674213409424\n",
      "Epoch: 70: train mse: 22.447298645973206 val mse: 12.682446241378784\n",
      "Epoch: 71: train mse: 27.165705680847168 val mse: 12.655151724815369\n",
      "Epoch: 72: train mse: 26.342039108276367 val mse: 12.6306312084198\n",
      "Epoch: 73: train mse: 25.987486839294434 val mse: 12.607282400131226\n",
      "Epoch: 74: train mse: 26.320831775665283 val mse: 12.5868399143219\n",
      "Epoch: 75: train mse: 21.53313022851944 val mse: 12.567792654037476\n",
      "Epoch: 76: train mse: 21.428342640399933 val mse: 12.551098346710205\n",
      "Epoch: 77: train mse: 21.296813309192657 val mse: 12.537318587303162\n",
      "Epoch: 78: train mse: 21.288559436798096 val mse: 12.524188756942749\n",
      "Epoch: 79: train mse: 26.41673469543457 val mse: 12.5119389295578\n",
      "Epoch: 80: train mse: 21.144842565059662 val mse: 12.499472618103027\n",
      "Epoch: 81: train mse: 25.82148551940918 val mse: 12.4883131980896\n",
      "Epoch: 82: train mse: 29.34023952484131 val mse: 12.47677743434906\n",
      "Epoch: 83: train mse: 25.126303672790527 val mse: 12.466675281524658\n",
      "Epoch: 84: train mse: 29.589986085891724 val mse: 12.459748983383179\n",
      "Epoch: 85: train mse: 25.02409791946411 val mse: 12.454282283782959\n",
      "Epoch: 86: train mse: 25.07763409614563 val mse: 12.450091123580933\n",
      "Epoch: 87: train mse: 29.23134708404541 val mse: 12.44729471206665\n",
      "Epoch: 88: train mse: 28.94034457206726 val mse: 12.447385787963867\n",
      "Epoch: 89: train mse: 25.20453977584839 val mse: 12.448613405227661\n",
      "Epoch: 90: train mse: 21.004854679107666 val mse: 12.447884559631348\n",
      "Epoch: 91: train mse: 25.022955179214478 val mse: 12.44375491142273\n",
      "Epoch: 92: train mse: 20.85412847995758 val mse: 12.438605308532715\n",
      "Epoch: 93: train mse: 24.876454830169678 val mse: 12.433817863464355\n",
      "Epoch: 94: train mse: 24.481013298034668 val mse: 12.428297758102417\n",
      "Epoch: 95: train mse: 20.75498068332672 val mse: 12.425642251968384\n",
      "Epoch: 96: train mse: 24.31449055671692 val mse: 12.418367624282837\n",
      "Epoch: 97: train mse: 24.464779376983643 val mse: 12.412362575531006\n",
      "Epoch: 98: train mse: 20.204319655895233 val mse: 12.407881736755371\n",
      "Epoch: 99: train mse: 20.4931743144989 val mse: 12.399592399597168\n",
      "Epoch: 100: train mse: 20.376060366630554 val mse: 12.390222549438477\n",
      "Epoch: 101: train mse: 23.608495235443115 val mse: 12.382834434509277\n",
      "Epoch: 102: train mse: 26.92266881465912 val mse: 12.377663373947144\n",
      "Epoch: 103: train mse: 24.340142726898193 val mse: 12.379601955413818\n",
      "Epoch: 104: train mse: 27.621621131896973 val mse: 12.379536628723145\n",
      "Epoch: 105: train mse: 28.291508197784424 val mse: 12.385957479476929\n",
      "Epoch: 106: train mse: 23.894365549087524 val mse: 12.3866548538208\n",
      "Epoch: 107: train mse: 20.066888689994812 val mse: 12.384953022003174\n",
      "Epoch: 108: train mse: 20.03547465801239 val mse: 12.379029273986816\n",
      "Epoch: 109: train mse: 24.00917100906372 val mse: 12.372299671173096\n",
      "Epoch: 110: train mse: 23.6255961060524 val mse: 12.365885257720947\n",
      "Epoch: 111: train mse: 22.972219467163086 val mse: 12.360347986221313\n",
      "Epoch: 112: train mse: 23.941998958587646 val mse: 12.358080863952637\n",
      "Epoch: 113: train mse: 19.907532930374146 val mse: 12.35524320602417\n",
      "Epoch: 114: train mse: 22.80257511138916 val mse: 12.344109535217285\n",
      "Epoch: 115: train mse: 23.621625661849976 val mse: 12.335362434387207\n",
      "Epoch: 116: train mse: 26.767529845237732 val mse: 12.32836651802063\n",
      "Epoch: 117: train mse: 19.644107580184937 val mse: 12.32321286201477\n",
      "Epoch: 118: train mse: 23.006428003311157 val mse: 12.31232213973999\n",
      "Epoch: 119: train mse: 19.810228943824768 val mse: 12.303835391998291\n",
      "Epoch: 120: train mse: 23.00047016143799 val mse: 12.288654327392578\n",
      "Epoch: 121: train mse: 22.843358993530273 val mse: 12.278336524963379\n",
      "Epoch: 122: train mse: 22.88674306869507 val mse: 12.27016019821167\n",
      "Epoch: 123: train mse: 23.200028657913208 val mse: 12.265288352966309\n",
      "Epoch: 124: train mse: 22.04081630706787 val mse: 12.264468431472778\n",
      "Epoch: 125: train mse: 23.044118881225586 val mse: 12.266307592391968\n",
      "Epoch: 126: train mse: 22.428778648376465 val mse: 12.262723445892334\n",
      "Epoch: 127: train mse: 26.42435359954834 val mse: 12.257463932037354\n",
      "Epoch: 128: train mse: 22.666565895080566 val mse: 12.264305591583252\n",
      "Epoch: 129: train mse: 18.728470981121063 val mse: 12.263047218322754\n",
      "Epoch: 130: train mse: 22.138959407806396 val mse: 12.263358116149902\n",
      "Epoch: 131: train mse: 22.732001304626465 val mse: 12.26741647720337\n",
      "Epoch: 132: train mse: 25.819458723068237 val mse: 12.272066116333008\n",
      "Epoch: 133: train mse: 21.619093418121338 val mse: 12.278422355651855\n",
      "Epoch: 134: train mse: 18.642216205596924 val mse: 12.277995109558105\n",
      "Epoch: 135: train mse: 18.38308423757553 val mse: 12.27916669845581\n",
      "Epoch: 136: train mse: 21.98797035217285 val mse: 12.271890640258789\n",
      "Epoch: 137: train mse: 21.633997917175293 val mse: 12.26479172706604\n",
      "Epoch: 138: train mse: 22.579402565956116 val mse: 12.258838176727295\n",
      "Epoch: 139: train mse: 25.273159742355347 val mse: 12.253966569900513\n",
      "Epoch: 140: train mse: 18.747197151184082 val mse: 12.257565975189209\n",
      "Epoch: 141: train mse: 21.373775482177734 val mse: 12.249389886856079\n",
      "Epoch: 142: train mse: 21.727705001831055 val mse: 12.242480039596558\n",
      "Epoch: 143: train mse: 21.967203617095947 val mse: 12.235297203063965\n",
      "Epoch: 144: train mse: 18.179691195487976 val mse: 12.227977275848389\n",
      "Epoch: 145: train mse: 21.72659420967102 val mse: 12.21239423751831\n",
      "Epoch: 146: train mse: 21.916271686553955 val mse: 12.199158191680908\n",
      "Epoch: 147: train mse: 24.318578481674194 val mse: 12.193704843521118\n",
      "Epoch: 148: train mse: 23.704343795776367 val mse: 12.198711156845093\n",
      "Epoch: 149: train mse: 18.109177350997925 val mse: 12.203458547592163\n",
      "Epoch: 150: train mse: 20.964696645736694 val mse: 12.192912817001343\n",
      "Epoch: 151: train mse: 21.677762746810913 val mse: 12.184808015823364\n",
      "Epoch: 152: train mse: 18.496994018554688 val mse: 12.1773099899292\n",
      "Epoch: 153: train mse: 20.641586542129517 val mse: 12.156765937805176\n",
      "Epoch: 154: train mse: 21.420748710632324 val mse: 12.142473936080933\n",
      "Epoch: 155: train mse: 20.44794201850891 val mse: 12.127610683441162\n",
      "Epoch: 156: train mse: 20.691288471221924 val mse: 12.114463806152344\n",
      "Epoch: 157: train mse: 24.166446447372437 val mse: 12.104127883911133\n",
      "Epoch: 158: train mse: 20.483736991882324 val mse: 12.11043405532837\n",
      "Epoch: 159: train mse: 20.972325325012207 val mse: 12.108004093170166\n",
      "Epoch: 160: train mse: 19.69995665550232 val mse: 12.115818500518799\n",
      "Epoch: 161: train mse: 17.31259047985077 val mse: 12.117452621459961\n",
      "Epoch: 162: train mse: 20.993927896022797 val mse: 12.103441715240479\n",
      "Epoch: 163: train mse: 18.019654035568237 val mse: 12.096651315689087\n",
      "Epoch: 164: train mse: 17.246235609054565 val mse: 12.073778629302979\n",
      "Epoch: 165: train mse: 23.14909052848816 val mse: 12.041104793548584\n",
      "Epoch: 166: train mse: 16.888579428195953 val mse: 12.029217720031738\n",
      "Epoch: 167: train mse: 17.407382369041443 val mse: 12.01240086555481\n",
      "Epoch: 168: train mse: 20.25189995765686 val mse: 11.984413146972656\n",
      "Epoch: 169: train mse: 17.142780900001526 val mse: 11.968778133392334\n",
      "Epoch: 170: train mse: 16.974234223365784 val mse: 11.938809394836426\n",
      "Epoch: 171: train mse: 21.48121953010559 val mse: 11.914084434509277\n",
      "Epoch: 172: train mse: 19.859335899353027 val mse: 11.907036781311035\n",
      "Epoch: 173: train mse: 19.52272868156433 val mse: 11.898032665252686\n",
      "Epoch: 174: train mse: 24.002554893493652 val mse: 11.889891147613525\n",
      "Epoch: 175: train mse: 16.727744340896606 val mse: 11.90238904953003\n",
      "Epoch: 176: train mse: 16.896167755126953 val mse: 11.893115043640137\n",
      "Epoch: 177: train mse: 16.617025017738342 val mse: 11.87037992477417\n",
      "Epoch: 178: train mse: 19.56866431236267 val mse: 11.838638305664062\n",
      "Epoch: 179: train mse: 16.240359365940094 val mse: 11.826796293258667\n",
      "Epoch: 180: train mse: 19.35847783088684 val mse: 11.825083017349243\n",
      "Epoch: 181: train mse: 18.971380710601807 val mse: 11.819839000701904\n",
      "Epoch: 182: train mse: 16.66176748275757 val mse: 11.813835620880127\n",
      "Epoch: 183: train mse: 20.138498067855835 val mse: 11.795835018157959\n",
      "Epoch: 184: train mse: 21.059956312179565 val mse: 11.78508996963501\n",
      "Epoch: 185: train mse: 23.399121522903442 val mse: 11.788639545440674\n",
      "Epoch: 186: train mse: 21.707982540130615 val mse: 11.800769805908203\n",
      "Epoch: 187: train mse: 22.070669412612915 val mse: 11.81744384765625\n",
      "Epoch: 188: train mse: 21.878350257873535 val mse: 11.846274375915527\n",
      "Epoch: 189: train mse: 18.50057864189148 val mse: 11.872894287109375\n",
      "Epoch: 190: train mse: 18.392037391662598 val mse: 11.888757944107056\n",
      "Epoch: 191: train mse: 19.333600759506226 val mse: 11.898492336273193\n",
      "Epoch: 192: train mse: 15.880425572395325 val mse: 11.892601490020752\n",
      "Epoch: 193: train mse: 16.344969153404236 val mse: 11.87063455581665\n",
      "Epoch: 194: train mse: 17.70639443397522 val mse: 11.833959579467773\n",
      "Epoch: 195: train mse: 20.269329071044922 val mse: 11.812498807907104\n",
      "Epoch: 196: train mse: 18.15688157081604 val mse: 11.797574996948242\n",
      "Epoch: 197: train mse: 19.711629629135132 val mse: 11.77884292602539\n",
      "Epoch: 198: train mse: 15.347941517829895 val mse: 11.766335725784302\n",
      "Epoch: 199: train mse: 17.41604208946228 val mse: 11.745368957519531\n",
      "Epoch: 200: train mse: 17.52807641029358 val mse: 11.7319016456604\n",
      "Epoch: 201: train mse: 15.204754054546356 val mse: 11.71959114074707\n",
      "Epoch: 202: train mse: 19.116734743118286 val mse: 11.702224731445312\n",
      "Epoch: 203: train mse: 15.457189917564392 val mse: 11.683134078979492\n",
      "Epoch: 204: train mse: 15.357176780700684 val mse: 11.658824443817139\n",
      "Epoch: 205: train mse: 17.079091548919678 val mse: 11.63460659980774\n",
      "Epoch: 206: train mse: 17.04680037498474 val mse: 11.614505529403687\n",
      "Epoch: 207: train mse: 17.529066562652588 val mse: 11.598856449127197\n",
      "Epoch: 208: train mse: 17.374812364578247 val mse: 11.586633205413818\n",
      "Epoch: 209: train mse: 17.28907346725464 val mse: 11.577291488647461\n",
      "Epoch: 210: train mse: 17.450856685638428 val mse: 11.569893836975098\n",
      "Epoch: 211: train mse: 15.189975500106812 val mse: 11.564562320709229\n",
      "Epoch: 212: train mse: 18.006222009658813 val mse: 11.54271650314331\n",
      "Epoch: 213: train mse: 17.800342082977295 val mse: 11.527646541595459\n",
      "Epoch: 214: train mse: 14.900631546974182 val mse: 11.521102905273438\n",
      "Epoch: 215: train mse: 25.71436882019043 val mse: 11.505250930786133\n",
      "Epoch: 216: train mse: 17.43309235572815 val mse: 11.531759262084961\n",
      "Epoch: 217: train mse: 16.864702224731445 val mse: 11.547109127044678\n",
      "Epoch: 218: train mse: 18.08325505256653 val mse: 11.56229853630066\n",
      "Epoch: 219: train mse: 15.170812368392944 val mse: 11.575470924377441\n",
      "Epoch: 220: train mse: 15.054044127464294 val mse: 11.559643507003784\n",
      "Epoch: 221: train mse: 14.451068460941315 val mse: 11.53452730178833\n",
      "Epoch: 222: train mse: 14.664251208305359 val mse: 11.500096321105957\n",
      "Epoch: 223: train mse: 14.575978636741638 val mse: 11.460672855377197\n",
      "Epoch: 224: train mse: 14.159416109323502 val mse: 11.42678689956665\n",
      "Epoch: 225: train mse: 16.515186309814453 val mse: 11.392841339111328\n",
      "Epoch: 226: train mse: 18.73811364173889 val mse: 11.367549896240234\n",
      "Epoch: 227: train mse: 14.779112458229065 val mse: 11.353981018066406\n",
      "Epoch: 228: train mse: 19.09596538543701 val mse: 11.330496788024902\n",
      "Epoch: 229: train mse: 13.829250767827034 val mse: 11.33126187324524\n",
      "Epoch: 230: train mse: 16.726780891418457 val mse: 11.330987453460693\n",
      "Epoch: 231: train mse: 14.169893383979797 val mse: 11.324009418487549\n",
      "Epoch: 232: train mse: 14.62607717514038 val mse: 11.31023359298706\n",
      "Epoch: 233: train mse: 14.83467161655426 val mse: 11.28516411781311\n",
      "Epoch: 234: train mse: 22.790246725082397 val mse: 11.26742935180664\n",
      "Epoch: 235: train mse: 17.659626007080078 val mse: 11.276585578918457\n",
      "Epoch: 236: train mse: 17.506566524505615 val mse: 11.283317804336548\n",
      "Epoch: 237: train mse: 14.098571956157684 val mse: 11.300702333450317\n",
      "Epoch: 238: train mse: 17.083787441253662 val mse: 11.295114994049072\n",
      "Epoch: 239: train mse: 17.44891369342804 val mse: 11.29686427116394\n",
      "Epoch: 240: train mse: 18.078391790390015 val mse: 11.296050071716309\n",
      "Epoch: 241: train mse: 17.399599075317383 val mse: 11.315735816955566\n",
      "Epoch: 242: train mse: 18.810932993888855 val mse: 11.331182718276978\n",
      "Epoch: 243: train mse: 16.334465265274048 val mse: 11.357605457305908\n",
      "Epoch: 244: train mse: 15.389135837554932 val mse: 11.377492904663086\n",
      "Epoch: 245: train mse: 13.481590420007706 val mse: 11.387089252471924\n",
      "Epoch: 246: train mse: 13.757813513278961 val mse: 11.381538152694702\n",
      "Epoch: 247: train mse: 18.95949673652649 val mse: 11.361989498138428\n",
      "Epoch: 248: train mse: 14.202551007270813 val mse: 11.359560012817383\n",
      "Epoch: 249: train mse: 15.467072248458862 val mse: 11.335379362106323\n",
      "Epoch: 250: train mse: 13.434508442878723 val mse: 11.317028999328613\n",
      "Epoch: 251: train mse: 13.511088192462921 val mse: 11.296525955200195\n",
      "Epoch: 252: train mse: 19.03301763534546 val mse: 11.263408184051514\n",
      "Epoch: 253: train mse: 17.075592041015625 val mse: 11.255563974380493\n",
      "Epoch: 254: train mse: 15.273632526397705 val mse: 11.259552240371704\n",
      "Epoch: 255: train mse: 18.735052585601807 val mse: 11.273478984832764\n",
      "Epoch: 256: train mse: 15.719188928604126 val mse: 11.2898850440979\n",
      "Epoch: 257: train mse: 19.57518744468689 val mse: 11.30000925064087\n",
      "Epoch: 258: train mse: 18.864924907684326 val mse: 11.321245431900024\n",
      "Epoch: 259: train mse: 13.340476036071777 val mse: 11.34882640838623\n",
      "Epoch: 260: train mse: 13.99674379825592 val mse: 11.336912393569946\n",
      "Epoch: 261: train mse: 15.085654735565186 val mse: 11.30603837966919\n",
      "Epoch: 262: train mse: 13.546968340873718 val mse: 11.278837203979492\n",
      "Epoch: 263: train mse: 18.206074714660645 val mse: 11.253715991973877\n",
      "Epoch: 264: train mse: 15.839013576507568 val mse: 11.25746488571167\n",
      "Epoch: 265: train mse: 20.445796728134155 val mse: 11.257492065429688\n",
      "Epoch: 266: train mse: 13.546513676643372 val mse: 11.28121304512024\n",
      "Epoch: 267: train mse: 12.772734254598618 val mse: 11.270887851715088\n",
      "Epoch: 268: train mse: 15.710821390151978 val mse: 11.255129337310791\n",
      "Epoch: 269: train mse: 12.641207098960876 val mse: 11.23584508895874\n",
      "Epoch: 270: train mse: 16.85447359085083 val mse: 11.21621060371399\n",
      "Epoch: 271: train mse: 13.15118682384491 val mse: 11.200486183166504\n",
      "Epoch: 272: train mse: 19.851243495941162 val mse: 11.174558639526367\n",
      "Epoch: 273: train mse: 12.551931947469711 val mse: 11.170737266540527\n",
      "Epoch: 274: train mse: 16.106656312942505 val mse: 11.161519527435303\n",
      "Epoch: 275: train mse: 12.61745023727417 val mse: 11.166200637817383\n",
      "Epoch: 276: train mse: 15.784915804862976 val mse: 11.157160758972168\n",
      "Epoch: 277: train mse: 12.492544561624527 val mse: 11.139415264129639\n",
      "Epoch: 278: train mse: 12.967988729476929 val mse: 11.113810062408447\n",
      "Epoch: 279: train mse: 12.997336745262146 val mse: 11.0768404006958\n",
      "Epoch: 280: train mse: 12.464454799890518 val mse: 11.046237468719482\n",
      "Epoch: 281: train mse: 13.184304237365723 val mse: 11.010497570037842\n",
      "Epoch: 282: train mse: 16.983817100524902 val mse: 10.977294206619263\n",
      "Epoch: 283: train mse: 16.283447861671448 val mse: 10.976469039916992\n",
      "Epoch: 284: train mse: 13.00373911857605 val mse: 10.989796161651611\n",
      "Epoch: 285: train mse: 13.465819358825684 val mse: 10.983006477355957\n",
      "Epoch: 286: train mse: 12.41917735338211 val mse: 10.978252410888672\n",
      "Epoch: 287: train mse: 15.14251160621643 val mse: 10.956358194351196\n",
      "Epoch: 288: train mse: 12.926572561264038 val mse: 10.92793083190918\n",
      "Epoch: 289: train mse: 12.17338714003563 val mse: 10.905757665634155\n",
      "Epoch: 290: train mse: 17.097851753234863 val mse: 10.891338586807251\n",
      "Epoch: 291: train mse: 12.14313718676567 val mse: 10.881775140762329\n",
      "Epoch: 292: train mse: 13.600192785263062 val mse: 10.864534854888916\n",
      "Epoch: 293: train mse: 15.917643785476685 val mse: 10.857191324234009\n",
      "Epoch: 294: train mse: 16.800424814224243 val mse: 10.867745876312256\n",
      "Epoch: 295: train mse: 11.964677959680557 val mse: 10.898357391357422\n",
      "Epoch: 296: train mse: 13.18191909790039 val mse: 10.912943840026855\n",
      "Epoch: 297: train mse: 12.079415112733841 val mse: 10.921692371368408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 298: train mse: 15.343560218811035 val mse: 10.907288312911987\n",
      "Epoch: 299: train mse: 13.993003129959106 val mse: 10.90687084197998\n",
      "Epoch: 300: train mse: 13.993003129959106 val mse: 10.90687084197998\n"
     ]
    }
   ],
   "source": [
    "config={'layers': [960, 512, 1], \n",
    "        'epoch': 300, \n",
    "        'batch_size': 16,\n",
    "        'patience': 200,\n",
    "        'early_stopping': True,\n",
    "        'lr': 1e-4,\n",
    "        'print_every_n_epoch': 1,\n",
    "        'debug': True}\n",
    "surrogate = topmodel.MLPSurrogate(config=config)\n",
    "surrogate.trainmodel(X=X_train, y=y_train, val=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_840650/3945170610.py:9: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  res = stats.spearmanr(a[indices], b[indices])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABAUAAAE3CAYAAADSc/h1AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAc7VJREFUeJzt3XlcVNX/P/DXgMwMwwzDLqgIouaSOyRhi2tAmWn5sVUT82NZluWafHI3JRPNLNvNtNUoLUstTNNM+Wg/TAsXTJIgNlNkBhwYBji/P/wyH0YGGJZhZpjX8/GYx4N7595zzx3gfc+877nnSIQQAkRERERERETkdFxsXQEiIiIiIiIisg0mBYiIiIiIiIicFJMCRERERERERE6KSQEiIiIiIiIiJ8WkABEREREREZGTYlKAiIiIiIiIyEkxKUBERERERETkpJgUICIiIiIiInJSTAoQEREREREROSkmBYiuExoaivXr19u6GkRETmPYsGF47rnnbF0NIiIip8SkADksiURS72vp0qVNKveXX37B448/3rKVJSJqg8aMGYPY2Fiz7x06dAgSiQS//fZbK9eKiKh1WatNWl32V1991WJ1JTKnna0rQNRUeXl5xp+3bduGxYsXIz093bhOqVQafxZCoLKyEu3aNfwn7+/v37IVJSJqo6ZOnYrx48fj77//RqdOnUze27x5MyIiItCvXz8b1Y6IqHU0pk1KZI/YU4AcVmBgoPGlVqshkUiMy2fPnoVKpcKePXsQHh4OmUyGn3/+GRkZGRg7dizat28PpVKJm266CT/88INJudc/PiCRSPDee+/h3nvvhUKhQPfu3bFz585WPlsiIvtz9913w9/fHx988IHJ+pKSEiQlJWHq1Km4fPkyHnroIXTs2BEKhQJ9+/bFp59+apsKExFZQX1t0sDAQHz22Wfo1asX5HI5evbsiTfeeMO4b3l5OZ5++mkEBQVBLpcjJCQECQkJAK61SQHg3nvvhUQiMS4TtTQmBahNW7BgAV566SWcOXMG/fr1Q0lJCe666y7s27cPv/76K2JjYzFmzBhkZWXVW86yZctw//3347fffsNdd92FRx55BIWFha10FkRE9qldu3Z49NFH8cEHH0AIYVyflJSEyspKPPTQQygrK0N4eDh27dqFtLQ0PP7445g0aRKOHTtmw5oTEbWOjz/+GIsXL8bKlStx5swZrFq1CosWLcKWLVsAABs2bMDOnTvx+eefIz09HR9//LHxy/8vv/wC4FrPq7y8POMyUUvj4wPUpi1fvhx33HGHcdnHxwf9+/c3Lq9YsQI7duzAzp078fTTT9dZTlxcHB566CEAwKpVq7BhwwYcO3aszmdpiYicxWOPPYY1a9bg4MGDGDZsGIBrDdjx48dDrVZDrVZj7ty5xu2feeYZfP/99/j8888xePBgG9WaiKh1LFmyBGvXrsV9990HAOjSpQtOnz6Nt99+G5MnT0ZWVha6d++OW2+9FRKJBCEhIcZ9qx9p9fLyQmBgoE3qT86BPQWoTYuIiDBZLikpwdy5c9GrVy94eXlBqVTizJkzDfYUqPlMrIeHBzw9PXHx4kWr1JmIyJH07NkTQ4YMwfvvvw8AOH/+PA4dOoSpU6cCACorK7FixQr07dsXPj4+UCqV+P777xuMu0REju7q1avIyMjA1KlToVQqja8XX3wRGRkZAK7deDpx4gR69OiBmTNnIjk52ca1JmfEngLUpnl4eJgsz507F3v37kViYiK6desGd3d3/Otf/0J5eXm95bi5uZksSyQSVFVVtXh9iYgc0dSpU/HMM89g48aN2Lx5M7p27YqhQ4cCANasWYNXX30V69evR9++feHh4YHnnnuuwbhLROToSkpKAADvvvsuIiMjTd5zdXUFAAwaNAgXLlzAnj178MMPP+D+++/HqFGj8MUXX7R6fcl5MSlATuXw4cOIi4vDvffeC+BasM7MzLRtpYiIHNz999+PZ599Fp988gm2bt2KJ598EhKJBMC1uDt27FhMnDgRAFBVVYVz586hd+/etqwyEZHVtW/fHh06dMCff/6JRx55pM7tPD098cADD+CBBx7Av/71L8TGxqKwsBA+Pj5wc3NDZWVlK9aanBGTAuRUunfvju3bt2PMmDGQSCRYtGgR7/gTETWTUqnEAw88gPj4eGi1WsTFxRnf6969O7744gscOXIE3t7eWLduHQoKCpgUICKnsGzZMsycORNqtRqxsbHQ6/X4f//v/+HKlSuYPXs21q1bh6CgIAwcOBAuLi5ISkpCYGAgvLy8AFybgWDfvn245ZZbIJPJ4O3tbdsTojaJYwqQU1m3bh28vb0xZMgQjBkzBjExMRg0aJCtq0VE5PCmTp2KK1euICYmBh06dDCuX7hwIQYNGoSYmBgMGzYMgYGBGDdunO0qSkTUiv7973/jvffew+bNm9G3b18MHToUH3zwAbp06QIAUKlUePnllxEREYGbbroJmZmZ2L17N1xcrn1NW7t2Lfbu3Yvg4GAMHDjQlqdCbZhE1JxDiIiIiIiIiIicBnsKEBERERERETkpJgWIiIiIiIiInBSTAkREREREREROikkBIiIiIiIiIifFpAARERERERGRk2JSgOj/zJw5E+Hh4ZDJZBgwYEC9254/fx4qlco4h2xzyk1PT8fw4cPRvn17yOVyhIWFYeHChTAYDE07ESIiO3b58mXExsaiQ4cOkMlkCA4OxtNPPw2tVmvcJi4uDhKJpNbrxhtvrLPcAwcOYOzYsQgKCoKHhwcGDBiAjz/+2GSbYcOGmS139OjRVjtfIqKGWNIG/e2333DbbbdBLpcjODgYL7/8coPl7tu3D0OGDIFKpUJgYCCef/55VFRUGN8vKytDXFwc+vbti3bt2nG6WCfGpABRDY899hgeeOCBercxGAx46KGHcNttt7VIuW5ubnj00UeRnJyM9PR0rF+/Hu+++y6WLFnSqLoTETkCFxcXjB07Fjt37sS5c+fwwQcf4IcffsD06dON27z66qvIy8szvrKzs+Hj44MJEybUWe6RI0fQr18/fPnll/jtt98wZcoUPProo/j222+N22zfvt2k3LS0NLi6utZbLhFRa6ivrajVahEdHY2QkBCkpqZizZo1WLp0Kd555506yzt58iTuuusuxMbG4tdff8W2bduwc+dOLFiwwLhNZWUl3N3dMXPmTIwaNarFz4kciCCyoqFDh4qnn35aPPvss8LLy0sEBASId955R5SUlIi4uDihVCpF165dxe7du437FBYWiocfflj4+fkJuVwuunXrJt5//33j+1lZWWLChAlCrVYLb29vcc8994gLFy60WJ2XLFki+vfvX+f78+fPFxMnThSbN28WarW6xcqtadasWeLWW2+1uGwiIkeMt9VeffVV0alTpzrf37Fjh5BIJCIzM7NR5d51111iypQpdb7/yiuvCJVKJUpKShpVLhHZP0eMiXW1Fd944w3h7e0t9Hq9cd3zzz8vevToUWdZ8fHxIiIiwmTdzp07hVwuF1qtttb2kydPFmPHjm1y3cmxsacAWd2WLVvg5+eHY8eO4ZlnnsGTTz6JCRMmYMiQITh+/Diio6MxadIk6HQ6AMCiRYtw+vRp7NmzB2fOnMGbb74JPz8/ANfu0sfExEClUuHQoUM4fPgwlEolYmNjUV5eXmcdQkNDsXTp0mafy/79+5GUlISNGzc2u6y6nD9/Ht999x2GDh1qtWMQUdvkiPE2NzcX27dvrzfmbdq0CaNGjUJISIjF5QKARqOBj49PveU++OCD8PDwaFS5ROQYHDEmmpOSkoLbb78dUqnUuC4mJgbp6em4cuWK2X30ej3kcrnJOnd3d5SVlSE1NbVZ9aE2yNZZCWrbhg4danLHu6KiQnh4eIhJkyYZ1+Xl5QkAIiUlRQghxJgxY+q8s/Phhx+KHj16iKqqKuM6vV4v3N3dxffff19nPUaMGCFee+01i+pcV5b20qVLIjg4WBw8eFAIIVq8p0BUVJSQyWQCgHj88cdFZWWlxWUTETlavH3wwQeFu7u7ACDGjBkjSktLzW6Xk5MjXF1dxbZt2xoss6Zt27YJqVQq0tLSzL5/9OhRAUAcPXq0UeUSkWNwtJgoRN1txTvuuEM8/vjjJutOnTolAIjTp0+bLev7778XLi4u4pNPPhEVFRXi77//FrfddpsAID755JNa27OngHNjTwGyun79+hl/dnV1ha+vL/r27Wtc1759ewDAxYsXAQBPPvkkPvvsMwwYMADz58/HkSNHjNuePHnSOMifUqmEUqmEj48PysrKkJGRUWcd9u3bh6effrpZ5zFt2jQ8/PDDuP3225tVTl22bduG48eP45NPPsGuXbuQmJholeMQUdvlSPH2lVdewfHjx/H1118jIyMDs2fPNrvdli1b4OXl1agBsH788UdMmTIF7777bp2DE27atAl9+/bF4MGDLS6XiByLI8XElhYdHY01a9Zg+vTpkMlkuOGGG3DXXXcBuDa2C1FN7WxdAWr73NzcTJYlEonJOolEAgCoqqoCANx5553466+/sHv3buzduxcjR47EjBkzkJiYiJKSEoSHh9caURoA/P39rXgW1x4d2Llzp/HLuhACVVVVaNeuHd555x089thjzSo/ODgYANC7d29UVlbi8ccfx5w5c+Dq6trsuhORc3CkeBsYGIjAwED07NkTPj4+uO2227Bo0SIEBQUZtxFC4P3338ekSZNMus3W5+DBgxgzZgxeeeUVPProo2a3uXr1Kj777DMsX7682edBRPbLkWJifQIDA1FQUGCyrno5MDCwzv1mz56NWbNmIS8vD97e3sjMzER8fDzCwsKsWl9yPEwKkF3y9/fH5MmTMXnyZNx2222YN28eEhMTMWjQIGzbtg0BAQHw9PRs1TqlpKSgsrLSuPz1119j9erVOHLkCDp27Niix6qqqoLBYEBVVRWTAkRkVfYQb6sb5Hq93mT9wYMHcf78eUydOtWicg4cOIC7774bq1evxuOPP17ndklJSdDr9Zg4cWLTK01EbZI9xMTrRUVF4YUXXoDBYDAmNfbu3YsePXrA29u73n0lEgk6dOgAAPj0008RHByMQYMGWb3O5FjYd4TszuLFi/H111/j/PnzOHXqFL799lv06tULAPDII4/Az88PY8eOxaFDh3DhwgUcOHAAM2fOxN9//11nmSNHjsTrr79e73HPnz+PEydOID8/H6WlpThx4gROnDhhHDymV69e6NOnj/HVsWNHuLi4oE+fPsaAvGPHDvTs2bNR5X788cf4/PPPcebMGfz555/4/PPPER8fjwceeKBWhpuIqCXZIt7u3r0bmzdvRlpaGjIzM7Fr1y5Mnz4dt9xyC0JDQ0223bRpEyIjI9GnT59a5bz++usYOXKkcfnHH3/E6NGjMXPmTIwfPx75+fnIz89HYWFhrX03bdqEcePGwdfXt6GPiIiciL22QR9++GFIpVJMnToVp06dwrZt2/Dqq6+aPHZlrg26Zs0a/P777zh16hRWrFiBl156CRs2bDC54XT69GmcOHEChYWF0Gg0xmOTc2FPAbI7UqkU8fHxyMzMhLu7O2677TZ89tlnAACFQoGffvoJzz//PO677z4UFxejY8eOGDlyZL1Z24yMDFy6dKne4/773//GwYMHjcsDBw4EAFy4cKFWQ7UuGo0G6enpjSq3Xbt2WL16Nc6dOwchBEJCQvD0009j1qxZFh2TiKipbBFv3d3d8e6772LWrFnQ6/UIDg7GfffdZzJ3NnAtnn755Zd49dVXzZZz6dIlk+d4t2zZAp1Oh4SEBCQkJBjXDx06FAcOHDAup6en4+eff0ZycnK9nw0ROR97bYOq1WokJydjxowZCA8Ph5+fHxYvXmzSI8pcG3TPnj1YuXIl9Ho9+vfvj6+//hp33nmnyTZ33XUX/vrrr1rHFkLUW2dqWySCv3EiIiIiIiIip8THB4iIiIiIiIicFJMCRERERERERE6KSQEiIiIiIiIiJ8WkABEREREREZGTYlKArOrAgQOQSCQoKiqyi3Ko6W6//XZ88skntq6G3XvwwQexdu1aW1eDiPG3DSsvL0e3bt1w5MgRW1elVb311lsYM2aMratBDoRxsO1gO9QyTW2HMilAdmfYsGF47rnnTNYNGTIEeXl5UKvVtqlUI2zcuBGhoaGQy+WIjIzEsWPH6t1+2LBhkEgktV6jR4822e7MmTO45557oFar4eHhgZtuuglZWVn1lq3VavHCCy+gZ8+ekMvlCAwMxKhRo7B9+3bjVDPmPu/r7dy5EwUFBXjwwQeN68rKyjBjxgz4+vpCqVRi/PjxKCgoqLechs6jsLAQzzzzDHr06AF3d3d07twZM2fOhEajabDc6x04cACDBg2CTCZDt27d8MEHHzS4z/fff4+bb74ZKpUK/v7+GD9+PDIzM43vx8XFmf1d3XjjjcZtFi5ciJUrVzapzkS25ujx93pCCCxevBhBQUFwd3fHqFGj8Mcff9S7z08//YQxY8agQ4cOkEgk+Oqrr2ptYy4WxMbGNlif/Px8PPPMMwgLC4NMJkNwcDDGjBmDffv2GbcJDQ3F+vXr6y3nrbfeQpcuXTBkyJB6t5s5cybCw8Mhk8kwYMCABusHND2215SXl4eHH34YN9xwA1xcXBq8xlTLysrC6NGjoVAoEBAQgHnz5qGiosL4/mOPPYbjx4/j0KFDjaoPUWM4ehxsbDu0ps8++wwSiQTjxo0zWb99+3ZER0fD19cXEokEJ06csKg8e2uHWnJNOH78OO644w54eXnB19cXjz/+OEpKSiw635qa0g4VQiAxMRE33HADZDIZOnbsiJUrVxrft2Y7lEmBZiovL7d1FazO3DkKIUwu1NYmlUoRGBgIiUTSasdsim3btmH27NlYsmQJjh8/jv79+yMmJgYXL16sc5/t27cjLy/P+EpLS4OrqysmTJhg3CYjIwO33norevbsiQMHDuC3337DokWLIJfL6yy3qKgIQ4YMwdatWxEfH4/jx4/jp59+wgMPPID58+c3Klhs2LABU6ZMgYvL/0LGrFmz8M033yApKQkHDx5Ebm4u7rvvvnrLaeg8cnNzkZubi8TERKSlpeGDDz7Ad999h6lTp1pcV+DavL6jR4/G8OHDceLECTz33HP497//je+//77efcaOHYsRI0bgxIkT+P7773Hp0iWTc3r11VdNflfZ2dnw8fEx+V316dMHXbt2xUcffdSoOlPjMf62DkeJv+a8/PLL2LBhA9566y0cPXoUHh4eiImJQVlZWZ37XL16Ff3798fGjRvrLTs2NtYkHnz66af1bp+ZmYnw8HDs378fa9aswe+//47vvvsOw4cPx4wZMyw+JyEEXn/9dYvj4mOPPYYHHnjA4vKbEtuvp9fr4e/vj4ULF6J///4W7VNZWYnRo0ejvLwcR44cwZYtW/DBBx9g8eLFxm2kUikefvhhbNiwoVH1acsYB1uHo8TBprRDq2VmZmLu3Lm47bbbar139epV3HrrrVi9erXFdbHHdmhD14Tc3FyMGjUK3bp1w9GjR/Hdd9/h1KlTiIuLs7iuQNPaoQDw7LPP4r333kNiYiLOnj2LnTt3YvDgwcb3rdoOFQ4kKSlJ9OnTR8jlcuHj4yNGjhwpSkpKhBBCTJ48WYwdO1YsXbpU+Pn5CZVKJZ544gmh1+uN+1dWVopVq1aJ0NBQIZfLRb9+/URSUpLx/YqKCvHYY48Z37/hhhvE+vXrTepQfZwXX3xRBAUFidDQUHHhwgUBQGzbtk3ceuutQi6Xi4iICJGeni6OHTsmwsPDhYeHh4iNjRUXL140lnXs2DExatQo4evrKzw9PcXtt98uUlNTTY4HQLz77rti3Lhxwt3dXXTr1k18/fXX9X5OZWVlYv78+aJTp05CKpWKrl27ivfee8/4/oEDB8RNN90kpFKpCAwMFM8//7wwGAzG94cOHSpmzJghnn32WeHr6yuGDRsmfvzxRwFA7N69WwwaNEi4ubmJH3/8scHPtHq/K1euCCGEuHTpknjwwQdFhw4dhLu7u+jTp4/45JNPTD5fACavCxcu1CpHCCG++OIL0bt3byGVSkVISIhITEw0+RxCQkLEypUrxZQpU4RSqRTBwcHi7bffrveza67BgweLGTNmGJcrKytFhw4dREJCgsVlvPLKK0KlUhn/toUQ4oEHHhATJ05sVF2efPJJ4eHhIXJycmq9V1xcbPydDx06VDz77LN1lnPx4kUhkUhEWlqacV1RUZFwc3Mz+V2fOXNGABApKSl1ltWU8/j888+FVCo1+RttyPz588WNN95Y69gxMTF17pOUlCTatWsnKisrjet27twpJBKJKC8vN7vPjh07hEQiEZmZmSbrly1bJm699VaL6+sIGH8Zf+09/l6vqqpKBAYGijVr1hjXFRUVCZlMJj799FOLygAgduzYUWt99d9iY9x5552iY8eOJrG9Ws3PNiQkRLzyyit1lvPLL78IFxcXodVqLT72kiVLRP/+/RvcrqmxvT4NXWOq7d69W7i4uIj8/HzjujfffFN4enqaxJKDBw8KqVQqdDpdk+rTHIyDjIP2Hgeb2g6tqKgQQ4YMEe+991698a36b+3XX39tsC721g615Jrw9ttvi4CAAJO24G+//SYAiD/++KPBc67WlHbo6dOnRbt27cTZs2ctPk5LtkMdJimQm5sr2rVrJ9atWycuXLggfvvtN7Fx40ZRXFwshLj2T6xUKsUDDzwg0tLSxLfffiv8/f3Ff/7zH2MZL774oujZs6f47rvvREZGhti8ebOQyWTiwIEDQgghysvLxeLFi8Uvv/wi/vzzT/HRRx8JhUIhtm3bZiyj+jiTJk0SaWlpIi0tzfgPUl326dOnxc033yzCw8PFsGHDxM8//yyOHz8uunXrJqZPn24sa9++feLDDz8UZ86cEadPnxZTp04V7du3N7nQAxCdOnUSn3zyifjjjz/EzJkzhVKpFJcvX67zs7r//vtFcHCw2L59u8jIyBA//PCD+Oyzz4QQQvz9999CoVCIp556Spw5c0bs2LFD+Pn5iSVLlhj3Hzp0qFAqlWLevHni7Nmz4uzZs8Zg2K9fP5GcnCzOnz8vLl++3OBnen0Q/fvvv8WaNWvEr7/+KjIyMsSGDRuEq6urOHr0qBDi2j9nVFSUmDZtmsjLyxN5eXmioqKiVjn/7//9P+Hi4iKWL18u0tPTxebNm4W7u7vYvHmz8TxCQkKEj4+P2Lhxo/jjjz9EQkKCcHFxqfefbeXKlcLDw6Pe119//WV2X71eL1xdXWs1IB999FFxzz331HnM6/Xp00dMmzbNuFxZWSmUSqVYvny5iI6OFv7+/mLw4MFmG6o19/H29haPP/54g8drKBhv375deHh4mATIffv21bo4CiFE586dxbp16+qsU2PPQwgh3n33XeHn59fgedR022231Tqn999/X3h6eta5z59//imkUql47733REVFhSgqKhITJkwQd9xxR5373H333Wbf37Nnj5BKpaKsrKxR9bZXjL+Mv/Yef83JyMgw23i9/fbbxcyZMy0qo76kgFqtFv7+/uKGG24Q06dPF5cuXaqznMuXLwuJRCJWrVrV4DEbSgqsW7dO9OzZ05LqG1maFGhKbG+IpUmBRYsW1arjn3/+KQCI48ePG9ddvXpVuLi4iB9//LFJ9WkqxkHGQXuPg81phy5evFiMGzdOCFF/0tPSpIA9tkMtuSZs2LBBdOrUyeT9P/74QwAw+d02pCnt0NWrV4sbbrhBJCYmitDQUBESEiKmTp1a7/9aS7ZDHSYpkJqaKgDUyoRUmzx5svDx8RFXr141rnvzzTeFUqkUlZWVoqysTCgUCnHkyBGT/aZOnSoeeuihOo87Y8YMMX78eJPjtG/f3iTzW/0PUjML+umnnwoAYt++fcZ1CQkJokePHnUeq7KyUqhUKvHNN98Y1wEQCxcuNC6XlJQIAGLPnj1my0hPTxcAxN69e82+/5///Ef06NFDVFVVGddt3LjR+DkJce2fc+DAgSb7VQfDr776yrjOks/UXGb1eqNHjxZz5swxLpsLDteX8/DDD9f6J5g3b57o3bu3cTkkJMTkrnRVVZUICAgQb775Zp11uXz5svjjjz/qfdV1xzonJ0cAqPV5zJs3TwwePLjOY9Z09OhRAcB4cRJCiLy8PAFAKBQKsW7dOvHrr7+KhIQEIZFIjBe96xUUFAgAFjXiGgrGr7zyiggLCzNZ9/HHHwupVFpr25tuuknMnz/fbDlNOY9//vlHdO7c2aRRZYnu3bvXanzv2rVLAKj37tKBAwdEQECAcHV1FQBEVFRUnX+7OTk5wtXV1aSxVu3kyZP1xitHw/h7DePvtXLsMf6ac/jwYQFA5ObmmqyfMGGCuP/++y0qo66kwKeffiq+/vpr8dtvv4kdO3aIXr16iZtuuklUVFSYLac6tm/fvr3BYzaUFHj22WfFiBEjLKp/NUuTAk2J7Q2xNCkwbdo0ER0dbbLu6tWrxrvDNXl7e4sPPvigSfVpKsbBaxgHr5Vjj3Gwqe3QQ4cOiY4dO4p//vlHCNEySQF7bIdack1IS0sT7dq1Ey+//LLQ6/WisLBQjB8/XgCwKKlbrSnt0CeeeELIZDIRGRkpfvrpJ/Hjjz+KAQMGiOHDh5vdvqXboe3qebLArvTv3x8jR45E3759ERMTg+joaPzrX/+Ct7e3yTYKhcK4HBUVhZKSEmRnZ6OkpAQ6nQ533HGHSbnl5eUYOHCgcXnjxo14//33kZWVhdLSUpSXl9canKdv376QSqW16tivXz/jz+3btzduW3NdzWd6CgoKsHDhQhw4cAAXL15EZWUldDpdrcHjapbr4eEBT0/POp8NOnHiBFxdXTF06FCz7585cwZRUVEmz0TdcsstKCkpwd9//43OnTsDAMLDw83uHxERYfz5/PnzFn2mNVVWVmLVqlX4/PPPkZOTg/Lycuj1epPfmyXOnDmDsWPHmqy75ZZbsH79elRWVsLV1RWA6WcnkUgQGBhY73NVPj4+8PHxaVRdWtKmTZvQt29fk+eHqqqqAABjx47FrFmzAAADBgzAkSNH8NZbb5n9XYv/G7ylJZSWltY7doGlGnseWq0Wo0ePRu/evbF06dJmH78h+fn5mDZtGiZPnoyHHnoIxcXFWLx4Mf71r39h7969tZ4j3LJlC7y8vGoNxgMA7u7uAACdTmf1ercGxt9rGH//dx72Fn8//vhjPPHEE8blPXv2GOthDTUHu+rbty/69euHrl274sCBAxg5cmSt7a0dk++8807j4HshISE4depUix3PHrm7u7d6fGUcvIZx8H/nYW9xsCmKi4sxadIkvPvuu/Dz82uxcu2xHWqJG2+8EVu2bMHs2bMRHx8PV1dXzJw5E+3btzcZz8AaqqqqoNfrsXXrVtxwww0Arn0vCA8PR3p6Onr06GGyfUu3Qx0mKeDq6oq9e/fiyJEjSE5OxmuvvYYXXngBR48eRZcuXRrcv3rUyF27dqFjx44m78lkMgDXRtycO3cu1q5di6ioKKhUKqxZswZHjx412d7Dw8PsMdzc3Iw/Vwe769dVfzECgMmTJ+Py5ct49dVXERISAplMhqioqFoDqtQsw1w5NVX/ETRXXedYc70ln+n11qxZg1dffRXr169H37594eHhgeeee85qA+U05rMDgFWrVmHVqlX1lnn69GnjRasmPz8/uLq61hr5tKCgAIGBgQ3W9erVq/jss8+wfPnyWuW2a9cOvXv3Nlnfq1cv/Pzzz2bL8vf3h5eXF86ePdvgcRvi5+eHK1eumKwLDAxEeXk5ioqK4OXlZVxf37k25jyKi4sRGxsLlUqFHTt21Po9NiQwMNDs78HT07PO/5GNGzdCrVbj5ZdfNq776KOPEBwcjKNHj+Lmm282rhdC4P3338ekSZPMNswKCwsBXPs9tAWMv6iznJoYf021Zvy95557EBkZaVzu2LEj8vLyAFz73w8KCjK+V1BQYPFI/JYKCwuDn58fzp8/bzYp0L17d0gkkhaLyb///rvJuvfeew+lpaUAan/ujdGU2N5SAgMDa42SXh3Hrz92YWFhq8dXxkHUWU5NjIOm7L0dmpGRgczMTJOpPqvr165dO6Snp6Nr16711scce2yHVq9v6Jrw8MMP4+GHH0ZBQQE8PDwgkUiwbt06hIWFWVznprRDg4KC0K5dO2NCALjWRgauzcxSMylgjXaowyQFgGv/SLfccgtuueUWLF68GCEhIdixYwdmz54NADh58iRKS0uNH/Z///tfKJVKBAcHw8fHBzKZDFlZWXVmLw8fPowhQ4bgqaeeMq7LyMiw2vkcPnwYb7zxBu666y4AQHZ2Ni5dutSsMvv27YuqqiocPHgQo0aNqvV+r1698OWXX0IIYbxgHD58GCqVCp06dWrUsXr37t3gZ3q9w4cPY+zYsZg4cSKAa4Hn3LlzJl8UpVIpKisr6y2nV69eOHz4cK2yb7jhhmbdHZo+fTruv//+erfp0KGD2fVSqRTh4eHYt2+fMWtXVVWFffv24emnn27w2ElJSdDr9cbPpma5N910E9LT003Wnzt3DiEhIWbLcnFxwYMPPogPP/wQS5YsqVXnkpISyOVytGvXcAgYOHAg8vPzceXKFeMdkfDwcLi5uWHfvn0YP348ACA9PR1ZWVmIiooyW46l56HVahETEwOZTIadO3c2KTscFRWF3bt3m6zbu3dvnXUDrmVTr88CV/8tXX8BP3jwIM6fP1/n6N9paWno1KlTi2bdbY3xt2GMv7aLvyqVCiqVymRdly5dEBgYiH379hkbfFqtFkePHsWTTz7Z5Hqa8/fff+Py5csmDc2afHx8EBMTg40bN2LmzJm1vvBc37Ctz8CBA/Hmm2+a/B1d/4WoqZoS21tKVFQUVq5ciYsXLyIgIADAtbjt6elp8jeakZGBsrKyOu8EWxPjYMMYBx2rHdqzZ89aScaFCxeiuLgYr776KoKDgxt/ErDPdmhjrwnVvW3ef/99yOXyWj1S6tOUdugtt9yCiooKZGRkGBMx586dA4Ba7X1rtEMdJilw9OhR7Nu3D9HR0QgICMDRo0fxzz//GDMowLXuQlOnTsXChQuRmZmJJUuW4Omnn4aLiwtUKhXmzp2LWbNmoaqqCrfeeis0Gg0OHz4MT09PTJ48Gd27d8fWrVvx/fffo0uXLvjwww/xyy+/WJQBboru3bvjww8/REREBLRaLebNm9fsDGtoaCgmT56Mxx57DBs2bED//v3x119/4eLFi7j//vvx1FNPYf369XjmmWfw9NNPIz09HUuWLMHs2bMb3S3Gks/U3Dl/8cUXOHLkCLy9vbFu3ToUFBSYBOPQ0FAcPXoUmZmZUCqVZrtRzZkzBzfddBNWrFiBBx54ACkpKXj99dfxxhtvNP5Dq6G53bZmz56NyZMnIyIiAoMHD8b69etx9epVTJkyxbjNo48+io4dOyIhIcFk302bNmHcuHHw9fWtVe68efPwwAMP4Pbbb8fw4cPx3Xff4ZtvvsGBAwfqrMvKlStx4MABREZGYuXKlYiIiICbmxsOHTqEhIQE/PLLLxY1QgcOHAg/Pz8cPnwYd999NwBArVZj6tSpmD17Nnx8fODp6YlnnnkGUVFRJnfUe/bsiYSEBNx7770WnYdWq0V0dDR0Oh0++ugjaLVaaLVaANeynZZeaKdPn47XX38d8+fPx2OPPYb9+/fj888/x65du4zbvP7669ixY4dxfvDRo0fjlVdewfLly42PD/znP/9BSEhIrcbnpk2bEBkZiT59+pg9/qFDhxAdHW1RXR0B469lGH9tG3+vJ5FI8Nxzz+HFF19E9+7d0aVLFyxatAgdOnQw6W45cuRI3HvvvcZGc0lJCc6fP298/8KFCzhx4gR8fHzQuXNnlJSUYNmyZRg/fjwCAwORkZGB+fPno1u3boiJiamzPhs3bsQtt9yCwYMHY/ny5ejXrx8qKiqwd+9evPnmmzhz5oxF5zV8+HCUlJTg1KlTdcagaufPn0dJSQny8/NRWlpqnFu8d+/ekEqlyMnJwciRI7F161YMHjzY4thuiepjlZSU4J9//sGJEycglUqNf287duxAfHy88U5idHQ0evfujUmTJuHll19Gfn4+Fi5ciBkzZpjc9T106BDCwsKadPeyORgHLcM46FjtULlcXiuOVLcNa64vLCxEVlYWcnNzAcB4gycwMLDOO/P21g619Jrw+uuvY8iQIVAqldi7dy/mzZuHl156yeLELdC0duioUaMwaNAgPPbYY1i/fj2qqqowY8YM3HHHHSa9BwArtUMtHn3Axk6fPi1iYmKEv7+/kMlk4oYbbhCvvfaa8f3qQTEWL14sfH19hVKpFNOmTTMZdbGqqkqsX79e9OjRQ7i5uQl/f38RExMjDh48KIS4NmBJXFycUKvVwsvLSzz55JNiwYIFJoPzmBt8w9ygG+YGNtm8ebNQq9XG5ePHj4uIiAghl8tF9+7dRVJSUq0BhmBmkCO1Wl3vCJilpaVi1qxZIigoSEilUtGtWzfx/vvvG9+3ZCqYhgZYqdbQZ3r9fpcvXxZjx44VSqVSBAQEiIULF4pHH33U5DNNT08XN998s3B3d7doKhg3NzfRuXNnkylGhDA/WFP//v1NRri1htdee0107txZSKVSMXjwYPHf//7X5P2hQ4eKyZMnm6w7e/asACCSk5PrLHfTpk2iW7duQi6Xi/79+5sMtlOXoqIisWDBAtG9e3chlUpF+/btxahRo8SOHTuMg/xYMgjU/PnzxYMPPmiyrrS0VDz11FPC29tbKBQKce+994q8vDyTbWBmtNb6zqP692zudeHCBeN2ISEhDf4eqwdokUqlIiwsrFY9lixZIkJCQkzWffrpp2LgwIHCw8ND+Pv7i3vuuUecOXPGZJuioiLh7u4u3nnnHbPHLS0tFWq1usnTd9kjxt//Yfy9xl7j7/WqqqrEokWLRPv27YVMJhMjR44U6enpJttcH0/qikPVcVun0xlnUHFzcxMhISFi2rRpJlPp1SU3N1fMmDFDhISECKlUKjp27Cjuuecek5H0GxpoUIhro7svWLCgweMNHTq03nha/f9T8/iWxHZLYrC549aMuZs3bxbXN0MzMzPFnXfeKdzd3YWfn5+YM2dOrUHVoqOjGzXNb0thHPwfxsFr7DUONqUdWpO5v7Hq/9frXw2di721Qy25JkyaNEn4+PgIqVQq+vXrJ7Zu3VqrPtZqh+bk5Ij77rtPKJVK0b59exEXF1dr9gFrtUMlQrTgSBA2FBcXh6KiInz11Ve2rgpRm5Ofn48bb7wRx48fr/ORhdai0+ng6+uLPXv2YNiwYTatizlvvvkmduzYgeTkZFtXpdUw/hK1rt9++w133HEHMjIyoFQqW/XYtozBp06dwogRI3Du3Dmo1epWPXZDGAeJrIftUMs1tR1q3WEUiahNCAwMxKZNm2qNSGwLP/74I0aMGGGXgRi4NqjQa6+9ZutqEFEb1q9fP6xevRoXLlxo9WPbMgbn5eVh69atdpcQICLrYjvUck1th7KnABERNQvjLxE5O8ZBInJkbSYpQERERERERESNw8cHiIiIiIiIiJwUkwJERERERERETopJASIiIiIiIiIn1c7WFWhNVVVVyM3NhUqlgkQisXV1iMiOCSFQXFyMDh06wMWF+dPGYrwlIks5S7xlXCQiS7V2XHSqpEBubi6Cg4NtXQ0iciDZ2dno1KmTravhcBhviaix2nq8ZVwkosZqrbjoVEkBlUoF4NqH6+npaePaEJE902q1CA4ONsYNahzGWyKylLPEW8ZFIrJUa8dFp0oKVHfV8vT0ZDAmIouwi2fTMN4SUWO19XjLuEhEjdVacbHtPrhFRERERERERPViUoCIiIiIiIjISTEpQEREREREROSkmBQgojapuMyA7EIdissMtq4KWYC/LyIiIufD6799cKqBBonIOaTlaJCUmg2NzgC1wg0TwoPRp6Pa1tWiOvD3RURE5Hx4/bcf7ClARG1KcZkBSanZKCwpR4BKjsKSciSlZjMDbaf4+yIiInI+vP7bFyYFiKhNKdIZoNEZEKR2h7vUFUFqd2h0BhTpeJGxR/x9EREROR9e/+0LkwJE1KZ4KdygVrghT1OK0vJK5GlKoVa4wUvhZuuqkRn8fRERETkfXv/tC5MCRNSmqOTXnknzUUpxsbgMPkopJoQHQyXnRcYe8fdFRETkfHj9ty8caJCI2pw+HdUI8VWgSGeAl8KNFxg7x98XERGR8+H1334wKUBEbZJKzouLI+Hvi4iIyPlYcv0vLjMwcWBlfHyAiMjB6fV6DBgwABKJBCdOnKh327KyMsyYMQO+vr5QKpUYP348CgoKTLbJysrC6NGjoVAoEBAQgHnz5qGiosKKZ0BERERUW1qOBonJ6VibnI7E5HSk5WhsXSWzissMyC7UOezsCUwKEBE5uPnz56NDhw4WbTtr1ix88803SEpKwsGDB5Gbm4v77rvP+H5lZSVGjx6N8vJyHDlyBFu2bMEHH3yAxYsXW6v6RERERLU4yrSFjpK4qA+TAkREDmzPnj1ITk5GYmJig9tqNBps2rQJ69atw4gRIxAeHo7NmzfjyJEj+O9//wsASE5OxunTp/HRRx9hwIABuPPOO7FixQps3LgR5eXl1j4dIiIiIgCOMW2hoyQuGsKkABGRgyooKMC0adPw4YcfQqFQNLh9amoqDAYDRo0aZVzXs2dPdO7cGSkpKQCAlJQU9O3bF+3btzduExMTA61Wi1OnTtVZtl6vh1arNXkRERERNZUjTFvoCIkLSzApQETkgIQQiIuLw/Tp0xEREWHRPvn5+ZBKpfDy8jJZ3759e+Tn5xu3qZkQqH6/+r26JCQkQK1WG1/BwcGNOBsiIiIiU44wbaEjJC4swdkHiIjsyIIFC7B69ep6tzlz5gySk5NRXFyM+Pj4VqpZ/eLj4zF79mzjslarZWKAiIiImsXepy2sTlwkpWbbbeLCEkwKEBHZkTlz5iAuLq7ebcLCwrB//36kpKRAJpOZvBcREYFHHnkEW7ZsqbVfYGAgysvLUVRUZNJboKCgAIGBgcZtjh07ZrJf9ewE1duYI5PJatWFiIiIqLnsfdpie09cWIJJASIiO+Lv7w9/f/8Gt9uwYQNefPFF43Jubi5iYmKwbds2REZGmt0nPDwcbm5u2LdvH8aPHw8ASE9PR1ZWFqKiogAAUVFRWLlyJS5evIiAgAAAwN69e+Hp6YnevXs39/SIiIiI2hx7T1w0hEkBIiIH1LlzZ5NlpVIJAOjatSs6deoEAMjJycHIkSOxdetWDB48GGq1GlOnTsXs2bPh4+MDT09PPPPMM4iKisLNN98MAIiOjkbv3r0xadIkvPzyy8jPz8fChQsxY8YM9gQgIiIiaoOYFCAiaqMMBgPS09Oh0+mM61555RW4uLhg/Pjx0Ov1iImJwRtvvGF839XVFd9++y2efPJJREVFwcPDA5MnT8by5cttcQpEREREZGUSIYSwdSVai1arhVqthkajgaenp62rQ0R2jPGiefj5EZGl7D1eZGZmYsWKFdi/fz/y8/PRoUMHTJw4ES+88AKkUqnF5dj7eRKR/WjteMGeAkREREREdTh79iyqqqrw9ttvo1u3bkhLS8O0adNw9epVJCYm2rp6RETNxqQAEREREVEdYmNjERsba1wOCwtDeno63nzzzXqTAnq9Hnq93ris1WqtWk8ioqZysXUFiIiaq7jMgOxCHYrLDLauChEROQGNRgMfH596t0lISIBarTa+goODW6l2RESNw6QAETm0tBwNEpPTsTY5HYnJ6UjL0di6SkRE1IadP38er732Gp544ol6t4uPj4dGozG+srOzW6mGRESNw6QAETms4jIDklKzUVhSjgCVHIUl5UhKzUZeUWmtngPsTUBERDUtWLAAEomk3tfZs2dN9snJyUFsbCwmTJiAadOm1Vu+TCaDp6enyYuIyB5xTAEiclhFOgM0OgOC1O5wl7oiSO2OcxeLkZicjsoqAbXCDRPCr3XXTErNhkZnMK7r01Ft49oTEbU9xWUGFOkM8FK4QSV3s3V16jVnzhzExcXVu01YWJjx59zcXAwfPhxDhgzBO++8Y+XaERG1HiYFiMjuFZcZ8PcVHSSQoKO3u7Gh6aVwg1rhhjxNKXw9ZPijQIscTRnaSYAwfxXyNKX4+OhfkAAoLqtAkNodeZpSJKVmI8RXYfcNViIiR5KWo3GoBKy/vz/8/f0t2jYnJwfDhw9HeHg4Nm/eDBcXdrYloraDSQEismtpORq8fTADabkaABLc2EGF6UO7oU9HNVTya43Otw6eR/KZfGh05aioEoAA/FVyBKndceFSCSQSCUJ9PYy9CS4Wl6FIZ2BSgIiohdR8nKutJWBzcnIwbNgwhISEIDExEf/884/xvcDAQBvWjIioZTApQER2pWbXUwD45Ohf+D1HA1eJBAJAWo4WHx/9C/+5qxdUcjeE+Crg7uaKigoBF4kElVVVyC7SoeKPKvQMVMHfUw4JgDxNqbGh6qOUGssnIqLmM/c4V1tJwO7duxfnz5/H+fPn0alTJ5P3hBA2qhURUcthUoCI7Mb1XU8jQryRVaiDiwRQ/9+X+MKScvyRX4xz+cUID/VBkc6AS8V66Csq4eoigbvUFSVllcjTlKGdiwvu7t8R3QKUSErNxsXiMvgopZgQHuzwjVQiIntS83GutpaAjYuLa3DsASIiR8akABHZheu7np7N1yLl/GWUGSpxRWeA3lCF8kqBotJyXCwpQ/z23/HU8G4Y2SsASnc3VFQJuLgAekMVXCSAu9QVHb3k+DX7Ckb2CsDc6B4OM/gVEZGjqX6ciwlYIiLHw6QAEdmFml1PXV2AyyV6XC2vQJ8Oavyeo0FRaTnKKwVcJRJ08HJHib4Cbx3MQGQXH0y6OQS//61BgbYMVVUCcjdXdFC7o3t7TxTpylGkMyDYx/GfayUismd9OqoR4qtgApaIyMEwKUBEdqFm11OlrB2KSg3wcpeii78HgtTuOPl3IbILS9HeUw6l3A0KtwoUXi1H9hUdBnfxxerx/fDBkUz89ncRXF0k6NNRjctX9W2m+yoRkSNQyZkMIHJWjjQlKZlyiPlUMjMzMXXqVHTp0gXu7u7o2rUrlixZgvLycltXjYhaSHXXUx+lFMVl1wam8nRvhyKdAfnaUnQNUMFLIcWlEj1Kygy4VFIOpdwNwd4KAEBkmC9e/lc/LB/bB5FdfFCir4BK3o7dV4mIiIisLC1Hg8TkdKxNTkdicjrScjS2rhI1gkP0FDh79iyqqqrw9ttvo1u3bkhLS8O0adNw9epVJCYm2rp6RNRCanY9PXz+Ej44konswn+glLthdN8gFGj0KCjWI/OyDv4qGaYP7YogL3fj/iq5G9p7ytHO1QVCCHBMaCIiIiLrastTkjoLh0gKxMbGIjY21rgcFhaG9PR0vPnmm0wKENmANbuHVZd3Jl+LLr4KeCmk+Ke4DLt+z0MXXwXG9AtC5iUdOnrLMbJXQK16JaVmo6SsAl38lLwoEREREVlZW56S1Fk4RFLAHI1GAx8fn3q30ev10Ov1xmWtVmvtahG1eddPGzghPBh9Oqpb9BjVF5dgHw+4S10hAJzNL4aXQgp/lRxKmZvZiw0vSkREREStqy1PSeosHGJMgeudP38er732Gp544ol6t0tISIBarTa+goODW6mGRG1Tze5hASo5CkvKkZSajeIyQ4sep+bFpbS8EkW6a+MHFOnKUVpeiTxNKdQKt1oXm+v3q2s7IiIiImoZNceF4pSkjsmmSYEFCxZAIpHU+zp79qzJPjk5OYiNjcWECRMwbdq0esuPj4+HRqMxvrKzs615OkRtnrk78RrdtUcJ6lNcZkB2oc7i5MH1F5f2ajmmD+0Kbw8pMi9frXMAQV6UiIiIiFpfn45qzI3ugTnRPTA3ukeL9yIl67Lp4wNz5sxBXFxcvduEhYUZf87NzcXw4cMxZMgQvPPOOw2WL5PJIJPJmltNIvo/Teke1tDjBtXjE7RzkaCiShjHKbh+vuu/Lutw9MLlBgcQdMZ5svV6PSIjI3Hy5En8+uuvGDBggNntCgsLsWTJEiQnJyMrKwv+/v4YN24cVqxYAbX6f78TiURSa99PP/0UDz74oLVOgYiIiBwcpyR1XDZNCvj7+8Pf39+ibXNycjB8+HCEh4dj8+bNcHFxyCcfiBxa9Z34pNRsi+7ENzQabXXC4K9LV5Gv1SNQLUeIr8KYOKi+uDRmAEFnnCN3/vz56NChA06ePFnvdrm5ucjNzUViYiJ69+6Nv/76C9OnT0dubi6++OILk203b95sMsCrl5eXNapORERERDbmEAMN5uTkYNiwYQgJCUFiYiL++ecf43uBgYE2rBmR82nMnficK6XIvVKKjl6KWgP/AUBSajYKNGX4p7gc2lIDXCWAezuXWl/46xtAsPr96t4E1h4E0d7s2bMHycnJ+PLLL7Fnz556t+3Tpw++/PJL43LXrl2xcuVKTJw4ERUVFWjX7n+XBC8vL8ZXIiIiIifgEEmBvXv34vz58zh//jw6depk8p4QnImcyB6l5WjwydG/cP6fEvxxsQSDOnvDUFllfNyg+ou+l0KKC5euwk8phb6iCl4KqXGcguqkQF2PLeQWleK9n/+ERmeAu9QVJWUVAOA0c+QWFBRg2rRp+Oqrr6BQKJpUhkajgaenp0lCAABmzJiBf//73wgLC8P06dMxZcoUs48VVONsL0RERESOySH64MfFxV17jtjMi4haV1qOBonJ6VibnI7E5HSk5WhqbVPd3b+4rAIDg70AAL9mF0FZY4DA6i/6RbpytHNxwaWScrRzkaBIV15rxgBzAwiO7huE3Wl5xpkQLmrLkJarga9S2qhBEB2VEAJxcXGYPn06IiIimlTGpUuXsGLFCjz++OMm65cvX47PP/8ce/fuxfjx4/HUU0/htddeq7cszvZCRERE5JgcoqcAEdmHhsYIqHZ9d39PdzfkFpVhclQoegZ5AjAdn6DMUIlKIeDvKUeAWm52nILrH1u4/hjB3h7485IO2YWlkPq7OuwcuQsWLMDq1avr3ebMmTNITk5GcXEx4uPjm3QcrVaL0aNHo3fv3li6dKnJe4sWLTL+PHDgQFy9ehVr1qzBzJkz6ywvPj4es2fPNimfiQEiIiIi+8ekABFZzNJn+6/v7n+5pBxBXnJ09HY3Ka/mF/3rZx8w5/pRbU2OcVWPGzuo4Cl3c+jpCC2dlWX//v1ISUmpNcNKREQEHnnkEWzZsqXO/YuLixEbGwuVSoUdO3bAza3+zygyMhIrVqyAXq+vc0YXzvZCRERE5JiYFCAii9X1bH+e5n/P9lcP8GfpLAVNnb5GJXfD6L5B+OyXLOQU6eCnkmFCeLDDT0do6awsGzZswIsvvmhczs3NRUxMDLZt24bIyMg699NqtYiJiYFMJsPOnTshl8sbPNaJEyfg7e3NL/1EREREbRCTAkRUp+un9zM3JeFdfYKw6/e8Wo8UzI3ugbnRPaz2BT0tR4Ndv+eh3FAFuZsr7uoTZJxpwBGTAY3VuXNnk2WlUgng2owC1QOy5uTkYOTIkdi6dSsGDx4MrVaL6Oho6HQ6fPTRR9BqtcYBAf39/eHq6opvvvkGBQUFuPnmmyGXy7F3716sWrUKc+fObd0TJCIiIqJWwaQAEZmVlqMxO71fQ8/213ykINin4ZH/r088WKLm2AYdvBTI05Rid1oeenfwdIqEgKUMBgPS09Oh0+kAAMePH8fRo0cBAN26dTPZ9sKFCwgNDYWbmxs2btyIWbNmQQiBbt26Yd26dZg2bVqr15+IiIiIrI9JASKqpaEBBet7tr8xA/zVlXhoSH2JCGdNCoSGhtaakeX6dcOGDWtw1pbY2FjExsZapY5EREREZH8cYkpCImpdRToDLhfroZS1g6sL6p3ez9x0gZYM8Fcz8RCgkqOwpPz/pjFseArBmmMblJZXIk9TWmsaQyIiIiIiahh7ChBRLXmaUpz/5yqKywzwcneDr1KGLv4edX7pvv6RAkvu1jfnbr+5sQ0ccaYBIiIiIiJbY1KAiEwUlxmw6/c8+CtlcJVIUFRajkoBzBjerd4v3Y2dRaCumQwsvdvflEQEERERETm+poxJRXVjUoCITFTfwe8V5AkXF0CjM0BbZkAHL/cWPU5L3O1v6nSGREREROSYmjomFdWNSQEiMnH9HfwSfQX8VDKrPK/Pu/1EREREZKmGBsOmpuFAg0RkoqkDBzbneJZMXUhEREREzs3cmFR1DYZNlmNPASKqhXfwiYiIiMjeNHdMKjKPPQWIyCzewSciIiIie9LaPVqdBXsKEDk4jr5KRERERM6CPVpbHpMCRA6oOhGQW1SK3Wl5HH2ViIiIiJwGZ6BqWUwKEDmY6mlYLhXrkfHPVQSoZOgZ6MnRV4mIiIiIqNE4pgCRA6k5DYtK7obiMgMul+jh6gKOvkpEREREdq+4zIDsQh2Ky9hmtRfsKUDkQGpOw+LiAni5S1FUWo4inQEl+gqOvkpEREREdqu6xysffbUv7ClA5EBqTsNSVQX4eEiNPQY4+ioRERER2auaPV4DVHIUlpQjKTWbPQbsAHsKEDmQ6mlYklKzcbG4DGEBHnhmZDcEqd05+ioRERER2a2aPV7dpa4IUrvjYnEZinQGtmFtjEkBIgfDaViIiIiIyNHU7PEapHZHnqaUj77aCT4+UA8OgkH2SiV3Q7APZxkgIiJqDffccw86d+4MuVyOoKAgTJo0Cbm5ubauFpFDqe7x6qOU4mJxGR99tSPsKVAHDoJB9D/FZQb2TCAiIqc1fPhw/Oc//0FQUBBycnIwd+5c/Otf/8KRI0dsXTUih8Ier/aJSQEzag6CUd21hfO/k7NigoyIiJzdrFmzjD+HhIRgwYIFGDduHAwGA9zczLcN9Xo99Hq9cVmr1Vq9nkSOQCVnMsDe8PEBM8wNgsH538kZcZRYx6DX6zFgwABIJBKcOHGi3m2HDRsGiURi8po+fbrJNllZWRg9ejQUCgUCAgIwb948VFRUWPEMiIgcR2FhIT7++GMMGTKkzoQAACQkJECtVhtfwcHBrVhLIiLLMSlgRs1BMErLK5GnKYVa4cZBMMjpMEHmGObPn48OHTpYvP20adOQl5dnfL388svG9yorKzF69GiUl5fjyJEj2LJlCz744AMsXrzYGlUnInIYzz//PDw8PODr64usrCx8/fXX9W4fHx8PjUZjfGVnZ7dSTYmoJTnDOHNMCpjBQTCIrmGCzP7t2bMHycnJSExMtHgfhUKBwMBA48vT09P4XnJyMk6fPo2PPvoIAwYMwJ133okVK1Zg48aNKC8vt8YpEBHZxIIFC2r1nLr+dfbsWeP28+bNw6+//ork5GS4urri0UcfhRCizvJlMhk8PT1NXkTkWNJyNEhMTsfa5HQkJqcjLUdj6ypZBccUqAMHwSD6X4IsKTWbCTI7VFBQgGnTpuGrr76CQqGweL+PP/4YH330EQIDAzFmzBgsWrTIuH9KSgr69u2L9u3bG7ePiYnBk08+iVOnTmHgwIFmy+Szs0TkaObMmYO4uLh6twkLCzP+7OfnBz8/P9xwww3o1asXgoOD8d///hdRUVFWrikR2YIzjTPHpEA9OAgGERNk9koIgbi4OEyfPh0RERHIzMy0aL+HH34YISEh6NChA3777Tc8//zzSE9Px/bt2wEA+fn5JgkBAMbl/Pz8OstNSEjAsmXLmnYyREQ24O/vD39//ybtW1VVBQAmyVAialvMPUZ7sbgMRTpDm2sPMylARA1igqz1LFiwAKtXr653mzNnziA5ORnFxcWIj49vVPmPP/648ee+ffsiKCgII0eOREZGBrp27dqkOgPXnp2dPXu2cVmr1XJQLSJqE44ePYpffvkFt956K7y9vZGRkYFFixaha9eu7CVA1IbVfIy2uqeAj1LaJh+jZVKAiMiOWNqddf/+/UhJSYFMJjN5LyIiAo888gi2bNli0fEiIyMBAOfPn0fXrl0RGBiIY8eOmWxTUFAAAAgMDKyzHJlMVqsuRERtgUKhwPbt27FkyRJcvXoVQUFBiI2NxcKFCxn3iNowldwNo/sG4bNfspBTpIOfSlbvY7TFZQaH7VnLpAARkR2xtDvrhg0b8OKLLxqXc3NzERMTg23bthm/6FuiegrDoKAgAEBUVBRWrlyJixcvIiAgAACwd+9eeHp6onfv3o04EyKitqFv377Yv3+/ratBRK0sLUeDHb/moOhqOZRyN9zVJwh9Oqrr3DYpNRsanQFqxbUxuera1h4xKVAPR872EFHb1rlzZ5NlpVIJAOjatSs6deoEAMjJycHIkSOxdetWDB48GBkZGfjkk09w1113wdfXF7/99htmzZqF22+/Hf369QMAREdHo3fv3pg0aRJefvll5OfnY+HChZgxYwbviBEREZFTKC4z4K2D55GWo0U7FwkqqnSoEpno3cGz1vfCtjAgIZMCdXD0bA8RkcFgQHp6OnQ6HQBAKpXihx9+wPr163H16lUEBwdj/PjxWLhwoXEfV1dXfPvtt3jyyScRFRUFDw8PTJ48GcuXL7fVaRARERG1qpwrpTiVWwwXiQSe7m4o0hlwKrcYOVdK0TPI9It+kc6AS8V6qORucHGBQw5IyKSAGW0h20NEziU0NLTWfNnXrwsODsbBgwcbLCskJAS7d+9u8ToSUctgT0YiIusSEAAEJJAAACTGdbXlFpUi45+rKC4zwMtdCh8PKcICPBxqQEImBcxwpukniIiIyHGwJyMRkfV18lagTwc1fs/RQFNqQKUQ6NtRjY7e7ibbFZcZsDstDz4KN1RWVaFQp0elEHhmZDeH+t7oYusKNJZer8eAAQMgkUiMA2S1tJrTT5SWVyJPUwq1ws2hsj1ERETUttTsyRigkqOwpBxJqdkoLjPYumpERG2KSu6GJ4Z2xZCuvujqr8SQrr54YmjXWl/0i3QG/HVZB03ptTislLWDv1KKIPX/kgfFZQZkF+rsOlY7XE+B+fPno0OHDjh58qTVjqGSX8u8J6Vm42JxGXyU0nqnnyAiIiKyNvZkJCJqPX06qhF/V696H9dq5yJBvqYM2lID/JRSXCopxz8l5Wjncu2xA0fp3WVxUuC+++6zuNDt27c3qTIN2bNnD5KTk/Hll19iz549VjlGtT4d1QjxVfCZPSKqlz3ERiJyDjV7MlaPeeSjlDpFT0bGWiJqLdeP21Lf98CKKoFATxlcJRLoK6rgrZDCXyVFRZVwqHHqLE4KqNX/y2gIIbBjxw6o1WpEREQAAFJTU1FUVNSooN0YBQUFmDZtGr766isoFAqL9tHr9dDr9cZlrVbbqGM29EdARGTr2EhEzsOZezIy1hJRa6i+s3+pWA+ZmwsevKkzBnfxrXN7L4UbQvw8IHdzhbdCiiu6crRXy+GlcHOo3l0WJwU2b95s/Pn555/H/fffj7feeguurq4AgMrKSjz11FPw9PRs8UoKIRAXF4fp06cjIiICmZmZFu2XkJCAZcuWtXh9iIiq2TI2EpHzcdaejIy1RNQU5mZrqWsGl+o7+39evIrCq+UoKi3H6dxiLLvnRkSGmU8M1EzWanQGtFfLMSE8GABQojfAXerqEL27JOL6Oaws4O/vj59//hk9evQwWZ+eno4hQ4bg8uXLFpWzYMECrF69ut5tzpw5g+TkZHz++ec4ePAgXF1dkZmZiS5duuDXX3/FgAED6tzXXE+B4OBgaDQaXjTIKXEaK8tptVqo1epGxYuWio1tQVM+PyJyTo2NF44aaxkXiVqXuef5AdT5jH92oQ4v7TmDzEs6GKqqIG/ngstXy3FzmC+W3nNjvW3nmm3svy7rjMeorBIQEGjn4tKoMQVaO140aaDBiooKnD17tlYwPnv2LKqqqiwuZ86cOYiLi6t3m7CwMOzfvx8pKSmQyWQm70VEROCRRx7Bli1bzO4rk8lq7UPkrBxloBNH1lKxkYiI6sZYS0QNMfc8/8dH/4IEQHFZhdln/L0UbpC5uaCotBy+HlKUGarg5e4GvaGywS7/1Y+dmzuup9wNj0aFoqO3u93elGtSUmDKlCmYOnUqMjIyMHjwYADA0aNH8dJLL2HKlCkWl+Pv7w9/f/8Gt9uwYQNefPFF43Jubi5iYmKwbds2REZGNv4EiJyMIw104shaKjYSEVHdGGuJqCHmnue/cKkEEokEob4eZp/xV8nd8OBNnXE6txiXr5bDy90NvkoZfFUyi7v8mztubpEO2jIDOsK94QJspElJgcTERAQGBmLt2rXIy8sDAAQFBWHevHmYM2dOi1YQADp37myyrFQqAQBdu3ZFp06dWvx4RG2NIw104shaOzYSETkjxloiaoi52Vr8VDJIgFrP+LdzkSC7UAcvhRsGd/HFsntuxOf/Lxt6QyV8VbJGDeh6/XHP5mtxsViPLUcy4fd/ZdljT90mjSlQU/WI/q35bJSlYwpcj89ykbMqLjMgMTndpKeAj1KKudE9mBSoQ3PjhS1ioz1hvCUiSzUnXjhSrGVcJGpdlowpMDDYG79mX6n1eG1zxuGqPu7lYj3O/3MV/koZegV5Nqr97RBjCgDXnuc6cOAAMjIy8PDDDwO41q3f09PTeCffWkJDQ9HMXAaRU3Hmaaxamy1jIxGRs2CsJaKG1DVbS/W6di4SvPVTRp2P1za1nVx93DN5Wmw5komOXgq776nbpKTAX3/9hdjYWGRlZUGv1+OOO+6ASqXC6tWrodfr8dZbb7V0PYmomRxxGitHmy2BsZGIyPoYa4mcW2Pah+a+3Fevyy7UWe3xWpXcDb2CPOGnkjnElIQuTdnp2WefRUREBK5cuQJ39/8NmHDvvfdi3759LVY5ImpZKrkbgn0cY3DBtBwNEpPTsTY5HYnJ6UjL0di6Sg1ibCQisj7GWiLn1ZLtw5rP/5eWVyJPUwq1wq3FvrRX99T1UUrtvqduk3oKHDp0CEeOHIFUKjVZHxoaipycnBapGBE5L0edLYGxkYjI+hhriZxTS7cPW+PxWkfpqdukpEBVVRUqKytrrf/777+hUqmaXSkicm6OOlsCYyMRkfUx1hI5J2u0D1vjS3tzxidoLU16fCA6Ohrr1683LkskEpSUlGDJkiW46667WqpuROSkrN2dy1oYG4mIrI+xlsg5Wat96EiP11pLk6YkzM7ORmxsLIQQ+OOPPxAREYE//vgDfn5++OmnnxAQEGCNujYbp4IhchzmppFpzXldmxIvHDU2WgPjLRFZqrHxwlFjLeMiUfPZun3YWlo7XjQpKQBcmwpm27ZtOHnyJEpKSjBo0CA88sgjJgO+2BsGYyLHYsvZB5oaLxwxNloD4y0RWaop8cIRYy3jIlHLaI32oa1nwLL7pIDBYEDPnj3x7bffolevXtaql1UwGBORpRobL2wZG/V6PSIjI3Hy5En8+uuvGDBggNntMjMz0aVLF7Pvff7555gwYQKAa11xr/fpp5/iwQcftLhOjLdEZKnGxAu2Q4nI2uyhN0Jrx4tGjyng5uaGsrIya9SFiMhh2TI2zp8/Hx06dGhwu+DgYOTl5Zm8li1bBqVSiTvvvNNk282bN5tsN27cOCvVnojIcmyHErUNxWUGZBfqUFxmsHVVTNSc4SBAJUdhSTmSUrPtrp4trUkDDc6YMQOrV69GRUVFS9eHiMhh2SI27tmzB8nJyUhMTGxwW1dXVwQGBpq8duzYgfvvvx9KpdJkWy8vL5Pt5HK5tU6BiKhR2A4lcmxpORokJqdjbXI6EpPTkZajsXWVjMzNcKDRXXuUoC1r0pSEv/zyC/bt24fk5GT07dsXHh4eJu9v3769RSpHRORIWjs2FhQUYNq0afjqq6+gUCgavX9qaipOnDiBjRs31npvxowZ+Pe//42wsDBMnz4dU6ZMMftYQTW9Xg+9Xm9c1mq1jaqLrZ/dIyLHwXYokeOqeSc+SO2OPE0pklKzEeJrH6P/15zhoLp+Pkqp3c+A1VxNSgp4eXlh/PjxLV0XIiKH1pqxUQiBuLg4TJ8+HREREcjMzGx0GZs2bUKvXr0wZMgQk/XLly/HiBEjoFAokJycjKeeegolJSWYOXNmnWUlJCRg2bJlja4DYB/P7hGR42A7lMhxmbsTf7G4DEU6g10kBVTya+2QpNRsXCwug49SignhwXZRN2tqVFKgqqoKa9aswblz51BeXo4RI0Zg6dKldj3Sa3PwzhURWaIlY+OCBQuwevXqerc5c+YMkpOTUVxcjPj4+CbVubS0FJ988gkWLVpU672a6wYOHIirV69izZo19SYF4uPjMXv2bOOyVqtFcHBwg/Ww9zsGRGQ/nK0dStQWOcKd+D4d1QjxVTjV98BGJQVWrlyJpUuXYtSoUXB3d8eGDRvwzz//4P3337dW/WyGd66IHFdrJ/RaMjbOmTMHcXFx9W4TFhaG/fv3IyUlBTKZzOS9iIgIPPLII9iyZUu9ZXzxxRfQ6XR49NFHG6xTZGQkVqxYAb1eX+t41WQyWZ3v1cfe7xgQkf1wpnYoObe2fGPSUe7Eq+Rt77OvT6OSAlu3bsUbb7yBJ554AgDwww8/YPTo0Xjvvffg4tKkMQvtEu9cETkuWyT0WjI2+vv7w9/fv8HtNmzYgBdffNG4nJubi5iYGGzbtg2RkZEN7r9p0ybcc889Fh3rxIkT8Pb2btKX/oY4wh0DIrIPztIOJefmDDcmm3snvi0nTWylUUmBrKws3HXXXcblUaNGQSKRIDc3F506dWrxytkK71wR2be6Lga2SujZIjZ27tzZZLl69oCuXbsaj5mTk4ORI0di69atGDx4sHHb8+fP46effsLu3btrlfvNN9+goKAAN998M+RyOfbu3YtVq1Zh7ty5VjkPR7ljQES25yztUHJeznRjsql34p0haWILjUoKVFRU1JqWys3NDQZD25qigXeuiOxXfRcDWyX07DU2GgwGpKenQ6fTmax///330alTJ0RHR9fax83NDRs3bsSsWbMghEC3bt2wbt06TJs2zWr1dMZn94io8ew11hK1FN6YrJ8zJU1aW6OSAtWjXdfsQlpWVobp06ebTAfj6FPB8M4VkX1q6GJgq4SePcTG0NBQCCEaXAcAq1atwqpVq8yWExsbi9jYWKvUsT7O9uweETWePcRaImvijcn6MWliPY1KCkyePLnWuokTJ7ZYZewJ71wR2Z+GLga2Sug5U2wkIrIVZ4u1fG7a+fDGZP2YNLGeRiUFNm/ebK162CXeuSKyL5ZcDGyR0HO22EhEZAvOFGv53LTz4o3JurVE0oTJNvMalRQgIrIlSy8GTOgREZE16PV6REZG4uTJk/j1118xYMCAFj8Gn5smtmPq1pykCZNtdWNSgIgcCjPoRERkK/Pnz0eHDh1w8uRJqx2Dz00T1a8pSRMm2+rHSV2JyOGo5G4I9mEQJyKi1rNnzx4kJycjMTHRqsep+ahcaXkl8jSlUCvc+Nw0UTOYS7ZpdNceJSAmBepVXGZAdqEOxWX8YyEiIiJyVgUFBZg2bRo+/PBDKBQKi/bR6/XQarUmL0tUPyrno5RysDmiFsJkW/34+EAd+MwJEREREVVPhTh9+nREREQgMzPTov0SEhKwbNmyJh2Tj8oRtSzO7FA/JgXM4DMnRERERG3bggULsHr16nq3OXPmDJKTk1FcXIz4+PhGlR8fH4/Zs2cbl7VaLYKDgy3en4PNEbUsJtvqxqSAGRzghYiIiKhtmzNnDuLi4urdJiwsDPv370dKSgpkMpnJexEREXjkkUewZcsWs/vKZLJa+xCRbTHZZh6TAmZYMhc6ERERETkuf39/+Pv7N7jdhg0b8OKLLxqXc3NzERMTg23btiEyMtKaVSRqsuIyA++Ik8WYFDCDz5wQEREREQB07tzZZFmpVAIAunbtik6dOtmiSkT14tho1FhMCtSBz5wQEREREZEj4dho1BRMCtSDz5wQERERUU2hoaEQQti6GkRmcWw0agoXW1eAiIiIiIiImq/m2Gil5ZXI05RCrXDj2GhULyYFiIiIiIiI2oDqsdF8lFKOjUYW4+MDREREREREbQTHRqPGYlKAiIiIiIioDeHYaNQYfHyAiIiIiIiIyEkxKUBERERERETkpBwqKbBr1y5ERkbC3d0d3t7eGDdunK2rRERkM6GhoZBIJCavl156qd59ysrKMGPGDPj6+kKpVGL8+PEoKCgw2SYrKwujR4+GQqFAQEAA5s2bh4qKCmueChEREVGLKy4zILtQh+Iyg62rYtccZkyBL7/8EtOmTcOqVaswYsQIVFRUIC0tzdbVIiKyqeXLl2PatGnGZZVKVe/2s2bNwq5du5CUlAS1Wo2nn34a9913Hw4fPgwAqKysxOjRoxEYGIgjR44gLy8Pjz76KNzc3LBq1SqrngsRERFRS0nL0SApNRsanQFqxbVZGfp0VNu6WnbJIZICFRUVePbZZ7FmzRpMnTrVuL537942rBURke2pVCoEBgZatK1Go8GmTZvwySefYMSIEQCAzZs3o1evXvjvf/+Lm2++GcnJyTh9+jR++OEHtG/fHgMGDMCKFSvw/PPPY+nSpZBKpdY8HSIiIqJmKy4zICk1G4Ul5QhSuyNPU4qk1GyE+Co4AKMZDvH4wPHjx5GTkwMXFxcMHDgQQUFBuPPOOxvsKaDX66HVak1eROQ42OWrYS+99BJ8fX0xcOBArFmzpt5u/qmpqTAYDBg1apRxXc+ePdG5c2ekpKQAAFJSUtC3b1+0b9/euE1MTAy0Wi1OnTpVZ9mMt0RERGQvinQGaHQGBKnd4S51RZDaHRqdAUU6tinNcYieAn/++ScAYOnSpVi3bh1CQ0Oxdu1aDBs2DOfOnYOPj4/Z/RISErBs2bLWrCoRtRB2+WrYzJkzMWjQIPj4+ODIkSOIj49HXl4e1q1bZ3b7/Px8SKVSeHl5maxv37498vPzjdvUTAhUv1/9Xl0Yb4mIiMheeCncoFa4IU9Tauwp4KOUwkvBXgLm2LSnwIIFC2oNknX96+zZs6iqqgIAvPDCCxg/fjzCw8OxefNmSCQSJCUl1Vl+fHw8NBqN8ZWdnd2o+vEuJZFt1OzyFaCSo7CkHEmp2U7xv2hpXASA2bNnY9iwYejXrx+mT5+OtWvX4rXXXoNer2/1ejc33hIRERG1FJX82g0lH6UUF4vL4KOUYkJ4MB8dqINNewrMmTMHcXFx9W4TFhaGvLw8AKZjCMhkMoSFhSErK6vOfWUyGWQyWZPqxruURLZjrsvXxeIyFOkMbT6YWxoXzYmMjERFRQUyMzPRo0ePWu8HBgaivLwcRUVFJr0FCgoKjOMSBAYG4tixYyb7Vc9OUN/YBc2Jt0REREQtrU9HNUJ8FSjSGeClcGvzbcjmsGlSwN/fH/7+/g1uFx4eDplMhvT0dNx6660AAIPBgMzMTISEhLR4vTgwBZFtOXOXL0vjojknTpyAi4sLAgICzL4fHh4ONzc37Nu3D+PHjwcApKenIysrC1FRUQCAqKgorFy5EhcvXjSWs3fvXnh6enJwVyIiInIoKjmTAZZwiDEFPD09MX36dCxZsgTBwcEICQnBmjVrAAATJkxo8eM5811KIntQ3eUrKTWbXb7qkJKSgqNHj2L48OFQqVRISUnBrFmzMHHiRHh7ewMAcnJyMHLkSGzduhWDBw+GWq3G1KlTMXv2bPj4+MDT0xPPPPMMoqKicPPNNwMAoqOj0bt3b0yaNAkvv/wy8vPzsXDhQsyYMYM9AYiIiIjaIIdICgDAmjVr0K5dO0yaNAmlpaWIjIzE/v37jY3fluTMdymJ7AW7fNVPJpPhs88+w9KlS6HX69GlSxfMmjULs2fPNm5jMBiQnp4OnU5nXPfKK6/AxcUF48ePh16vR0xMDN544w3j+66urvj222/x5JNPIioqCh4eHpg8eTKWL1/equdHRERERK1DIoQQtq5Ea9FqtVCr1dBoNPD09Kx3W44pQOTcGhMvqDZ+fkRkKWeJF85ynkTUfK0dLxymp0Br411KIiIiIiKyluIyA79rkF1gUqAeHJiCiIiIiIhaGnslkz1xsXUFiIiIiIiInEXNmc4CVHIUlpQjKTUbxWUGW1eNnBSTAkRERERERK3E3ExnGt21RwmIbIFJASIiIiIiolZSc6az0vJK5GlKoVa4caYzshkmBYiIiIiIiFqJSn5tDAEfpRQXi8vgo5RiQngwxzIjm+FAg0RERERERK2IM52RPWFSgIiIiIiIqJVxpjOyF3x8gIiIiIiIiMhJMSlARHUqLjMgu1DHKXKIiIhaGa/BRNRa+PgAEZmVlqNBUmo2NDoD1IprA+L06ai2dbWIiIjaPF6Diag1sacAEdVSXGZAUmo2CkvKEaCSo7CkHEmp2bxbQUREZGW8BhNRa2NSgIhqKdIZoNEZEKR2h7vUFUFqd2h0BhTp2CAhIiKyJl6Diai1MSlARLV4KdygVrghT1OK0vJK5GlKoVa4wUvBEXKJiIisiddgImptTArUgwO8kCXa4t+JSn7t+UUfpRQXi8vgo5RiQngwp80hIiKyMl6Diai1caDBOnCAF+dRXHatS56XovFzxbblv5M+HdUI8VU0+bMhIiKipuE1mIhaE5MCZtQc4CVI7Y48TSmSUrMR4qtgUG5jmvOl3hn+TlRyNkSIiIhsgddgImotfHzADA7w4hyaO7ov/06IiIiIiMjRMSlgBgd4cQ7N/VLPvxMiIiIiInJ0TAqYwQFenENzv9Tz74RsLTQ0FBKJxOT10ksv1bl9YWEhnnnmGfTo0QPu7u7o3LkzZs6cCY1GY7Ld9WVKJBJ89tln1j4dIiK71dh4S0TkSDimQB04wEvbV/2lPik1u8lf6vl3Qra2fPlyTJs2zbisUqnq3DY3Nxe5ublITExE79698ddff2H69OnIzc3FF198YbLt5s2bERsba1z28vJq8boTETmSxsRbIiJHwqQAObWW+FLPgYDIllQqFQIDAy3atk+fPvjyyy+Ny127dsXKlSsxceJEVFRUoF27/10SvLy8LC6XiMgZNCbeEhE5Ej4+UIe0HA0Sk9OxNjkdicnpSMvRNLwTOSSV3A3BPm1nxgByLi+99BJ8fX0xcOBArFmzBhUVFY3aX6PRwNPT0yQhAAAzZsyAn58fBg8ejPfffx9CiHrL0ev10Gq1Ji8ioraksfGWcZGIHAV7CpjhDFPNEZHjmzlzJgYNGgQfHx8cOXIE8fHxyMvLw7p16yza/9KlS1ixYgUef/xxk/XLly/HiBEjoFAokJycjKeeegolJSWYOXNmnWUlJCRg2bJlzTofIiJ71ZR4y7hIRI5CIhq6/dOGaLVaqNVq452xumQX6rA2OR0BKjncpa4oLa/ExeIyzInugWAfRSvWmIhsxdJ40dIWLFiA1atX17vNmTNn0LNnz1rr33//fTzxxBMoKSmBTCartwytVos77rgDPj4+2LlzJ9zc6k54Ll68GJs3b0Z2dnad2+j1euj1epPyg4ODW/3zIyLH01bjLeMiETVVa8dF9hQwo+ao9NU9BXyUUk41R0RWN2fOHMTFxdW7TVhYmNn1kZGRqKioQGZmJnr06FHn/sXFxYiNjYVKpcKOHTvqTQhUl7tixQro9fo6G78ymazBRAQRkT2xdrxlXCQiR8GkgBktMSo9EVFT+Pv7w9/fv0n7njhxAi4uLggICKhzG61Wi5iYGMhkMuzcuRNyudyicr29vdm4JaI2xdrxlojIUTApUAdONUdE9iwlJQVHjx7F8OHDoVKpkJKSglmzZmHixInw9vYGAOTk5GDkyJHYunUrBg8eDK1Wi+joaOh0Onz00UcmA1/5+/vD1dUV33zzDQoKCnDzzTdDLpdj7969WLVqFebOnWvL0yUishlL4i0RkSNjUqAenGqOiOyVTCbDZ599hqVLl0Kv16NLly6YNWsWZs+ebdzGYDAgPT0dOp0OAHD8+HEcPXoUANCtWzeT8i5cuIDQ0FC4ublh48aNmDVrFoQQ6NatG9atW2cyNzcRkTOxJN4SETkyDjRIRGQG40Xz8PMjIks5S7xwlvMkouZr7XjhYvUjEBEREREREZFdYlKAyA4UlxmQXahDcZnB1lUhIiIiIiInwjEFiGwsLUeDpNRsaHQGqBXXZr7o01Ft62oREREREZETYE8BIhsqLjMgKTUbhSXlCFDJUVhSjqTUbPYYICIiIiKiVsGkAJENFekM0OgMCFK7w13qiiC1OzQ6A4p0TAoQEREREZH1MSlAZENeCjeoFW7I05SitLwSeZpSqBVu8FJwKkwiIiIiIrI+JgWIbEglvzaGgI9SiovFZfBRSjEhPBgqOZMCRERERERkfQ4z0OC5c+cwb948HD58GOXl5ejXrx9WrFiB4cOHW+2YxWXXunF7Kdz4JY2spk9HNUJ8FfxbIyIiIiKiVucwSYG7774b3bt3x/79++Hu7o7169fj7rvvRkZGBgIDA1v8eBwR3nnZIhmkkjMZQERERERErc8hkgKXLl3CH3/8gU2bNqFfv34AgJdeeglvvPEG0tLSWjwpUHNE+CC1O/I0pUhKzUaIr4Jf3No4JoOIiIiIiMiZOMSYAr6+vujRowe2bt2Kq1evoqKiAm+//TYCAgIQHh5e5356vR5ardbkZYnqEeF9lVIYKqvgq5RyRHgnwOkBiYjI2RWXGZBdqOO1j8hO8X+UrMEhegpIJBL88MMPGDduHFQqFVxcXBAQEIDvvvsO3t7ede6XkJCAZcuWNfp4Xgo3VFYJHEj/B64uElRWCfTtqOaI8G2cuekBLxaXoUhnYA8RIiJq89hbjsi+8X+UrMWmPQUWLFgAiURS7+vs2bMQQmDGjBkICAjAoUOHcOzYMYwbNw5jxoxBXl5eneXHx8dDo9EYX9nZ2RbXTUAAACTXLVPbxekBiYjIWbG3HJF94/8oWZNNewrMmTMHcXFx9W4TFhaG/fv349tvv8WVK1fg6ekJAHjjjTewd+9ebNmyBQsWLDC7r0wmg0wma3S9inQGtHNxwbAbAiCRAEIARaXlvGPcxlVPD5iUms3pAYmIyKmwtxyRfeP/KFmTTZMC/v7+8Pf3b3A7nU4HAHBxMe3Y4OLigqqqqhavV/Ud48sleuNAgz5KKe8YOwFOD0hERM6oZm85tn2I7A//R8maHGKgwaioKHh7e2Py5Mk4efIkzp07h3nz5uHChQsYPXp0ix+v+o6xj1LKO8ZOSCV3Q7APZ5ogIiLnwbYPkX3j/yhZk0MMNOjn54fvvvsOL7zwAkaMGAGDwYAbb7wRX3/9Nfr372+VY/KOMRERETkTtn2I7Bv/R8laHCIpAAARERH4/vvvW/WYKjn/2YiIiMh5sO1DZN/4P0rW4BCPDxARERERERFRy2NSgIiIiIiIiMhJMSlARERERERE5KQcZkyBliCEAABotVob14SI7F11nKiOG9Q4jLdEZClnibeMi0RkqdaOi06VFCguLgYABAcH27gmROQoiouLoVarbV0Nh8N4S0SN1dbjLeMiETVWa8VFiWjradkaqqqqkJubC5VKBYlEYuvqOAytVovg4GBkZ2fD09PT1tVpM/i5Wk9LfLZCCBQXF6NDhw5wceGTVo1VV7x1pr97ZzlXnmfbYovzdJZ4y3Zo4znL/11r4+dqHS35ubZ2XHSqngIuLi7o1KmTravhsDw9PRk4rICfq/U097Nty3esrK2heOtMf/fOcq48z7altc/TGeIt26FN5yz/d62Nn6t1tNTn2ppxse2mY4mIiIiIiIioXkwKEBERERERETkpJgWoQTKZDEuWLIFMJrN1VdoUfq7Ww8/WfjnT78ZZzpXn2bY4y3mSY+Dfo3Xwc7UOR/5cnWqgQSIiIiIiIiL6H/YUICIiIiIiInJSTAoQEREREREROSkmBYiIiIiIiIicFJMCRERERERERE6KSQGq18qVKzFkyBAoFAp4eXmZ3SYrKwujR4+GQqFAQEAA5s2bh4qKitataBsQGhoKiURi8nrppZdsXS2Hs3HjRoSGhkIulyMyMhLHjh2zdZXo/1gST6pdvnwZnTp1gkQiQVFRUavUr6U0dJ4nT57EQw89hODgYLi7u6NXr1549dVXW7+izeTM14dz585h7Nix8PPzg6enJ2699Vb8+OOPtq6WVezatQuRkZFwd3eHt7c3xo0bZ+sqkZNw5hjTmtj+bBmO3v5kUoDqVV5ejgkTJuDJJ580+35lZSVGjx6N8vJyHDlyBFu2bMEHH3yAxYsXt3JN24bly5cjLy/P+HrmmWdsXSWHsm3bNsyePRtLlizB8ePH0b9/f8TExODixYu2rhqh4XhS09SpU9GvX79WqFXLa+g8U1NTERAQgI8++ginTp3CCy+8gPj4eLz++uutXNPmcebrw913342Kigrs378fqamp6N+/P+6++27k5+fbumot6ssvv8SkSZMwZcoUnDx5EocPH8bDDz9s62qRk3DmGNPa2P5snjbR/hREFti8ebNQq9W11u/evVu4uLiI/Px847o333xTeHp6Cr1e34o1dHwhISHilVdesXU1HNrgwYPFjBkzjMuVlZWiQ4cOIiEhwYa1ouvVFU+qvfHGG2Lo0KFi3759AoC4cuVKq9WtJTV0njU99dRTYvjw4datkJU42/Xhn3/+EQDETz/9ZFyn1WoFALF3714b1qxlGQwG0bFjR/Hee+/Zuirk5JwtxrQ2tj+bry20P9lTgJolJSUFffv2Rfv27Y3rYmJioNVqcerUKRvWzDG99NJL8PX1xcCBA7FmzRp2gWuE8vJypKamYtSoUcZ1Li4uGDVqFFJSUmxYM2qM06dPY/ny5di6dStcXJznEqXRaODj42PrarSotnp98PX1RY8ePbB161ZcvXoVFRUVePvttxEQEIDw8HBbV6/FHD9+HDk5OXBxccHAgQMRFBSEO++8E2lpabauGhGAthtjbIHtz6ZrK+3PdrauADm2/Px8k2AMwLjc1rpRWtvMmTMxaNAg+Pj44MiRI4iPj0deXh7WrVtn66o5hEuXLqGystLs3+PZs2dtVCtqDL1ej4ceeghr1qxB586d8eeff9q6Sq3iyJEj2LZtG3bt2mXrqrSotnp9kEgk+OGHHzBu3DioVCq4uLggICAA3333Hby9vW1dvRZT/f+3dOlSrFu3DqGhoVi7di2GDRuGc+fOtbkkFjmethpjWhvbn83TVtqfznMbhowWLFhQa0CR61+O9EdszxrzWc+ePRvDhg1Dv379MH36dKxduxavvfYa9Hq9jc+CqG4tGU/i4+PRq1cvTJw40cq1bjxrxc20tDSMHTsWS5YsQXR0tBVq3jjOfH2w9NyFEJgxYwYCAgJw6NAhHDt2DOPGjcOYMWOQl5dn69NokKXnWVVVBQB44YUXMH78eISHh2Pz5s2QSCRISkqy8VmQo3LmGNOa2P6kxmJPASc0Z84cxMXF1btNWFiYRWUFBgbWGl2zoKDA+J6za85nHRkZiYqKCmRmZqJHjx5WqF3b4ufnB1dXV+PfX7WCggL+LVpRS8aT/fv34/fff8cXX3wBABBCALj2u33hhRewbNmyZtW1OVryPKudPn0aI0eOxOOPP46FCxc2o3Ytx5mvD5ae+/79+/Htt9/iypUr8PT0BAC88cYb2Lt3L7Zs2YIFCxa0Qm2bztLzrE5w9O7d27heJpMhLCwMWVlZ1qwitWHOHGNaE9ufraettD+ZFHBC/v7+8Pf3b5GyoqKisHLlSly8eBEBAQEAgL1798LT09OkIeGsmvNZnzhxwtgtlRomlUoRHh6Offv2GafMqqqqwr59+/D000/btnJtWEvGky+//BKlpaXG5V9++QWPPfYYDh06hK5du7bIMZqqJc8TAE6dOoURI0Zg8uTJWLlyZYuV21zOfH2w9Nx1Oh0A1BrzwsXFxXh33Z5Zep7h4eGQyWRIT0/HrbfeCgAwGAzIzMxESEiItatJbZQzx5jWxPZn62kr7U8mBaheWVlZKCwsRFZWFiorK3HixAkAQLdu3aBUKhEdHY3evXtj0qRJePnll5Gfn4+FCxdixowZkMlktq28A0lJScHRo0cxfPhwqFQqpKSkYNasWZg4cWKbekbV2mbPno3JkycjIiICgwcPxvr163H16lVMmTLF1lUjNBxPrv/if+nSJQBAr1696pyj2h41dJ5paWkYMWIEYmJiMHv2bOOzr66uri2aeLA2Z70+REVFwdvbG5MnT8bixYvh7u6Od999FxcuXMDo0aNtXb0W4+npienTp2PJkiUIDg5GSEgI1qxZAwCYMGGCjWtHzsBZY0xrYvuzZbSJ9qetpz8g+zZ58mQBoNbrxx9/NG6TmZkp7rzzTuHu7i78/PzEnDlzhMFgsF2lHVBqaqqIjIwUarVayOVy0atXL7Fq1SpRVlZm66o5nNdee0107txZSKVSMXjwYPHf//7X1lWi/2NJPKnpxx9/dMgpCRs6zyVLlph9PyQkxKb1bixnvj788ssvIjo6Wvj4+AiVSiVuvvlmsXv3bltXq8WVl5eLOXPmiICAAKFSqcSoUaNEWlqaratFTsKZY0xrYfuz5Th6+1MixP89tElEREREREREToWzDxARERERERE5KSYFiIiIiIiIiJwUkwJERERERERETopJASIiIiIiIiInxaQAERERERERkZNiUoCIiIiIiIjISTEpQEREREREROSkmBQgIiIiIiIiclJMChARERERERE5KSYFqM2QSCT1vpYuXWrrKhIRtQmMt0REphgXyZG1s3UFiFpKXl6e8edt27Zh8eLFSE9PN65TKpXGn4UQqKysRLt2/BcgImosxlsiIlOMi+TI2FOA2ozAwEDjS61WQyKRGJfPnj0LlUqFPXv2IDw8HDKZDD///DPi4uIwbtw4k3Kee+45DBs2zLhcVVWFhIQEdOnSBe7u7ujfvz+++OKL1j05IiI7wnhLRGSKcZEcGdNT5FQWLFiAxMREhIWFwdvb26J9EhIS8NFHH+Gtt95C9+7d8dNPP2HixInw9/fH0KFDrVxjIiLHxHhLRGSKcZHsFZMC5FSWL1+OO+64w+Lt9Xo9Vq1ahR9++AFRUVEAgLCwMPz88894++23GYyJiOrAeEtEZIpxkewVkwLkVCIiIhq1/fnz56HT6WoF8PLycgwcOLAlq0ZE1KYw3hIRmWJcJHvFpAA5FQ8PD5NlFxcXCCFM1hkMBuPPJSUlAIBdu3ahY8eOJtvJZDIr1ZKIyPEx3hIRmWJcJHvFpAA5NX9/f6SlpZmsO3HiBNzc3AAAvXv3hkwmQ1ZWFrtoERE1A+MtEZEpxkWyF0wKkFMbMWIE1qxZg61btyIqKgofffQR0tLSjF2yVCoV5s6di1mzZqGqqgq33norNBoNDh8+DE9PT0yePNnGZ0BE5BgYb4mITDEukr1gUoCcWkxMDBYtWoT58+ejrKwMjz32GB599FH8/vvvxm1WrFgBf39/JCQk4M8//4SXlxcGDRqE//znPzasORGRY2G8JSIyxbhI9kIirn+QhYiIiIiIiIicgoutK0BEREREREREtsGkABEREREREZGTYlKAiIiIiIiIyEkxKUBERERERETkpJgUICIiIiIiInJSTAoQEREREREROSkmBYiIiIiIiIicFJMCRERERERERE6KSQEiIiIiIiIiJ8WkABEREREREZGTYlKAiIiIiIiIyEn9fxlaHYM15fKsAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_val_pred = surrogate.predict(X_val)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "ax[1].set_title(f'Val \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = surrogate.predict(embeddings)\n",
    "# assert y_pred.shape[0] == embeddings.shape[0] == df_results.shape[0]\n",
    "# df_results['pred_ESMC600M_feat_mean_MLP'] = y_pred\n",
    "\n",
    "# df_results.to_csv(results_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESM2, ESM3, ESMC - perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esm2 = ESM2(model_path='/data/users/kgeorge/workspace/esm2/checkpoints/esm2_t33_650M_UR50D.pt', device='gpu')\n",
    "# esm3 = ESM3LM(device='gpu')\n",
    "# esmc = ESMCLM(name='esmc_300m', device='gpu')\n",
    "esmc = ESMCLM(name='esmc_600m', device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['fitness_log'].to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for seq in tqdm(df['seq']):\n",
    "    # perplexity = esm2.compute_perplexity(seq)\n",
    "    # perplexity = esm3.compute_perplexity(seq)\n",
    "    perplexity = esmc.compute_perplexity(seq)\n",
    "    y_pred.append(perplexity)\n",
    "\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(7,3), layout='constrained')\n",
    "\n",
    "ax[0].plot(y, -y_pred, '.', alpha=0.5)\n",
    "corr = stats.spearmanr(y, -y_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y, -y_pred)\n",
    "ax[0].set_title(f'Train \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mask = ~(df['fitness_raw'] == 0)\n",
    "ax[1].plot(y[mask], -y_pred[mask], '.', alpha=0.5)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y[mask], -y_pred[mask])\n",
    "ax[1].set_title(f'Train \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert y_pred.shape[0] == df_results.shape[0]\n",
    "# df_results['pred_ESMC600M_perplexity'] = y_pred\n",
    "\n",
    "# df_results.to_csv(results_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESM2, ESM3, ESMC - ZeroShot Margiaals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from DomainPrediction.utils.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gxps_wt = helper.read_fasta('/nethome/kgeorge/workspace/DomainPrediction/Data/gxps/GxpS_ATC.fasta', mode='str')[0]\n",
    "# A_domain_wt = ''.join([s for i, s in enumerate(gxps_wt) if i in A_gxps_atc])\n",
    "# C_domain_wt = ''.join([s for i, s in enumerate(gxps_wt) if i in C_gxps_atc])\n",
    "# TplusLinker_wt = ''.join([s for i, s in enumerate(gxps_wt) if i not in A_gxps_atc+C_gxps_atc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert TplusLinker_wt == df.loc[df['name'] == 'WT', 'seq'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['TplusLinker'] = df['seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert gxps_wt ==  A_domain_wt + TplusLinker_wt + C_domain_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['seq'] = df['seq'].apply(lambda x: A_domain_wt+x+C_domain_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert gxps_wt == df.loc[df['name'] == 'WT', 'seq'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esm2 = ESM2(model_path='/data/users/kgeorge/workspace/esm2/checkpoints/esm2_t33_650M_UR50D.pt', device='gpu')\n",
    "# esm3 = ESM3LM(device='gpu')\n",
    "# esmc = ESMCLM(name='esmc_300m', device='gpu')\n",
    "esmc = ESMCLM(name='esmc_600m', device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_sequence = df.loc[df['name'] == 'WT', 'seq'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## wt marginals\n",
    "# # wt_log_prob = esm2.get_log_prob(wt_sequence)\n",
    "# # wt_log_prob = esm3.get_log_prob(wt_sequence)\n",
    "# wt_log_prob = esmc.get_log_prob(wt_sequence)\n",
    "# y_pred = []\n",
    "# for i, row in tqdm(df.iterrows()):\n",
    "#     mt_sequence = row['seq']\n",
    "#     # score, n_muts = esm2.get_wildtype_marginal(mt_sequence, wt_sequence, wt_log_prob)\n",
    "#     # score, n_muts = esm3.get_wildtype_marginal(mt_sequence, wt_sequence, wt_log_prob)\n",
    "#     score, n_muts = esmc.get_wildtype_marginal(mt_sequence, wt_sequence, wt_log_prob)\n",
    "\n",
    "#     assert n_muts == row['n_mut']\n",
    "\n",
    "#     y_pred.append(score)\n",
    "\n",
    "# y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## masked marginals\n",
    "# y_pred = []\n",
    "# for i, row in tqdm(df.iterrows()):\n",
    "#     mt_sequence = row['seq']\n",
    "#     # score, n_muts = esm2.get_masked_marginal(mt_sequence, wt_sequence)\n",
    "#     # score, n_muts = esm3.get_masked_marginal(mt_sequence, wt_sequence)\n",
    "#     score, n_muts = esmc.get_masked_marginal(mt_sequence, wt_sequence)\n",
    "\n",
    "#     assert n_muts == row['n_mut']\n",
    "\n",
    "#     y_pred.append(score)\n",
    "\n",
    "# y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## masked marginals mutant\n",
    "# y_pred = []\n",
    "# for i, row in tqdm(df.iterrows()):\n",
    "#     mt_sequence = row['seq']\n",
    "#     # score, n_muts = esm2.get_masked_marginal_var(mt_sequence, wt_sequence)\n",
    "#     # score, n_muts = esm3.get_masked_marginal_var(mt_sequence, wt_sequence)\n",
    "#     score, n_muts = esmc.get_masked_marginal_var(mt_sequence, wt_sequence, mode='mt')\n",
    "\n",
    "#     assert n_muts == row['n_mut']\n",
    "\n",
    "#     y_pred.append(score)\n",
    "\n",
    "# y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pseudolikelihood\n",
    "y_pred = []\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    mt_sequence = row['seq']\n",
    "    # score, n_muts = esm2.get_masked_marginal_var(mt_sequence, wt_sequence)\n",
    "    # score, n_muts = esm3.get_masked_marginal_var(mt_sequence, wt_sequence)\n",
    "    score = esmc.pseudolikelihood(mt_sequence)\n",
    "\n",
    "    y_pred.append(score)\n",
    "\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['fitness_log'].to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(7,3), layout='constrained')\n",
    "\n",
    "ax[0].plot(y, y_pred, '.', alpha=0.5)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y, y_pred)\n",
    "ax[0].set_title(f'Full Dataset \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mask = ~(df['fitness_raw'] == 0)\n",
    "ax[1].plot(y[mask], y_pred[mask], '.', alpha=0.5)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y[mask], y_pred[mask])\n",
    "ax[1].set_title(f'Omit fitness = 0 \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "_ = df['n_mut'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(7,3), layout='constrained')\n",
    "\n",
    "mask_muts = (df['n_mut'] < 15)\n",
    "\n",
    "ax[0].plot(y[mask_muts], y_pred[mask_muts], '.', alpha=0.5)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y[mask_muts], y_pred[mask_muts])\n",
    "ax[0].set_title(f'n mutations < 15 \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "\n",
    "ax[1].plot(y[~mask_muts], y_pred[~mask_muts], '.', alpha=0.5)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y[~mask_muts], y_pred[~mask_muts])\n",
    "ax[1].set_title(f'n mutations > 15 \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(7,3), layout='constrained')\n",
    "\n",
    "mask_muts = (df['n_mut'] < 15)\n",
    "mask_omit = df['fitness_raw'] > 0.01\n",
    "\n",
    "ax[0].plot(y[mask_muts & mask_omit], y_pred[mask_muts & mask_omit], '.', alpha=0.5)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y[mask_muts & mask_omit], y_pred[mask_muts & mask_omit])\n",
    "ax[0].set_title(f'n mutations < 15 and omit \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "ax[1].plot(y[~mask_muts & mask_omit], y_pred[~mask_muts & mask_omit], '.', alpha=0.5)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y[~mask_muts & mask_omit], y_pred[~mask_muts & mask_omit])\n",
    "ax[1].set_title(f'n mutations > 15 and omit \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert y_pred.shape[0] == df_results.shape[0]\n",
    "# df_results['pred_ESMC600_wt_marginal'] = y_pred\n",
    "\n",
    "# df_results.to_csv(results_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert y_pred.shape[0] == df_results.shape[0]\n",
    "# df_results['pred_ESMC600_masked_marginal'] = y_pred\n",
    "\n",
    "# df_results.to_csv(results_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ConFit - Contrastive Fitness Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, val_mask, test_mask = get_split_mask(df, omit_zero=False)\n",
    "df_train = df[train_mask]\n",
    "df_val = df[val_mask]\n",
    "df_test = df[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config={'model_path': '/data/users/kgeorge/workspace/esm2/checkpoints/esm2_t33_650M_UR50D.pt',\n",
    "#         'epoch': 30, \n",
    "#         'batch_size': 8,\n",
    "#         'lambda': 0.1,\n",
    "#         'accumulate_batch_size': 32,\n",
    "#         'patience': 20,\n",
    "#         'early_stopping': False,\n",
    "#         'lr': 5e-4,\n",
    "#         'print_every_n_epoch': 1,\n",
    "#         'device': 'gpu'}\n",
    "# surrogate = ESM2ConFit(config=config)\n",
    "# surrogate.print_trainable_parameters(surrogate.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'epoch': 10, \n",
    "        'batch_size': 8,\n",
    "        'lambda': 0.1,\n",
    "        'accumulate_batch_size': 32,\n",
    "        'patience': 20,\n",
    "        'early_stopping': False,\n",
    "        'lr': 5e-4,\n",
    "        'print_every_n_epoch': 1,\n",
    "        'device': 'gpu'}\n",
    "# surrogate = ESMCConFit(name='esmc_300m', config=config)\n",
    "surrogate = ESMCConFit(name='esmc_600m', config=config)\n",
    "surrogate.print_trainable_parameters(surrogate.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_sequence = df.loc[df['name'] == 'WT', 'seq'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.sanity_check(df_train, wt_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.config['epoch'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.trainmodel(df_train, wt_sequence, df_test[df_test['fitness_raw']>0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## masked marginals\n",
    "y_pred = []\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    mt_sequence = row['seq']\n",
    "    score, n_muts = surrogate.get_masked_marginal(mt_sequence, wt_sequence)\n",
    "\n",
    "    assert n_muts == row['n_mut']\n",
    "\n",
    "    y_pred.append(score)\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "y = df['fitness_log'].to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred, y_train = y_pred[train_mask], y[train_mask]\n",
    "y_val_pred, y_val = y_pred[val_mask], y[val_mask]\n",
    "y_test_pred, y_test = y_pred[test_mask], y[test_mask]\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.8)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.8)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.8)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "ax[1].set_title(f'Val \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omit_mask = df['fitness_raw'] != 0\n",
    "# omit_mask = df['fitness_raw'] > 0.01\n",
    "y_train_pred, y_train = y_pred[train_mask & omit_mask], y[train_mask & omit_mask]\n",
    "y_val_pred, y_val = y_pred[val_mask & omit_mask], y[val_mask & omit_mask]\n",
    "y_test_pred, y_test = y_pred[test_mask & omit_mask], y[test_mask & omit_mask]\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.8)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.8)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.8)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "ax[1].set_title(f'Val \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# omit_mask = df['fitness_raw'] != 0\n",
    "omit_mask = df['fitness_raw'] > 0.01\n",
    "y_train_pred, y_train = y_pred[train_mask & omit_mask], y[train_mask & omit_mask]\n",
    "y_val_pred, y_val = y_pred[val_mask & omit_mask], y[val_mask & omit_mask]\n",
    "y_test_pred, y_test = y_pred[test_mask & omit_mask], y[test_mask & omit_mask]\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.8)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.8)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.8)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "# mse = mean_squared_error(y_val, y_val_pred)\n",
    "# corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "# ax[1].set_title(f'Val \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pseudolikelihood\n",
    "pseudo_likelihood_surrogate = []\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    mt_sequence = row['seq']\n",
    "    score = surrogate.pseudolikelihood(mt_sequence)\n",
    "\n",
    "    pseudo_likelihood_surrogate.append(score)\n",
    "\n",
    "pseudo_likelihood_surrogate = np.array(pseudo_likelihood_surrogate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esmc = ESMCLM(name='esmc_600m', device='gpu')\n",
    "## pseudolikelihood\n",
    "pseudo_likelihood_baseline = []\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    mt_sequence = row['seq']\n",
    "    score = esmc.pseudolikelihood(mt_sequence)\n",
    "\n",
    "    pseudo_likelihood_baseline.append(score)\n",
    "\n",
    "pseudo_likelihood_baseline = np.array(pseudo_likelihood_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omit_mask = df['fitness_raw'] > 0.01\n",
    "y_train_pred, y_train = pseudo_likelihood_baseline[train_mask & omit_mask], y[train_mask & omit_mask]\n",
    "y_val_pred, y_val = pseudo_likelihood_baseline[val_mask & omit_mask], y[val_mask & omit_mask]\n",
    "y_test_pred, y_test = pseudo_likelihood_baseline[test_mask & omit_mask], y[test_mask & omit_mask]\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.8)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.8)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.8)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "# mse = mean_squared_error(y_val, y_val_pred)\n",
    "# corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "# ax[1].set_title(f'Val \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omit_mask = df['fitness_raw'] > 0.01\n",
    "y_train_pred, y_train = pseudo_likelihood_surrogate[train_mask & omit_mask], y[train_mask & omit_mask]\n",
    "y_val_pred, y_val = pseudo_likelihood_surrogate[val_mask & omit_mask], y[val_mask & omit_mask]\n",
    "y_test_pred, y_test = pseudo_likelihood_surrogate[test_mask & omit_mask], y[test_mask & omit_mask]\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.8)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.8)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.8)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_train, y_train_pred)\n",
    "ax[0].set_title(f'Train \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "# mse = mean_squared_error(y_val, y_val_pred)\n",
    "# corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_val, y_val_pred)\n",
    "# ax[1].set_title(f'Val \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y_test, y_test_pred)\n",
    "ax[2].set_title(f'Test \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert y_pred.shape[0] == df_results.shape[0]\n",
    "# df_results['pred_ESMC600M_confit'] = y_pred\n",
    "\n",
    "# df_results.to_csv(results_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.columns[df_results.columns.str.contains('pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing WT to ESM3-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esmc = ESMCLM(name='esmc_600m', device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_sequence = df.loc[df['name'] == 'WT', 'seq'].iloc[0]\n",
    "esm2_seq = df.loc[df['name'] == 'ESM2', 'seq'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## masked marginals\n",
    "y_pred_wt = []\n",
    "y_pred_esm2 = []\n",
    "muts_wt = []\n",
    "muts_esm2 = []\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    mt_sequence = row['seq']\n",
    "    # score_wt, n_muts_wt = esmc.get_masked_marginal(mt_sequence, wt_sequence)\n",
    "    # score_esm2, n_muts_esm2 = esmc.get_masked_marginal(mt_sequence, esm2_seq)\n",
    "    \n",
    "    score_wt, n_muts_wt = esmc.get_wildtype_marginal(mt_sequence, wt_sequence)\n",
    "    score_esm2, n_muts_esm2 = esmc.get_wildtype_marginal(mt_sequence, esm2_seq)\n",
    "\n",
    "    assert n_muts_wt == row['n_mut']\n",
    "\n",
    "    y_pred_wt.append(score_wt)\n",
    "    y_pred_esm2.append(score_esm2)\n",
    "    muts_wt.append(n_muts_wt)\n",
    "    muts_esm2.append(n_muts_esm2)\n",
    "\n",
    "\n",
    "y_pred_wt = np.array(y_pred_wt)\n",
    "y_pred_esm2 = np.array(y_pred_esm2)\n",
    "muts_wt = np.array(muts_wt)\n",
    "muts_esm2 = np.array(muts_esm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['fitness_log'].to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(7,3), layout='constrained')\n",
    "\n",
    "ax[0].plot(y, y_pred_wt, '.', alpha=0.8)\n",
    "corr = stats.spearmanr(y, y_pred_wt)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y, y_pred_wt)\n",
    "ax[0].set_title(f'wrt wt \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "ax[1].plot(y, y_pred_esm2, '.', alpha=0.9)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y, y_pred_esm2)\n",
    "ax[1].set_title(f'wrt esm2 \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(7,3), layout='constrained')\n",
    "\n",
    "_mask = df['fitness_raw'] > 0.01\n",
    "\n",
    "ax[0].plot(y[_mask], y_pred_wt[_mask], '.', alpha=0.8)\n",
    "corr = stats.spearmanr(y[_mask], y_pred_wt[_mask])\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y[_mask], y_pred_wt[_mask])\n",
    "ax[0].set_title(f'wrt wt \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "ax[1].plot(y[_mask], y_pred_esm2[_mask], '.', alpha=0.9)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y[_mask], y_pred_esm2[_mask])\n",
    "ax[1].set_title(f'wrt esm2 \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(5,2), layout='constrained')\n",
    "\n",
    "ax[0].hist(muts_wt[_mask])\n",
    "ax[0].set_title(f'wrt wt')\n",
    "\n",
    "ax[1].hist(muts_esm2[_mask])\n",
    "ax[1].set_title(f'wrt esm2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(7,3), layout='constrained')\n",
    "\n",
    "__mask = df['fitness_raw'] > 0.01\n",
    "_mask = __mask & (df['n_mut'] < 15)\n",
    "\n",
    "print(df.loc[_mask, 'name'].to_numpy())\n",
    "\n",
    "ax[0].plot(y[_mask], y_pred_wt[_mask], '.', alpha=0.8)\n",
    "corr = stats.spearmanr(y[_mask], y_pred_wt[_mask])\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y[_mask], y_pred_wt[_mask])\n",
    "ax[0].set_title(f'wrt wt \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "ax[1].plot(y[_mask], y_pred_esm2[_mask], '.', alpha=0.9)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y[_mask], y_pred_esm2[_mask])\n",
    "ax[1].set_title(f'wrt esm2 \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(5,2), layout='constrained')\n",
    "\n",
    "ax[0].hist(muts_wt[_mask])\n",
    "ax[0].set_title(f'wrt wt')\n",
    "\n",
    "ax[1].hist(muts_esm2[_mask])\n",
    "ax[1].set_title(f'wrt esm2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(7,3), layout='constrained')\n",
    "\n",
    "__mask = df['fitness_raw'] > 0.01\n",
    "_mask = __mask & (df['n_mut'] > 15)\n",
    "\n",
    "print(df.loc[_mask, 'name'].to_numpy())\n",
    "\n",
    "ax[0].plot(y[_mask], y_pred_wt[_mask], '.', alpha=0.8)\n",
    "corr = stats.spearmanr(y[_mask], y_pred_wt[_mask])\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y[_mask], y_pred_wt[_mask])\n",
    "ax[0].set_title(f'wrt wt \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "ax[1].plot(y[_mask], y_pred_esm2[_mask], '.', alpha=0.9)\n",
    "corr, ci_lower, ci_upper, *_  = get_spearmanr_bootstrap(y[_mask], y_pred_esm2[_mask])\n",
    "ax[1].set_title(f'wrt esm2 \\nspearman correlation = {corr} CI ({ci_lower}, {ci_upper})', size=10)\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(5,2), layout='constrained')\n",
    "\n",
    "ax[0].hist(muts_wt[_mask])\n",
    "ax[0].set_title(f'wrt wt')\n",
    "\n",
    "ax[1].hist(muts_esm2[_mask])\n",
    "ax[1].set_title(f'wrt esm2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace-esm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
