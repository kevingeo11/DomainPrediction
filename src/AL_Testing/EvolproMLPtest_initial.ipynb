{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DomainPrediction.utils import helper\n",
    "from DomainPrediction.eval import metrics\n",
    "from DomainPrediction.esm.esm2 import ESM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*Consider increasing the value of the `num_workers` argument*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*Set a lower value for log_every_n_steps*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esm2 = ESM2(model_path='/data/users/kgeorge/workspace/esm2/checkpoints/esm2_t33_650M_UR50D.pt', device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_mean(sequences):\n",
    "    embeddings = []\n",
    "    for seq in tqdm(sequences):\n",
    "        rep = esm2.get_res(sequence=seq)\n",
    "        embeddings.append(rep['representations'][33][:,1:-1,:].mean(1).cpu().numpy())\n",
    "\n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def get_embeddings_mean_batch(sequences, batch_size=3):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(sequences), batch_size)):\n",
    "        seqs = sequences[i:i+batch_size]\n",
    "        rep, batch_lens = esm2.get_res_batch(sequences=seqs)\n",
    "        assert (batch_lens == batch_lens[0]).all() == True\n",
    "        embeddings.append(rep['representations'][33][:,1:-1,:].mean(1).cpu().numpy())\n",
    "\n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def get_embeddings_full(sequences):\n",
    "    embeddings = []\n",
    "    for seq in tqdm(sequences):\n",
    "        rep = esm2.get_res(sequence=seq)\n",
    "        embeddings.append(rep['representations'][33][:,1:-1,:].cpu().numpy()[0])\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def one_hot_encode(sequences: list[str]) -> np.ndarray:\n",
    "    \"\"\"Encode a protein sequence as a one-hot array.\"\"\"\n",
    "    embeddings = []\n",
    "    for seq in tqdm(sequences):\n",
    "        amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "        aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "        one_hot = np.zeros((len(seq), len(amino_acids)))\n",
    "        for i, aa in enumerate(seq):\n",
    "            if aa in amino_acids:\n",
    "                one_hot[i, aa_to_index[aa]] = 1\n",
    "    \n",
    "        embeddings.append(one_hot.flatten())  \n",
    "\n",
    "    embeddings = np.stack(embeddings, axis=0)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFSurrogate():\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        self.model = RandomForestRegressor(n_estimators=100, criterion='friedman_mse', max_depth=None, min_samples_split=2,\n",
    "                                            min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0,\n",
    "                                            max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False,\n",
    "                                            n_jobs=None, random_state=1, verbose=0, warm_start=False, ccp_alpha=0.0,\n",
    "                                            max_samples=None)\n",
    "    \n",
    "    def train(self, X, y, val=None, debug=True):\n",
    "        '''\n",
    "            X - embeddings from esm2\n",
    "            X - shape (n, features)\n",
    "            y - shape (n, )\n",
    "        '''\n",
    "        # if val:\n",
    "        #     idx = np.arange(X.shape[0])\n",
    "        #     train_idx, val_idx = train_test_split(idx, test_size=0.2)\n",
    "        #     _ = self.model.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "        #     if debug:\n",
    "        #         self.print_eval(X[train_idx], y[train_idx], label='train')\n",
    "        #         self.print_eval(X[val_idx], y[val_idx], label='val')\n",
    "        # else:\n",
    "        _ = self.model.fit(X, y)\n",
    "        if debug:\n",
    "            self.print_eval(X, y, label='train')\n",
    "            if val is not None:\n",
    "                X_val, y_val = val\n",
    "                self.print_eval(X_val, y_val, label='val')\n",
    "\n",
    "    \n",
    "    def print_eval(self, X, y, label='set'):\n",
    "        ypred = self.model.predict(X)\n",
    "        mse = mean_squared_error(ypred, y)\n",
    "        corr = stats.spearmanr(ypred, y)\n",
    "\n",
    "        print(f'{label}: mse = {mse}, spearman correlation = {corr.statistic}')\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeSurrogate():\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        self.model = Ridge(alpha=1.0, fit_intercept=True, random_state=1)\n",
    "    \n",
    "    def train(self, X, y, val=None, debug=True):\n",
    "        '''\n",
    "            X - embeddings from esm2\n",
    "            X - shape (n, features)\n",
    "            y - shape (n, )\n",
    "        '''\n",
    "        # if val:\n",
    "        #     idx = np.arange(X.shape[0])\n",
    "        #     train_idx, val_idx = train_test_split(idx, test_size=0.2)\n",
    "        #     _ = self.model.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "        #     if debug:\n",
    "        #         self.print_eval(X[train_idx], y[train_idx], label='train')\n",
    "        #         self.print_eval(X[val_idx], y[val_idx], label='val')\n",
    "        # else:\n",
    "        #     _ = self.model.fit(X, y)\n",
    "        #     if debug:\n",
    "        #         self.print_eval(X, y, label='train')\n",
    "\n",
    "        _ = self.model.fit(X, y)\n",
    "        if debug:\n",
    "            self.print_eval(X, y, label='train')\n",
    "            if val is not None:\n",
    "                X_val, y_val = val\n",
    "                self.print_eval(X_val, y_val, label='val')\n",
    "    \n",
    "    def print_eval(self, X, y, label='set'):\n",
    "        ypred = self.model.predict(X)\n",
    "        mse = mean_squared_error(ypred, y)\n",
    "        corr = stats.spearmanr(ypred, y)\n",
    "\n",
    "        print(f'{label}: mse = {mse}, spearman correlation = {corr.statistic}')\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "class EMLPSurrogate():\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        self.model = MLPRegressor(hidden_layer_sizes=(5), max_iter=1000, activation='relu', solver='adam', alpha=0.001,\n",
    "                             batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5,\n",
    "                             momentum=0.9, nesterovs_momentum=True, shuffle=True, random_state=1, tol=0.0001,\n",
    "                             verbose=False, warm_start=False, early_stopping=False, validation_fraction=0.1, beta_1=0.9,\n",
    "                             beta_2=0.999, epsilon=1e-08)\n",
    "    \n",
    "    def train(self, X, y, val=True, debug=True):\n",
    "        '''\n",
    "            X - embeddings from esm2\n",
    "            X - shape (n, features)\n",
    "            y - shape (n, )\n",
    "        '''\n",
    "        if val:\n",
    "            idx = np.arange(X.shape[0])\n",
    "            train_idx, val_idx = train_test_split(idx, test_size=0.2)\n",
    "            _ = self.model.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "            if debug:\n",
    "                self.print_eval(X[train_idx], y[train_idx], label='train')\n",
    "                self.print_eval(X[val_idx], y[val_idx], label='val')\n",
    "        else:\n",
    "            _ = self.model.fit(X, y)\n",
    "            if debug:\n",
    "                self.print_eval(X, y, label='train')\n",
    "    \n",
    "    def print_eval(self, X, y, label='set'):\n",
    "        ypred = self.model.predict(X)\n",
    "        mse = mean_squared_error(ypred, y)\n",
    "        corr = stats.spearmanr(ypred, y)\n",
    "\n",
    "        print(f'{label}: mse = {mse}, spearman correlation = {corr.statistic}')\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinFunDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X, self.y = X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class MLPSurrogate(pl.LightningModule):\n",
    "    def __init__(self, inp_size=1280, hidden_size=512, \n",
    "                 config={'epoch': 10, \n",
    "                         'batch_size': 16}\n",
    "                ) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        # self.mlp = nn.Sequential(\n",
    "        #     nn.Linear(inp_size, hidden_size),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(hidden_size, 1)\n",
    "        # )\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.LayerNorm(1280),\n",
    "            nn.Linear(1280, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1280),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1280, 1)\n",
    "        )\n",
    "        self.accumulate_batch_loss_train = []\n",
    "        self.accumulate_batch_loss_val = []\n",
    "        self.debug=True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        # y_hat = self.mlp(x)\n",
    "        # print(y_hat)\n",
    "        # print(y_hat.flatten())\n",
    "        # print(y)\n",
    "        # loss = nn.functional.mse_loss(y_hat.flatten(), y)\n",
    "        loss = nn.functional.mse_loss(y_hat.flatten(), y)\n",
    "        self.log(\"train/loss\", loss, on_step=True, on_epoch=True)\n",
    "        self.accumulate_batch_loss_train.append(loss.item())\n",
    "        # print(loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        # y_hat = self.mlp(x)\n",
    "        loss = nn.functional.mse_loss(y_hat.flatten(), y)\n",
    "        self.log(\"val/loss\", loss, on_step=True, on_epoch=True)\n",
    "        self.accumulate_batch_loss_val.append(loss.item())\n",
    "    \n",
    "    @staticmethod\n",
    "    def trainmodel(model, X, y, val=True, debug=True):\n",
    "        '''\n",
    "            X - embeddings from esm2\n",
    "            X - shape (n, features)\n",
    "            y - shape (n, )\n",
    "        '''\n",
    "        model.debug = debug\n",
    "        if val:\n",
    "            idx = np.arange(X.shape[0])\n",
    "            train_idx, val_idx = train_test_split(idx, test_size=0.2)\n",
    "            train_dataset = ProteinFunDataset(X[train_idx], y[train_idx])\n",
    "            val_dataset = ProteinFunDataset(X[val_idx], y[val_idx])\n",
    "            train_loader = DataLoader(train_dataset, batch_size=model.config['batch_size'], shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=model.config['batch_size'], shuffle=False)\n",
    "\n",
    "            earlystopping_callback = EarlyStopping(monitor=\"val/loss\", patience=10, verbose=False, mode=\"min\")\n",
    "\n",
    "            trainer = pl.Trainer(max_epochs=model.config['epoch'], callbacks=[earlystopping_callback],\n",
    "                                 accelerator=\"auto\",\n",
    "                                 enable_progress_bar=False,\n",
    "                                 enable_model_summary=False\n",
    "                                 )\n",
    "            trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "            ## Needs to change - we need to load the least val loss model\n",
    "            y_pred = model.predict(X[val_idx])\n",
    "            val_mse = mean_squared_error(y_pred, y[val_idx])\n",
    "            print(f'Train end val mse: {val_mse}')\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Needs Fix\")\n",
    "            train_dataset = ProteinFunDataset(X, y)\n",
    "            train_loader = DataLoader(train_dataset)\n",
    "\n",
    "            trainer = pl.Trainer(max_epochs=95, \n",
    "                                 enable_progress_bar=False,\n",
    "                                 accelerator=\"auto\"\n",
    "                                 )\n",
    "            trainer.fit(model=model, train_dataloaders=train_loader)\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        self.accumulate_batch_loss_train.clear()\n",
    "        self.accumulate_batch_loss_val.clear()\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        if self.current_epoch % self.config['print_every_n_epoch'] == 0 and self.debug:\n",
    "            print(f'Epoch: {self.current_epoch}: train mse: {np.mean(self.accumulate_batch_loss_train)} val mse: {np.mean(self.accumulate_batch_loss_val)}')\n",
    "\n",
    "    def on_train_end(self):\n",
    "        print(f'Epoch: {self.current_epoch}: train mse: {np.mean(self.accumulate_batch_loss_train)} val mse: {np.mean(self.accumulate_batch_loss_val)}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "            X is numpy array\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            y = self(torch.tensor(X))\n",
    "        return y.numpy().flatten()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../..'\n",
    "data_path = os.path.join(root, 'Data/al_test_experiments/Evolvepro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.join(data_path, 'brenan.csv')\n",
    "df = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['seq'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ESM2 mean-pooled embeddings\n",
    "\n",
    "# embeddings = get_embeddings_mean(df['seq'])\n",
    "# file_name = os.path.join(data_path, 'brenan_embeddings.npy')\n",
    "# np.save(file_name, embeddings)\n",
    "\n",
    "file_name = os.path.join(data_path, 'brenan_embeddings.npy')\n",
    "embeddings = np.load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = one_hot_encode(df['seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.2\n",
    "num_seq_in_pos = 19\n",
    "block_size = 10\n",
    "num_blocks = int(df.shape[0]*test_split // (num_seq_in_pos * block_size) + 1)\n",
    "positions = df['pos'].unique()\n",
    "step_size = len(positions) // num_blocks\n",
    "block_indices = [i for i in range(0, len(positions) - block_size + 1, step_size)][:num_blocks]\n",
    "blocks = [positions[i:i + block_size] for i in block_indices]\n",
    "\n",
    "for _block in blocks:\n",
    "    assert len(_block) == 10\n",
    "    for i in _block:\n",
    "        assert i in positions\n",
    "\n",
    "test_positions = np.concatenate(blocks)\n",
    "test_indices = np.array(df[df['pos'].isin(test_positions)].index)\n",
    "\n",
    "val_split = 0.1\n",
    "n_pos_val = int((~df['pos'].isin(test_positions)).sum()*val_split // num_seq_in_pos + 1)\n",
    "val_positions = np.random.choice(df.loc[~df['pos'].isin(test_positions), 'pos'].unique(), n_pos_val, replace=False)\n",
    "for i in val_positions:\n",
    "    assert i not in test_positions\n",
    "val_indices = np.array(df[df['pos'].isin(val_positions)].index)\n",
    "train_indices = np.array(df[~df['pos'].isin(np.concatenate([val_positions, test_positions]))].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total size: {df.shape[0]}')\n",
    "print(f'train size: {train_indices.shape[0]} ({round(train_indices.shape[0]*100/df.shape[0], 2)}%)')\n",
    "print(f'val size  : {val_indices.shape[0]} ({round(val_indices.shape[0]*100/df.shape[0], 2)}%)')\n",
    "print(f'test size : {test_indices.shape[0]} ({round(test_indices.shape[0]*100/df.shape[0], 2)}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = False\n",
    "if scaled:\n",
    "    property_label = 'function_scaled'\n",
    "else:\n",
    "    property_label = 'function'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = embeddings\n",
    "y = df[property_label].to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[train_indices]\n",
    "y_train = y[train_indices]\n",
    "\n",
    "X_val = X[val_indices]\n",
    "y_val = y[val_indices]\n",
    "\n",
    "X_test = X[test_indices]\n",
    "y_test = y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = RidgeSurrogate()\n",
    "surrogate.train(X=X_train, y=y_train, val=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_val_pred = surrogate.predict(X_val)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr = stats.spearmanr(y_train, y_train_pred)\n",
    "s_corr = round(corr.statistic, 2)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {s_corr}')\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr = stats.spearmanr(y_val, y_val_pred)\n",
    "s_corr = round(corr.statistic, 2)\n",
    "ax[1].set_title(f'Val \\nmse : {str(round(mse, 2))} \\nspearman correlation = {s_corr}')\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr = stats.spearmanr(y_test, y_test_pred)\n",
    "s_corr = round(corr.statistic, 2)\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {s_corr}')\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = RFSurrogate()\n",
    "surrogate.train(X=X_train, y=y_train, val=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = surrogate.predict(X_train)\n",
    "y_val_pred = surrogate.predict(X_val)\n",
    "y_test_pred = surrogate.predict(X_test)\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3), layout='constrained')\n",
    "ax[0].plot(y_train, y_train_pred, '.', alpha=0.5)\n",
    "ax[1].plot(y_val, y_val_pred, '.', alpha=0.5)\n",
    "ax[2].plot(y_test, y_test_pred, '.', alpha=0.5)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "corr = stats.spearmanr(y_train, y_train_pred)\n",
    "s_corr = round(corr.statistic, 2)\n",
    "ax[0].set_title(f'Train \\nmse : {str(round(mse, 2))} \\nspearman correlation = {s_corr}')\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "corr = stats.spearmanr(y_val, y_val_pred)\n",
    "s_corr = round(corr.statistic, 2)\n",
    "ax[1].set_title(f'Val \\nmse : {str(round(mse, 2))} \\nspearman correlation = {s_corr}')\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "corr = stats.spearmanr(y_test, y_test_pred)\n",
    "s_corr = round(corr.statistic, 2)\n",
    "ax[2].set_title(f'Test \\nmse : {str(round(mse, 2))} \\nspearman correlation = {s_corr}')\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].set_ylabel('Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surrogate = EMLPSurrogate()\n",
    "# surrogate.train(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ypred = surrogate.predict(X)\n",
    "# plt.plot(y, ypred, '.')\n",
    "# mse = mean_squared_error(y, ypred)\n",
    "# corr = stats.spearmanr(y, ypred)\n",
    "# s_corr = round(corr.statistic, 2)\n",
    "# plt.title(f'mse : {str(round(mse, 2))} \\nspearman correlation = {s_corr}')\n",
    "# if scaled:\n",
    "#     _min = 0\n",
    "#     _max = max(y) + 0.1\n",
    "# else:\n",
    "#     _min = min(y) - 0.1\n",
    "#     _max = max(y) + 0.1\n",
    "\n",
    "# plt.xlim(_min, _max)\n",
    "# plt.ylim(_min, _max)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'epoch': 500, 'batch_size': 32, 'print_every_n_epoch': 10}\n",
    "surrogate = MLPSurrogate(config=config)\n",
    "MLPSurrogate.trainmodel(model=surrogate, X=X.astype(np.float32), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = surrogate.predict(X.astype(np.float32))\n",
    "fig, ax = plt.subplots(1,2, figsize=(7,3), layout='constrained')\n",
    "ax[0].plot(y, ypred, '.')\n",
    "ax[1].plot(y, ypred, '.')\n",
    "mse = mean_squared_error(y, ypred)\n",
    "corr = stats.spearmanr(y, ypred)\n",
    "s_corr = round(corr.statistic, 2)\n",
    "ax[0].set_title(f'yaxis \\nmse : {str(round(mse, 2))} \\nspearman correlation = {s_corr}')\n",
    "ax[1].set_title(f'yaxis-min-max \\nmse : {str(round(mse, 2))} \\nspearman correlation = {s_corr}')\n",
    "if scaled:\n",
    "    _min = 0\n",
    "    _max = max(y) + 0.1\n",
    "else:\n",
    "    _min = min(y) - 0.1\n",
    "    _max = max(y) + 0.1\n",
    "\n",
    "ax[1].set_xlim(_min, _max)\n",
    "ax[1].set_ylim(_min, _max)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace-esm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
