{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "# import pytorch_lightning as pl\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DomainPrediction.utils import helper\n",
    "from DomainPrediction.eval import metrics\n",
    "from DomainPrediction.esm.esm2 import ESM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*Consider increasing the value of the `num_workers` argument*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*Set a lower value for log_every_n_steps*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esm2 = ESM2(model_path='/data/users/kgeorge/workspace/esm2/checkpoints/esm2_t33_650M_UR50D.pt', device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_mean(sequences):\n",
    "    embeddings = []\n",
    "    for seq in tqdm(sequences):\n",
    "        rep = esm2.get_res(sequence=seq)\n",
    "        embeddings.append(rep['representations'][33].mean(1).cpu().numpy())\n",
    "\n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def get_embeddings_mean_batch(sequences, batch_size=3):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(sequences), batch_size)):\n",
    "        seqs = sequences[i:i+batch_size]\n",
    "        rep, batch_lens = esm2.get_res_batch(sequences=seqs)\n",
    "        assert (batch_lens == batch_lens[0]).all() == True\n",
    "        embeddings.append(rep['representations'][33].mean(1).cpu().numpy())\n",
    "\n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def get_embeddings_full(sequences):\n",
    "    embeddings = []\n",
    "    for seq in tqdm(sequences):\n",
    "        rep = esm2.get_res(sequence=seq)\n",
    "        embeddings.append(rep['representations'][33].cpu().numpy()[0])\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFSurrogate():\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        self.model = RandomForestRegressor(n_estimators=100, criterion='friedman_mse', max_depth=None, min_samples_split=2,\n",
    "                                            min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0,\n",
    "                                            max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False,\n",
    "                                            n_jobs=None, random_state=1, verbose=0, warm_start=False, ccp_alpha=0.0,\n",
    "                                            max_samples=None)\n",
    "    \n",
    "    def train(self, X, y, val=True, debug=True):\n",
    "        '''\n",
    "            X - embeddings from esm2\n",
    "            X - shape (n, features)\n",
    "            y - shape (n, )\n",
    "        '''\n",
    "        if val:\n",
    "            idx = np.arange(X.shape[0])\n",
    "            train_idx, val_idx = train_test_split(idx, test_size=0.2)\n",
    "            _ = self.model.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "            if debug:\n",
    "                self.print_eval(X[train_idx], y[train_idx], label='train')\n",
    "                self.print_eval(X[val_idx], y[val_idx], label='val')\n",
    "        else:\n",
    "            _ = self.model.fit(X, y)\n",
    "            if debug:\n",
    "                self.print_eval(X, y, label='train')\n",
    "    \n",
    "    def print_eval(self, X, y, label='set'):\n",
    "        ypred = self.model.predict(X)\n",
    "        mse = mean_squared_error(ypred, y)\n",
    "        corr = stats.spearmanr(ypred, y)\n",
    "\n",
    "        print(f'{label}: mse = {mse}, spearman correlation = {corr.statistic}')\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeSurrogate():\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        self.model = Ridge(alpha=1.0, fit_intercept=True, random_state=1)\n",
    "    \n",
    "    def train(self, X, y, val=True, debug=True):\n",
    "        '''\n",
    "            X - embeddings from esm2\n",
    "            X - shape (n, features)\n",
    "            y - shape (n, )\n",
    "        '''\n",
    "        if val:\n",
    "            idx = np.arange(X.shape[0])\n",
    "            train_idx, val_idx = train_test_split(idx, test_size=0.2)\n",
    "            _ = self.model.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "            if debug:\n",
    "                self.print_eval(X[train_idx], y[train_idx], label='train')\n",
    "                self.print_eval(X[val_idx], y[val_idx], label='val')\n",
    "        else:\n",
    "            _ = self.model.fit(X, y)\n",
    "            if debug:\n",
    "                self.print_eval(X, y, label='train')\n",
    "    \n",
    "    def print_eval(self, X, y, label='set'):\n",
    "        ypred = self.model.predict(X)\n",
    "        mse = mean_squared_error(ypred, y)\n",
    "        corr = stats.spearmanr(ypred, y)\n",
    "\n",
    "        print(f'{label}: mse = {mse}, spearman correlation = {corr.statistic}')\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinFunDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X, self.y = X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class MLPSurrogate(pl.LightningModule):\n",
    "    def __init__(self, inp_size=1280, hidden_size=512, \n",
    "                 config={'epoch': 10, \n",
    "                         'batch_size': 16}\n",
    "                ) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(inp_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        self.accumulate_batch_loss_train = []\n",
    "        self.accumulate_batch_loss_val = []\n",
    "        self.debug=True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.functional.mse_loss(y_hat.flatten(), y)\n",
    "        self.log(\"train/loss\", loss, on_step=True, on_epoch=True)\n",
    "        self.accumulate_batch_loss_train.append(loss.item())\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.functional.mse_loss(y_hat.flatten(), y)\n",
    "        self.log(\"val/loss\", loss, on_step=True, on_epoch=True)\n",
    "        self.accumulate_batch_loss_val.append(loss.item())\n",
    "    \n",
    "    @staticmethod\n",
    "    def trainmodel(model, X, y, val=True, debug=True):\n",
    "        '''\n",
    "            X - embeddings from esm2\n",
    "            X - shape (n, features)\n",
    "            y - shape (n, )\n",
    "        '''\n",
    "        model.debug = debug\n",
    "        if val:\n",
    "            idx = np.arange(X.shape[0])\n",
    "            train_idx, val_idx = train_test_split(idx, test_size=0.2)\n",
    "            train_dataset = ProteinFunDataset(X[train_idx], y[train_idx])\n",
    "            val_dataset = ProteinFunDataset(X[val_idx], y[val_idx])\n",
    "            train_loader = DataLoader(train_dataset, batch_size=model.config['batch_size'], shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=model.config['batch_size'], shuffle=False)\n",
    "\n",
    "            earlystopping_callback = EarlyStopping(monitor=\"val/loss\", patience=5, verbose=False, mode=\"min\")\n",
    "\n",
    "            trainer = pl.Trainer(max_epochs=model.config['epoch'], callbacks=[earlystopping_callback],\n",
    "                                 accelerator=\"auto\",\n",
    "                                 enable_progress_bar=False,\n",
    "                                 enable_model_summary=False\n",
    "                                 )\n",
    "            trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "            ## Needs to change - we need to load the least val loss model\n",
    "            y_pred = model.predict(X[val_idx])\n",
    "            val_mse = mean_squared_error(y_pred, y[val_idx])\n",
    "            print(f'Train end val mse: {val_mse}')\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Needs Fix\")\n",
    "            train_dataset = ProteinFunDataset(X, y)\n",
    "            train_loader = DataLoader(train_dataset)\n",
    "\n",
    "            trainer = pl.Trainer(max_epochs=95, \n",
    "                                 enable_progress_bar=False,\n",
    "                                 accelerator=\"auto\"\n",
    "                                 )\n",
    "            trainer.fit(model=model, train_dataloaders=train_loader)\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        self.accumulate_batch_loss_train.clear()\n",
    "        self.accumulate_batch_loss_val.clear()\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        if self.current_epoch % self.config['print_every_n_epoch'] == 0 and self.debug:\n",
    "            print(f'Epoch: {self.current_epoch}: train mse: {np.mean(self.accumulate_batch_loss_train)} val mse: {np.mean(self.accumulate_batch_loss_val)}')\n",
    "\n",
    "    def on_train_end(self):\n",
    "        print(f'Epoch: {self.current_epoch}: train mse: {np.mean(self.accumulate_batch_loss_train)} val mse: {np.mean(self.accumulate_batch_loss_val)}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "            X is numpy array\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            y = self(torch.tensor(X))\n",
    "        return y.numpy().flatten()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../..'\n",
    "data_path = os.path.join(root, 'Data/al_test_experiments/Evolvepro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.join(data_path, 'brenan.csv')\n",
    "df = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_embeddings_mean(df['seq'][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'epoch': 500, 'batch_size': 16, 'print_every_n_epoch': 50}\n",
    "surrogate = MLPSurrogate(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPSurrogate.trainmodel(model=surrogate, X=embeddings, y=df['function'][:100].to_numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.predict(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AL Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_embeddings_mean(df['seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surrogate = RFSurrogate()\n",
    "# surrogate = RidgeSurrogate()\n",
    "config = {'epoch': 500, 'batch_size': 16, 'print_every_n_epoch': 50}\n",
    "surrogate = MLPSurrogate(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"lightning.pytorch.utilities.rank_zero\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"lightning.pytorch.accelerators.cuda\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only sample initial points with function < 0.3\n",
    "\n",
    "df_al = df.copy()\n",
    "df_al['round'] = -1\n",
    "\n",
    "rounds = 10\n",
    "thresh = 0.3\n",
    "n_sample = 10\n",
    "high_thresh = 0.6\n",
    "df_al['high'] = 0\n",
    "df_al.loc[list(df_al.loc[(df_al['round'] == -1) & (df_al['function'] > high_thresh)].index), 'high'] = 1\n",
    "index = list(df_al.loc[(df_al['round'] == -1) & (df_al['function'] < thresh)].index)\n",
    "sample_index = random.sample(index, n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(rounds):\n",
    "    print(' ')\n",
    "    print(f'Round {i}')\n",
    "\n",
    "    df_al.loc[sample_index, 'round'] = i\n",
    "    train_index = list(df_al.loc[df_al['round'] != -1].index) ## whatever was selected\n",
    "    X = embeddings[train_index]\n",
    "    y = df_al.loc[train_index, 'function'].to_numpy().astype(np.float32)\n",
    "    \n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    print(f'number of samples for training: {X.shape[0]}')\n",
    "\n",
    "    # surrogate.train(X, y)\n",
    "    # ypred = surrogate.predict(embeddings)\n",
    "\n",
    "    config = {'epoch': 500, 'batch_size': 16, 'print_every_n_epoch': 50}\n",
    "    surrogate = MLPSurrogate(config=config)\n",
    "    MLPSurrogate.trainmodel(model=surrogate, X=X, y=y)\n",
    "    ypred = surrogate.predict(embeddings)\n",
    "\n",
    "    df_al[f'round_{i}_pred'] = ypred\n",
    "\n",
    "    sample_index = df_al.loc[df_al['round']==-1, f'round_{i}_pred'].nlargest(n_sample).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_ylabel('Titer')\n",
    "for i, _round in enumerate(range(rounds)):\n",
    "    ax.boxplot(df_al.loc[df_al['round']==_round, 'function'], positions=[i], labels=[_round], showmeans=True)\n",
    "ax.axhline(high_thresh, ls='--', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_ylabel('Titer')\n",
    "\n",
    "counts = []\n",
    "for i in range(rounds):\n",
    "    counts.append(df_al.loc[df_al['round']==i, 'high'].sum())\n",
    "\n",
    "ax.plot(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_hits = []\n",
    "n_exp = 100\n",
    "for _ in tqdm(range(n_exp)):\n",
    "\n",
    "    df_al = df.copy()\n",
    "    df_al['round'] = -1\n",
    "\n",
    "    rounds = 10\n",
    "    thresh = 0.3\n",
    "    n_sample = 10\n",
    "    high_thresh = 0.6\n",
    "    df_al['high'] = 0\n",
    "    df_al.loc[list(df_al.loc[(df_al['round'] == -1) & (df_al['function'] > high_thresh)].index), 'high'] = 1\n",
    "    index = list(df_al.loc[(df_al['round'] == -1) & (df_al['function'] < thresh)].index)\n",
    "    sample_index = random.sample(index, n_sample)\n",
    "\n",
    "    for i in range(rounds):\n",
    "        df_al.loc[sample_index, 'round'] = i\n",
    "        train_index = list(df_al.loc[df_al['round'] != -1].index) ## whatever was selected\n",
    "        X = embeddings[train_index]\n",
    "        y = df_al.loc[train_index, 'function'].to_numpy().astype(np.float32)\n",
    "        \n",
    "        assert X.shape[0] == y.shape[0]\n",
    "\n",
    "        # surrogate.train(X, y, debug=False)\n",
    "        config = {'epoch': 100, 'batch_size': 16, 'print_every_n_epoch': 50}\n",
    "        surrogate = MLPSurrogate(config=config)\n",
    "        MLPSurrogate.trainmodel(model=surrogate, X=X, y=y, debug=False)\n",
    "        ypred = surrogate.predict(embeddings)\n",
    "\n",
    "        df_al[f'round_{i}_pred'] = ypred\n",
    "\n",
    "        sample_index = df_al.loc[df_al['round']==-1, f'round_{i}_pred'].nlargest(n_sample).index\n",
    "\n",
    "    hits = []\n",
    "    for i in range(rounds):\n",
    "        hits.append(df_al.loc[df_al['round']==i, 'high'].sum())\n",
    "\n",
    "    found_hits.append(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reset trainn weights\n",
    "## revove this print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_hits_cum = np.cumsum(np.array(found_hits), axis=1)/df_al['high'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.cumsum(np.array(found_hits), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 5, figsize=(15,6), layout='constrained')\n",
    "for i, ax in enumerate(axs.reshape(-1)):\n",
    "    ax.hist(found_hits_cum[:, i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# found_hits_mean_ = []\n",
    "# ci_lower_ = []\n",
    "# ci_upper_ = []\n",
    "# for i in range(found_hits_cum.shape[1]):\n",
    "#     if i == 0:\n",
    "#         found_hits_mean_.append(0)\n",
    "#         ci_lower_.append(0)\n",
    "#         ci_upper_.append(0)\n",
    "#     else:\n",
    "#         alpha, loc, beta = stats.gamma.fit(found_hits_cum[:,i])\n",
    "#         found_hits_mean_.append(stats.gamma.mean(alpha, loc, beta))\n",
    "#         confidence = 1 - 0.95\n",
    "#         lower_bound = stats.gamma.ppf(confidence / 2, alpha, loc=loc, scale=beta)\n",
    "#         upper_bound = stats.gamma.ppf(1 - confidence / 2, alpha, loc=loc, scale=beta)\n",
    "#         ci_lower_.append(lower_bound)\n",
    "#         ci_upper_.append(upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_hits_mean = found_hits_cum.mean(0)\n",
    "found_hits_sem = stats.sem(found_hits_cum, axis=0)\n",
    "ci = stats.norm.interval(confidence=0.95,  \n",
    "                        loc=found_hits_mean, \n",
    "                        scale=found_hits_sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(10), found_hits_mean, label='Mean Line', color='blue')\n",
    "plt.fill_between(np.arange(10), ci[0], ci[1], color='blue', alpha=0.2, label='Confidence Interval')\n",
    "# plt.plot(np.arange(10), found_hits_mean_, label='Mean Line', color='green')\n",
    "# plt.fill_between(np.arange(10), ci_lower_, ci_upper_, color='green', alpha=0.2, label='Confidence Interval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace-esm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
