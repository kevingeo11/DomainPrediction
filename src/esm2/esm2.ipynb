{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DomainPrediction import BaseProtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein = BaseProtein(file='../../Data/GxpS_ATC_AF.pdb')\n",
    "T = [i for i in range(538,608)] ## 539-608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein.get_residues(T) ## T domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_query = ''.join(['<mask>' if i in T else protein.sequence[i] for i in range(len(protein.sequence))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "\n",
    "class ESM2():\n",
    "    def __init__(self, model_path, device='cpu') -> None:\n",
    "        self.model, self.alphabet = esm.pretrained.load_model_and_alphabet(model_path)\n",
    "        self.batch_converter = self.alphabet.get_batch_converter()\n",
    "        self.model.eval()\n",
    "        self.device = device\n",
    "\n",
    "        if self.device == 'gpu':\n",
    "            self.model.cuda()\n",
    "\n",
    "        self.tok_to_idx = self.alphabet.tok_to_idx\n",
    "        self.idx_to_tok = {v:k for k,v in self.tok_to_idx.items()}\n",
    "\n",
    "    def get_res(self, sequence):\n",
    "        data = [\n",
    "            (\"protein1\", sequence)\n",
    "        ]\n",
    "        batch_labels, batch_strs, batch_tokens = self.batch_converter(data)\n",
    "        batch_lens = (batch_tokens != self.alphabet.padding_idx).sum(1)\n",
    "\n",
    "        if self.device == 'gpu':\n",
    "            batch_tokens = batch_tokens.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            results = self.model(batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def get_logits(self, sequence):\n",
    "\n",
    "        results = self.get_res(sequence)\n",
    "        return results['logits']\n",
    "\n",
    "    def get_prob(self, sequence):\n",
    "        logits = self.get_logits(sequence)\n",
    "        prob = torch.nn.functional.softmax(logits, dim=-1)[0, 1:-1, :] # 1st and last are start and end tokens\n",
    "\n",
    "        return prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/data/users/kgeorge/workspace/esm2/checkpoints/esm2_t30_150M_UR50D.pt'\n",
    "# model_path = '/data/users/kgeorge/workspace/esm2/checkpoints/esm2_t6_8M_UR50D.pt'\n",
    "esm2 = ESM2(model_path = model_path, device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = esm2.get_prob(sequence=masked_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def compute_perplexity(model, sequence, mask_token='<mask>'):\n",
    "    '''\n",
    "        pseudoperplexity(x) = exp( -1/L \\sum_{i=1}_{L} [log( p(x_{i}|x_{j!=i}) )] )\n",
    "    '''\n",
    "    \n",
    "    sum_log = 0\n",
    "    for pos in tqdm(range(len(sequence))):\n",
    "        masked_query = list(sequence)\n",
    "        assert mask_token not in masked_query\n",
    "        masked_query[pos] = mask_token\n",
    "        masked_query = ''.join(masked_query)\n",
    "        prob = model.get_prob(sequence=masked_query)\n",
    "\n",
    "        assert prob.shape[0] == len(sequence)\n",
    "\n",
    "        prob_pos = np.log(prob[pos, model.tok_to_idx[sequence[pos]]])\n",
    "        \n",
    "        sum_log += prob_pos\n",
    "\n",
    "    return np.exp(-1*sum_log/len(sequence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = compute_perplexity(esm2, protein.sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace-esm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
